{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='elasticsearch', url='', help='"Elasticsearch represents an Elasticsearch resource in a Kubernetes cluster."'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of Elasticsearch', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'elasticsearch.k8s.elastic.co/v1',
    kind: 'Elasticsearch',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help='"ElasticsearchSpec holds the specification of an Elasticsearch cluster."'),
  spec: {
    '#auth':: d.obj(help='"Auth contains user authentication and authorization security settings for Elasticsearch."'),
    auth: {
      '#fileRealm':: d.obj(help='"FileRealm to propagate to the Elasticsearch cluster."'),
      fileRealm: {
        '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
        withSecretName(secretName): { secretName: secretName },
      },
      '#roles':: d.obj(help='"Roles to propagate to the Elasticsearch cluster."'),
      roles: {
        '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
        withSecretName(secretName): { secretName: secretName },
      },
      '#withFileRealm':: d.fn(help='"FileRealm to propagate to the Elasticsearch cluster."', args=[d.arg(name='fileRealm', type=d.T.array)]),
      withFileRealm(fileRealm): { spec+: { auth+: { fileRealm: if std.isArray(v=fileRealm) then fileRealm else [fileRealm] } } },
      '#withFileRealmMixin':: d.fn(help='"FileRealm to propagate to the Elasticsearch cluster."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='fileRealm', type=d.T.array)]),
      withFileRealmMixin(fileRealm): { spec+: { auth+: { fileRealm+: if std.isArray(v=fileRealm) then fileRealm else [fileRealm] } } },
      '#withRoles':: d.fn(help='"Roles to propagate to the Elasticsearch cluster."', args=[d.arg(name='roles', type=d.T.array)]),
      withRoles(roles): { spec+: { auth+: { roles: if std.isArray(v=roles) then roles else [roles] } } },
      '#withRolesMixin':: d.fn(help='"Roles to propagate to the Elasticsearch cluster."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='roles', type=d.T.array)]),
      withRolesMixin(roles): { spec+: { auth+: { roles+: if std.isArray(v=roles) then roles else [roles] } } },
    },
    '#http':: d.obj(help='"HTTP holds HTTP layer settings for Elasticsearch."'),
    http: {
      '#service':: d.obj(help='"Service defines the template for the associated Kubernetes Service object."'),
      service: {
        '#metadata':: d.obj(help='"ObjectMeta is the metadata of the service. The name and namespace provided here are managed by ECK and will be ignored."'),
        metadata: {
          '#withAnnotations':: d.fn(help='', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotations(annotations): { spec+: { http+: { service+: { metadata+: { annotations: annotations } } } } },
          '#withAnnotationsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotationsMixin(annotations): { spec+: { http+: { service+: { metadata+: { annotations+: annotations } } } } },
          '#withFinalizers':: d.fn(help='', args=[d.arg(name='finalizers', type=d.T.array)]),
          withFinalizers(finalizers): { spec+: { http+: { service+: { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } } } } },
          '#withFinalizersMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
          withFinalizersMixin(finalizers): { spec+: { http+: { service+: { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } } } } },
          '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { spec+: { http+: { service+: { metadata+: { labels: labels } } } } },
          '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { spec+: { http+: { service+: { metadata+: { labels+: labels } } } } },
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { http+: { service+: { metadata+: { name: name } } } } },
          '#withNamespace':: d.fn(help='', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { spec+: { http+: { service+: { metadata+: { namespace: namespace } } } } },
        },
        '#spec':: d.obj(help='"Spec is the specification of the service."'),
        spec: {
          '#ports':: d.obj(help='"The list of ports that are exposed by this service. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"'),
          ports: {
            '#withAppProtocol':: d.fn(help='"The application protocol for this port. This field follows standard Kubernetes label syntax. Un-prefixed names are reserved for IANA standard service names (as per RFC-6335 and http://www.iana.org/assignments/service-names). Non-standard protocols should use prefixed names such as mycompany.com/my-custom-protocol. This is a beta field that is guarded by the ServiceAppProtocol feature gate and enabled by default."', args=[d.arg(name='appProtocol', type=d.T.string)]),
            withAppProtocol(appProtocol): { appProtocol: appProtocol },
            '#withName':: d.fn(help="\"The name of this port within the service. This must be a DNS_LABEL. All ports within a ServiceSpec must have unique names. When considering the endpoints for a Service, this must match the 'name' field in the EndpointPort. Optional if only one ServicePort is defined on this service.\"", args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withNodePort':: d.fn(help='"The port on each node on which this service is exposed when type is NodePort or LoadBalancer.  Usually assigned by the system. If a value is specified, in-range, and not in use it will be used, otherwise the operation will fail.  If not specified, a port will be allocated if this Service requires one.  If this field is specified when creating a Service which does not need it, creation will fail. This field will be wiped when updating a Service to no longer need it (e.g. changing type from NodePort to ClusterIP). More info: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport"', args=[d.arg(name='nodePort', type=d.T.integer)]),
            withNodePort(nodePort): { nodePort: nodePort },
            '#withPort':: d.fn(help='"The port that will be exposed by this service."', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { port: port },
            '#withProtocol':: d.fn(help='"The IP protocol for this port. Supports \\"TCP\\", \\"UDP\\", and \\"SCTP\\". Default is TCP."', args=[d.arg(name='protocol', type=d.T.string)]),
            withProtocol(protocol): { protocol: protocol },
            '#withTargetPort':: d.fn(help="\"Number or name of the port to access on the pods targeted by the service. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. If this is a string, it will be looked up as a named port in the target Pod's container ports. If this is not specified, the value of the 'port' field is used (an identity map). This field is ignored for services with clusterIP=None, and should be omitted or set equal to the 'port' field. More info: https://kubernetes.io/docs/concepts/services-networking/service/#defining-a-service\"", args=[d.arg(name='targetPort', type=d.T.any)]),
            withTargetPort(targetPort): { targetPort: targetPort },
          },
          '#sessionAffinityConfig':: d.obj(help='"sessionAffinityConfig contains the configurations of session affinity."'),
          sessionAffinityConfig: {
            '#clientIP':: d.obj(help='"clientIP contains the configurations of Client IP based session affinity."'),
            clientIP: {
              '#withTimeoutSeconds':: d.fn(help='"timeoutSeconds specifies the seconds of ClientIP type session sticky time. The value must be >0 && <=86400(for 1 day) if ServiceAffinity == \\"ClientIP\\". Default value is 10800(for 3 hours)."', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
              withTimeoutSeconds(timeoutSeconds): { spec+: { http+: { service+: { spec+: { sessionAffinityConfig+: { clientIP+: { timeoutSeconds: timeoutSeconds } } } } } } },
            },
          },
          '#withAllocateLoadBalancerNodePorts':: d.fn(help='"allocateLoadBalancerNodePorts defines if NodePorts will be automatically allocated for services with type LoadBalancer.  Default is \\"true\\". It may be set to \\"false\\" if the cluster load-balancer does not rely on NodePorts. allocateLoadBalancerNodePorts may only be set for services with type LoadBalancer and will be cleared if the type is changed to any other type. This field is alpha-level and is only honored by servers that enable the ServiceLBNodePortControl feature."', args=[d.arg(name='allocateLoadBalancerNodePorts', type=d.T.boolean)]),
          withAllocateLoadBalancerNodePorts(allocateLoadBalancerNodePorts): { spec+: { http+: { service+: { spec+: { allocateLoadBalancerNodePorts: allocateLoadBalancerNodePorts } } } } },
          '#withClusterIP':: d.fn(help='"clusterIP is the IP address of the service and is usually assigned randomly. If an address is specified manually, is in-range (as per system configuration), and is not in use, it will be allocated to the service; otherwise creation of the service will fail. This field may not be changed through updates unless the type field is also being changed to ExternalName (which requires this field to be blank) or the type field is being changed from ExternalName (in which case this field may optionally be specified, as describe above).  Valid values are \\"None\\", empty string (\\"\\"), or a valid IP address. Setting this to \\"None\\" makes a \\"headless service\\" (no virtual IP), which is useful when direct endpoint connections are preferred and proxying is not required.  Only applies to types ClusterIP, NodePort, and LoadBalancer. If this field is specified when creating a Service of type ExternalName, creation will fail. This field will be wiped when updating a Service to type ExternalName. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"', args=[d.arg(name='clusterIP', type=d.T.string)]),
          withClusterIP(clusterIP): { spec+: { http+: { service+: { spec+: { clusterIP: clusterIP } } } } },
          '#withClusterIPs':: d.fn(help='"ClusterIPs is a list of IP addresses assigned to this service, and are usually assigned randomly.  If an address is specified manually, is in-range (as per system configuration), and is not in use, it will be allocated to the service; otherwise creation of the service will fail. This field may not be changed through updates unless the type field is also being changed to ExternalName (which requires this field to be empty) or the type field is being changed from ExternalName (in which case this field may optionally be specified, as describe above).  Valid values are \\"None\\", empty string (\\"\\"), or a valid IP address.  Setting this to \\"None\\" makes a \\"headless service\\" (no virtual IP), which is useful when direct endpoint connections are preferred and proxying is not required.  Only applies to types ClusterIP, NodePort, and LoadBalancer. If this field is specified when creating a Service of type ExternalName, creation will fail. This field will be wiped when updating a Service to type ExternalName.  If this field is not specified, it will be initialized from the clusterIP field.  If this field is specified, clients must ensure that clusterIPs[0] and clusterIP have the same value. \\n Unless the \\"IPv6DualStack\\" feature gate is enabled, this field is limited to one value, which must be the same as the clusterIP field.  If the feature gate is enabled, this field may hold a maximum of two entries (dual-stack IPs, in either order).  These IPs must correspond to the values of the ipFamilies field. Both clusterIPs and ipFamilies are governed by the ipFamilyPolicy field. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"', args=[d.arg(name='clusterIPs', type=d.T.array)]),
          withClusterIPs(clusterIPs): { spec+: { http+: { service+: { spec+: { clusterIPs: if std.isArray(v=clusterIPs) then clusterIPs else [clusterIPs] } } } } },
          '#withClusterIPsMixin':: d.fn(help='"ClusterIPs is a list of IP addresses assigned to this service, and are usually assigned randomly.  If an address is specified manually, is in-range (as per system configuration), and is not in use, it will be allocated to the service; otherwise creation of the service will fail. This field may not be changed through updates unless the type field is also being changed to ExternalName (which requires this field to be empty) or the type field is being changed from ExternalName (in which case this field may optionally be specified, as describe above).  Valid values are \\"None\\", empty string (\\"\\"), or a valid IP address.  Setting this to \\"None\\" makes a \\"headless service\\" (no virtual IP), which is useful when direct endpoint connections are preferred and proxying is not required.  Only applies to types ClusterIP, NodePort, and LoadBalancer. If this field is specified when creating a Service of type ExternalName, creation will fail. This field will be wiped when updating a Service to type ExternalName.  If this field is not specified, it will be initialized from the clusterIP field.  If this field is specified, clients must ensure that clusterIPs[0] and clusterIP have the same value. \\n Unless the \\"IPv6DualStack\\" feature gate is enabled, this field is limited to one value, which must be the same as the clusterIP field.  If the feature gate is enabled, this field may hold a maximum of two entries (dual-stack IPs, in either order).  These IPs must correspond to the values of the ipFamilies field. Both clusterIPs and ipFamilies are governed by the ipFamilyPolicy field. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='clusterIPs', type=d.T.array)]),
          withClusterIPsMixin(clusterIPs): { spec+: { http+: { service+: { spec+: { clusterIPs+: if std.isArray(v=clusterIPs) then clusterIPs else [clusterIPs] } } } } },
          '#withExternalIPs':: d.fn(help='"externalIPs is a list of IP addresses for which nodes in the cluster will also accept traffic for this service.  These IPs are not managed by Kubernetes.  The user is responsible for ensuring that traffic arrives at a node with this IP.  A common example is external load-balancers that are not part of the Kubernetes system."', args=[d.arg(name='externalIPs', type=d.T.array)]),
          withExternalIPs(externalIPs): { spec+: { http+: { service+: { spec+: { externalIPs: if std.isArray(v=externalIPs) then externalIPs else [externalIPs] } } } } },
          '#withExternalIPsMixin':: d.fn(help='"externalIPs is a list of IP addresses for which nodes in the cluster will also accept traffic for this service.  These IPs are not managed by Kubernetes.  The user is responsible for ensuring that traffic arrives at a node with this IP.  A common example is external load-balancers that are not part of the Kubernetes system."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='externalIPs', type=d.T.array)]),
          withExternalIPsMixin(externalIPs): { spec+: { http+: { service+: { spec+: { externalIPs+: if std.isArray(v=externalIPs) then externalIPs else [externalIPs] } } } } },
          '#withExternalName':: d.fn(help='"externalName is the external reference that discovery mechanisms will return as an alias for this service (e.g. a DNS CNAME record). No proxying will be involved.  Must be a lowercase RFC-1123 hostname (https://tools.ietf.org/html/rfc1123) and requires `type` to be \\"ExternalName\\"."', args=[d.arg(name='externalName', type=d.T.string)]),
          withExternalName(externalName): { spec+: { http+: { service+: { spec+: { externalName: externalName } } } } },
          '#withExternalTrafficPolicy':: d.fn(help='"externalTrafficPolicy denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints. \\"Local\\" preserves the client source IP and avoids a second hop for LoadBalancer and Nodeport type services, but risks potentially imbalanced traffic spreading. \\"Cluster\\" obscures the client source IP and may cause a second hop to another node, but should have good overall load-spreading."', args=[d.arg(name='externalTrafficPolicy', type=d.T.string)]),
          withExternalTrafficPolicy(externalTrafficPolicy): { spec+: { http+: { service+: { spec+: { externalTrafficPolicy: externalTrafficPolicy } } } } },
          '#withHealthCheckNodePort':: d.fn(help='"healthCheckNodePort specifies the healthcheck nodePort for the service. This only applies when type is set to LoadBalancer and externalTrafficPolicy is set to Local. If a value is specified, is in-range, and is not in use, it will be used.  If not specified, a value will be automatically allocated.  External systems (e.g. load-balancers) can use this port to determine if a given node holds endpoints for this service or not.  If this field is specified when creating a Service which does not need it, creation will fail. This field will be wiped when updating a Service to no longer need it (e.g. changing type)."', args=[d.arg(name='healthCheckNodePort', type=d.T.integer)]),
          withHealthCheckNodePort(healthCheckNodePort): { spec+: { http+: { service+: { spec+: { healthCheckNodePort: healthCheckNodePort } } } } },
          '#withInternalTrafficPolicy':: d.fn(help='"InternalTrafficPolicy specifies if the cluster internal traffic should be routed to all endpoints or node-local endpoints only. \\"Cluster\\" routes internal traffic to a Service to all endpoints. \\"Local\\" routes traffic to node-local endpoints only, traffic is dropped if no node-local endpoints are ready. The default value is \\"Cluster\\"."', args=[d.arg(name='internalTrafficPolicy', type=d.T.string)]),
          withInternalTrafficPolicy(internalTrafficPolicy): { spec+: { http+: { service+: { spec+: { internalTrafficPolicy: internalTrafficPolicy } } } } },
          '#withIpFamilies':: d.fn(help='"IPFamilies is a list of IP families (e.g. IPv4, IPv6) assigned to this service, and is gated by the \\"IPv6DualStack\\" feature gate.  This field is usually assigned automatically based on cluster configuration and the ipFamilyPolicy field. If this field is specified manually, the requested family is available in the cluster, and ipFamilyPolicy allows it, it will be used; otherwise creation of the service will fail.  This field is conditionally mutable: it allows for adding or removing a secondary IP family, but it does not allow changing the primary IP family of the Service.  Valid values are \\"IPv4\\" and \\"IPv6\\".  This field only applies to Services of types ClusterIP, NodePort, and LoadBalancer, and does apply to \\"headless\\" services.  This field will be wiped when updating a Service to type ExternalName. \\n This field may hold a maximum of two entries (dual-stack families, in either order).  These families must correspond to the values of the clusterIPs field, if specified. Both clusterIPs and ipFamilies are governed by the ipFamilyPolicy field."', args=[d.arg(name='ipFamilies', type=d.T.array)]),
          withIpFamilies(ipFamilies): { spec+: { http+: { service+: { spec+: { ipFamilies: if std.isArray(v=ipFamilies) then ipFamilies else [ipFamilies] } } } } },
          '#withIpFamiliesMixin':: d.fn(help='"IPFamilies is a list of IP families (e.g. IPv4, IPv6) assigned to this service, and is gated by the \\"IPv6DualStack\\" feature gate.  This field is usually assigned automatically based on cluster configuration and the ipFamilyPolicy field. If this field is specified manually, the requested family is available in the cluster, and ipFamilyPolicy allows it, it will be used; otherwise creation of the service will fail.  This field is conditionally mutable: it allows for adding or removing a secondary IP family, but it does not allow changing the primary IP family of the Service.  Valid values are \\"IPv4\\" and \\"IPv6\\".  This field only applies to Services of types ClusterIP, NodePort, and LoadBalancer, and does apply to \\"headless\\" services.  This field will be wiped when updating a Service to type ExternalName. \\n This field may hold a maximum of two entries (dual-stack families, in either order).  These families must correspond to the values of the clusterIPs field, if specified. Both clusterIPs and ipFamilies are governed by the ipFamilyPolicy field."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ipFamilies', type=d.T.array)]),
          withIpFamiliesMixin(ipFamilies): { spec+: { http+: { service+: { spec+: { ipFamilies+: if std.isArray(v=ipFamilies) then ipFamilies else [ipFamilies] } } } } },
          '#withIpFamilyPolicy':: d.fn(help='"IPFamilyPolicy represents the dual-stack-ness requested or required by this Service, and is gated by the \\"IPv6DualStack\\" feature gate.  If there is no value provided, then this field will be set to SingleStack. Services can be \\"SingleStack\\" (a single IP family), \\"PreferDualStack\\" (two IP families on dual-stack configured clusters or a single IP family on single-stack clusters), or \\"RequireDualStack\\" (two IP families on dual-stack configured clusters, otherwise fail). The ipFamilies and clusterIPs fields depend on the value of this field.  This field will be wiped when updating a service to type ExternalName."', args=[d.arg(name='ipFamilyPolicy', type=d.T.string)]),
          withIpFamilyPolicy(ipFamilyPolicy): { spec+: { http+: { service+: { spec+: { ipFamilyPolicy: ipFamilyPolicy } } } } },
          '#withLoadBalancerClass':: d.fn(help="\"loadBalancerClass is the class of the load balancer implementation this Service belongs to. If specified, the value of this field must be a label-style identifier, with an optional prefix, e.g. \\\"internal-vip\\\" or \\\"example.com/internal-vip\\\". Unprefixed names are reserved for end-users. This field can only be set when the Service type is 'LoadBalancer'. If not set, the default load balancer implementation is used, today this is typically done through the cloud provider integration, but should apply for any default implementation. If set, it is assumed that a load balancer implementation is watching for Services with a matching class. Any default load balancer implementation (e.g. cloud providers) should ignore Services that set this field. This field can only be set when creating or updating a Service to type 'LoadBalancer'. Once set, it can not be changed. This field will be wiped when a service is updated to a non 'LoadBalancer' type.\"", args=[d.arg(name='loadBalancerClass', type=d.T.string)]),
          withLoadBalancerClass(loadBalancerClass): { spec+: { http+: { service+: { spec+: { loadBalancerClass: loadBalancerClass } } } } },
          '#withLoadBalancerIP':: d.fn(help='"Only applies to Service Type: LoadBalancer LoadBalancer will get created with the IP specified in this field. This feature depends on whether the underlying cloud-provider supports specifying the loadBalancerIP when a load balancer is created. This field will be ignored if the cloud-provider does not support the feature."', args=[d.arg(name='loadBalancerIP', type=d.T.string)]),
          withLoadBalancerIP(loadBalancerIP): { spec+: { http+: { service+: { spec+: { loadBalancerIP: loadBalancerIP } } } } },
          '#withLoadBalancerSourceRanges':: d.fn(help='"If specified and supported by the platform, this will restrict traffic through the cloud-provider load-balancer will be restricted to the specified client IPs. This field will be ignored if the cloud-provider does not support the feature.\\" More info: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/"', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
          withLoadBalancerSourceRanges(loadBalancerSourceRanges): { spec+: { http+: { service+: { spec+: { loadBalancerSourceRanges: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } } } },
          '#withLoadBalancerSourceRangesMixin':: d.fn(help='"If specified and supported by the platform, this will restrict traffic through the cloud-provider load-balancer will be restricted to the specified client IPs. This field will be ignored if the cloud-provider does not support the feature.\\" More info: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
          withLoadBalancerSourceRangesMixin(loadBalancerSourceRanges): { spec+: { http+: { service+: { spec+: { loadBalancerSourceRanges+: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } } } },
          '#withPorts':: d.fn(help='"The list of ports that are exposed by this service. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"', args=[d.arg(name='ports', type=d.T.array)]),
          withPorts(ports): { spec+: { http+: { service+: { spec+: { ports: if std.isArray(v=ports) then ports else [ports] } } } } },
          '#withPortsMixin':: d.fn(help='"The list of ports that are exposed by this service. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ports', type=d.T.array)]),
          withPortsMixin(ports): { spec+: { http+: { service+: { spec+: { ports+: if std.isArray(v=ports) then ports else [ports] } } } } },
          '#withPublishNotReadyAddresses':: d.fn(help="\"publishNotReadyAddresses indicates that any agent which deals with endpoints for this Service should disregard any indications of ready/not-ready. The primary use case for setting this field is for a StatefulSet's Headless Service to propagate SRV DNS records for its Pods for the purpose of peer discovery. The Kubernetes controllers that generate Endpoints and EndpointSlice resources for Services interpret this to mean that all endpoints are considered \\\"ready\\\" even if the Pods themselves are not. Agents which consume only Kubernetes generated endpoints through the Endpoints or EndpointSlice resources can safely assume this behavior.\"", args=[d.arg(name='publishNotReadyAddresses', type=d.T.boolean)]),
          withPublishNotReadyAddresses(publishNotReadyAddresses): { spec+: { http+: { service+: { spec+: { publishNotReadyAddresses: publishNotReadyAddresses } } } } },
          '#withSelector':: d.fn(help='"Route service traffic to pods with label keys and values matching this selector. If empty or not present, the service is assumed to have an external process managing its endpoints, which Kubernetes will not modify. Only applies to types ClusterIP, NodePort, and LoadBalancer. Ignored if type is ExternalName. More info: https://kubernetes.io/docs/concepts/services-networking/service/"', args=[d.arg(name='selector', type=d.T.object)]),
          withSelector(selector): { spec+: { http+: { service+: { spec+: { selector: selector } } } } },
          '#withSelectorMixin':: d.fn(help='"Route service traffic to pods with label keys and values matching this selector. If empty or not present, the service is assumed to have an external process managing its endpoints, which Kubernetes will not modify. Only applies to types ClusterIP, NodePort, and LoadBalancer. Ignored if type is ExternalName. More info: https://kubernetes.io/docs/concepts/services-networking/service/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='selector', type=d.T.object)]),
          withSelectorMixin(selector): { spec+: { http+: { service+: { spec+: { selector+: selector } } } } },
          '#withSessionAffinity':: d.fn(help='"Supports \\"ClientIP\\" and \\"None\\". Used to maintain session affinity. Enable client IP based session affinity. Must be ClientIP or None. Defaults to None. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"', args=[d.arg(name='sessionAffinity', type=d.T.string)]),
          withSessionAffinity(sessionAffinity): { spec+: { http+: { service+: { spec+: { sessionAffinity: sessionAffinity } } } } },
          '#withTopologyKeys':: d.fn(help='"topologyKeys is a preference-order list of topology keys which implementations of services should use to preferentially sort endpoints when accessing this Service, it can not be used at the same time as externalTrafficPolicy=Local. Topology keys must be valid label keys and at most 16 keys may be specified. Endpoints are chosen based on the first topology key with available backends. If this field is specified and all entries have no backends that match the topology of the client, the service has no backends for that client and connections should fail. The special value \\"*\\" may be used to mean \\"any topology\\". This catch-all value, if used, only makes sense as the last value in the list. If this is not specified or empty, no topology constraints will be applied. This field is alpha-level and is only honored by servers that enable the ServiceTopology feature. This field is deprecated and will be removed in a future version."', args=[d.arg(name='topologyKeys', type=d.T.array)]),
          withTopologyKeys(topologyKeys): { spec+: { http+: { service+: { spec+: { topologyKeys: if std.isArray(v=topologyKeys) then topologyKeys else [topologyKeys] } } } } },
          '#withTopologyKeysMixin':: d.fn(help='"topologyKeys is a preference-order list of topology keys which implementations of services should use to preferentially sort endpoints when accessing this Service, it can not be used at the same time as externalTrafficPolicy=Local. Topology keys must be valid label keys and at most 16 keys may be specified. Endpoints are chosen based on the first topology key with available backends. If this field is specified and all entries have no backends that match the topology of the client, the service has no backends for that client and connections should fail. The special value \\"*\\" may be used to mean \\"any topology\\". This catch-all value, if used, only makes sense as the last value in the list. If this is not specified or empty, no topology constraints will be applied. This field is alpha-level and is only honored by servers that enable the ServiceTopology feature. This field is deprecated and will be removed in a future version."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='topologyKeys', type=d.T.array)]),
          withTopologyKeysMixin(topologyKeys): { spec+: { http+: { service+: { spec+: { topologyKeys+: if std.isArray(v=topologyKeys) then topologyKeys else [topologyKeys] } } } } },
          '#withType':: d.fn(help='"type determines how the Service is exposed. Defaults to ClusterIP. Valid options are ExternalName, ClusterIP, NodePort, and LoadBalancer. \\"ClusterIP\\" allocates a cluster-internal IP address for load-balancing to endpoints. Endpoints are determined by the selector or if that is not specified, by manual construction of an Endpoints object or EndpointSlice objects. If clusterIP is \\"None\\", no virtual IP is allocated and the endpoints are published as a set of endpoints rather than a virtual IP. \\"NodePort\\" builds on ClusterIP and allocates a port on every node which routes to the same endpoints as the clusterIP. \\"LoadBalancer\\" builds on NodePort and creates an external load-balancer (if supported in the current cloud) which routes to the same endpoints as the clusterIP. \\"ExternalName\\" aliases this service to the specified externalName. Several other fields do not apply to ExternalName services. More info: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types"', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { http+: { service+: { spec+: { type: type } } } } },
        },
      },
      '#tls':: d.obj(help='"TLS defines options for configuring TLS for HTTP."'),
      tls: {
        '#certificate':: d.obj(help='"Certificate is a reference to a Kubernetes secret that contains the certificate and private key for enabling TLS. The referenced secret should contain the following: \\n - `ca.crt`: The certificate authority (optional). - `tls.crt`: The certificate (or a chain). - `tls.key`: The private key to the first certificate in the certificate chain."'),
        certificate: {
          '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
          withSecretName(secretName): { spec+: { http+: { tls+: { certificate+: { secretName: secretName } } } } },
        },
        '#selfSignedCertificate':: d.obj(help='"SelfSignedCertificate allows configuring the self-signed certificate generated by the operator."'),
        selfSignedCertificate: {
          '#subjectAltNames':: d.obj(help='"SubjectAlternativeNames is a list of SANs to include in the generated HTTP TLS certificate."'),
          subjectAltNames: {
            '#withDns':: d.fn(help='"DNS is the DNS name of the subject."', args=[d.arg(name='dns', type=d.T.string)]),
            withDns(dns): { dns: dns },
            '#withIp':: d.fn(help='"IP is the IP address of the subject."', args=[d.arg(name='ip', type=d.T.string)]),
            withIp(ip): { ip: ip },
          },
          '#withDisabled':: d.fn(help='"Disabled indicates that the provisioning of the self-signed certifcate should be disabled."', args=[d.arg(name='disabled', type=d.T.boolean)]),
          withDisabled(disabled): { spec+: { http+: { tls+: { selfSignedCertificate+: { disabled: disabled } } } } },
          '#withSubjectAltNames':: d.fn(help='"SubjectAlternativeNames is a list of SANs to include in the generated HTTP TLS certificate."', args=[d.arg(name='subjectAltNames', type=d.T.array)]),
          withSubjectAltNames(subjectAltNames): { spec+: { http+: { tls+: { selfSignedCertificate+: { subjectAltNames: if std.isArray(v=subjectAltNames) then subjectAltNames else [subjectAltNames] } } } } },
          '#withSubjectAltNamesMixin':: d.fn(help='"SubjectAlternativeNames is a list of SANs to include in the generated HTTP TLS certificate."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='subjectAltNames', type=d.T.array)]),
          withSubjectAltNamesMixin(subjectAltNames): { spec+: { http+: { tls+: { selfSignedCertificate+: { subjectAltNames+: if std.isArray(v=subjectAltNames) then subjectAltNames else [subjectAltNames] } } } } },
        },
      },
    },
    '#monitoring':: d.obj(help='"Monitoring enables you to collect and ship log and monitoring data of this Elasticsearch cluster. See https://www.elastic.co/guide/en/elasticsearch/reference/current/monitor-elasticsearch-cluster.html. Metricbeat and Filebeat are deployed in the same Pod as sidecars and each one sends data to one or two different Elasticsearch monitoring clusters running in the same Kubernetes cluster."'),
    monitoring: {
      '#logs':: d.obj(help='"Logs holds references to Elasticsearch clusters which receive log data from this Elasticsearch cluster."'),
      logs: {
        '#elasticsearchRefs':: d.obj(help='"ElasticsearchRefs is a reference to a list of monitoring Elasticsearch clusters running in the same Kubernetes cluster. Due to existing limitations, only a single Elasticsearch cluster is currently supported."'),
        elasticsearchRefs: {
          '#withName':: d.fn(help='"Name of the Kubernetes object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withNamespace':: d.fn(help='"Namespace of the Kubernetes object. If empty, defaults to the current namespace."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { namespace: namespace },
          '#withServiceName':: d.fn(help='"ServiceName is the name of an existing Kubernetes service which is used to make requests to the referenced object. It has to be in the same namespace as the referenced resource. If left empty, the default HTTP service of the referenced resource is used."', args=[d.arg(name='serviceName', type=d.T.string)]),
          withServiceName(serviceName): { serviceName: serviceName },
        },
        '#withElasticsearchRefs':: d.fn(help='"ElasticsearchRefs is a reference to a list of monitoring Elasticsearch clusters running in the same Kubernetes cluster. Due to existing limitations, only a single Elasticsearch cluster is currently supported."', args=[d.arg(name='elasticsearchRefs', type=d.T.array)]),
        withElasticsearchRefs(elasticsearchRefs): { spec+: { monitoring+: { logs+: { elasticsearchRefs: if std.isArray(v=elasticsearchRefs) then elasticsearchRefs else [elasticsearchRefs] } } } },
        '#withElasticsearchRefsMixin':: d.fn(help='"ElasticsearchRefs is a reference to a list of monitoring Elasticsearch clusters running in the same Kubernetes cluster. Due to existing limitations, only a single Elasticsearch cluster is currently supported."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='elasticsearchRefs', type=d.T.array)]),
        withElasticsearchRefsMixin(elasticsearchRefs): { spec+: { monitoring+: { logs+: { elasticsearchRefs+: if std.isArray(v=elasticsearchRefs) then elasticsearchRefs else [elasticsearchRefs] } } } },
      },
      '#metrics':: d.obj(help='"Metrics holds references to Elasticsearch clusters which receive monitoring data from this Elasticsearch cluster."'),
      metrics: {
        '#elasticsearchRefs':: d.obj(help='"ElasticsearchRefs is a reference to a list of monitoring Elasticsearch clusters running in the same Kubernetes cluster. Due to existing limitations, only a single Elasticsearch cluster is currently supported."'),
        elasticsearchRefs: {
          '#withName':: d.fn(help='"Name of the Kubernetes object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withNamespace':: d.fn(help='"Namespace of the Kubernetes object. If empty, defaults to the current namespace."', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { namespace: namespace },
          '#withServiceName':: d.fn(help='"ServiceName is the name of an existing Kubernetes service which is used to make requests to the referenced object. It has to be in the same namespace as the referenced resource. If left empty, the default HTTP service of the referenced resource is used."', args=[d.arg(name='serviceName', type=d.T.string)]),
          withServiceName(serviceName): { serviceName: serviceName },
        },
        '#withElasticsearchRefs':: d.fn(help='"ElasticsearchRefs is a reference to a list of monitoring Elasticsearch clusters running in the same Kubernetes cluster. Due to existing limitations, only a single Elasticsearch cluster is currently supported."', args=[d.arg(name='elasticsearchRefs', type=d.T.array)]),
        withElasticsearchRefs(elasticsearchRefs): { spec+: { monitoring+: { metrics+: { elasticsearchRefs: if std.isArray(v=elasticsearchRefs) then elasticsearchRefs else [elasticsearchRefs] } } } },
        '#withElasticsearchRefsMixin':: d.fn(help='"ElasticsearchRefs is a reference to a list of monitoring Elasticsearch clusters running in the same Kubernetes cluster. Due to existing limitations, only a single Elasticsearch cluster is currently supported."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='elasticsearchRefs', type=d.T.array)]),
        withElasticsearchRefsMixin(elasticsearchRefs): { spec+: { monitoring+: { metrics+: { elasticsearchRefs+: if std.isArray(v=elasticsearchRefs) then elasticsearchRefs else [elasticsearchRefs] } } } },
      },
    },
    '#nodeSets':: d.obj(help='"NodeSets allow specifying groups of Elasticsearch nodes sharing the same configuration and Pod templates."'),
    nodeSets: {
      '#volumeClaimTemplates':: d.obj(help='"VolumeClaimTemplates is a list of persistent volume claims to be used by each Pod in this NodeSet. Every claim in this list must have a matching volumeMount in one of the containers defined in the PodTemplate. Items defined here take precedence over any default claims added by the operator with the same name."'),
      volumeClaimTemplates: {
        '#metadata':: d.obj(help="\"Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\""),
        metadata: {
          '#withAnnotations':: d.fn(help='', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotations(annotations): { metadata+: { annotations: annotations } },
          '#withAnnotationsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
          '#withFinalizers':: d.fn(help='', args=[d.arg(name='finalizers', type=d.T.array)]),
          withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
          '#withFinalizersMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
          withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
          '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { metadata+: { labels: labels } },
          '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { metadata+: { labels+: labels } },
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { metadata+: { name: name } },
          '#withNamespace':: d.fn(help='', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { metadata+: { namespace: namespace } },
        },
        '#spec':: d.obj(help='"Spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims"'),
        spec: {
          '#dataSource':: d.obj(help='"This field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) * An existing custom resource that implements data population (Alpha) In order to use custom resource types that implement data population, the AnyVolumeDataSource feature gate must be enabled. If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source."'),
          dataSource: {
            '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
            withApiGroup(apiGroup): { spec+: { dataSource+: { apiGroup: apiGroup } } },
            '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
            withKind(kind): { spec+: { dataSource+: { kind: kind } } },
            '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { dataSource+: { name: name } } },
          },
          '#resources':: d.obj(help='"Resources represents the minimum resources the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"'),
          resources: {
            '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
            withLimits(limits): { spec+: { resources+: { limits: limits } } },
            '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
            withLimitsMixin(limits): { spec+: { resources+: { limits+: limits } } },
            '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
            withRequests(requests): { spec+: { resources+: { requests: requests } } },
            '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
            withRequestsMixin(requests): { spec+: { resources+: { requests+: requests } } },
          },
          '#selector':: d.obj(help='"A label query over volumes to consider for binding."'),
          selector: {
            '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
            matchExpressions: {
              '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
              withOperator(operator): { operator: operator },
              '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
              withValues(values): { values: if std.isArray(v=values) then values else [values] },
              '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
              withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
            },
            '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
            withMatchExpressions(matchExpressions): { spec+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
            '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
            withMatchExpressionsMixin(matchExpressions): { spec+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
            '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabels(matchLabels): { spec+: { selector+: { matchLabels: matchLabels } } },
            '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabelsMixin(matchLabels): { spec+: { selector+: { matchLabels+: matchLabels } } },
          },
          '#withAccessModes':: d.fn(help='"AccessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"', args=[d.arg(name='accessModes', type=d.T.array)]),
          withAccessModes(accessModes): { spec+: { accessModes: if std.isArray(v=accessModes) then accessModes else [accessModes] } },
          '#withAccessModesMixin':: d.fn(help='"AccessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessModes', type=d.T.array)]),
          withAccessModesMixin(accessModes): { spec+: { accessModes+: if std.isArray(v=accessModes) then accessModes else [accessModes] } },
          '#withStorageClassName':: d.fn(help='"Name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1"', args=[d.arg(name='storageClassName', type=d.T.string)]),
          withStorageClassName(storageClassName): { spec+: { storageClassName: storageClassName } },
          '#withVolumeMode':: d.fn(help='"volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec."', args=[d.arg(name='volumeMode', type=d.T.string)]),
          withVolumeMode(volumeMode): { spec+: { volumeMode: volumeMode } },
          '#withVolumeName':: d.fn(help='"VolumeName is the binding reference to the PersistentVolume backing this claim."', args=[d.arg(name='volumeName', type=d.T.string)]),
          withVolumeName(volumeName): { spec+: { volumeName: volumeName } },
        },
        '#withApiVersion':: d.fn(help='"APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources"', args=[d.arg(name='apiVersion', type=d.T.string)]),
        withApiVersion(apiVersion): { apiVersion: apiVersion },
        '#withKind':: d.fn(help='"Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds"', args=[d.arg(name='kind', type=d.T.string)]),
        withKind(kind): { kind: kind },
      },
      '#withConfig':: d.fn(help='"Config holds the Elasticsearch configuration."', args=[d.arg(name='config', type=d.T.object)]),
      withConfig(config): { config: config },
      '#withConfigMixin':: d.fn(help='"Config holds the Elasticsearch configuration."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='config', type=d.T.object)]),
      withConfigMixin(config): { config+: config },
      '#withCount':: d.fn(help='"Count of Elasticsearch nodes to deploy. If the node set is managed by an autoscaling policy the initial value is automatically set by the autoscaling controller."', args=[d.arg(name='count', type=d.T.integer)]),
      withCount(count): { count: count },
      '#withName':: d.fn(help='"Name of this set of nodes. Becomes a part of the Elasticsearch node.name setting."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { name: name },
      '#withPodTemplate':: d.fn(help='"PodTemplate provides customisation options (labels, annotations, affinity rules, resource requests, and so on) for the Pods belonging to this NodeSet."', args=[d.arg(name='podTemplate', type=d.T.object)]),
      withPodTemplate(podTemplate): { podTemplate: podTemplate },
      '#withPodTemplateMixin':: d.fn(help='"PodTemplate provides customisation options (labels, annotations, affinity rules, resource requests, and so on) for the Pods belonging to this NodeSet."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='podTemplate', type=d.T.object)]),
      withPodTemplateMixin(podTemplate): { podTemplate+: podTemplate },
      '#withVolumeClaimTemplates':: d.fn(help='"VolumeClaimTemplates is a list of persistent volume claims to be used by each Pod in this NodeSet. Every claim in this list must have a matching volumeMount in one of the containers defined in the PodTemplate. Items defined here take precedence over any default claims added by the operator with the same name."', args=[d.arg(name='volumeClaimTemplates', type=d.T.array)]),
      withVolumeClaimTemplates(volumeClaimTemplates): { volumeClaimTemplates: if std.isArray(v=volumeClaimTemplates) then volumeClaimTemplates else [volumeClaimTemplates] },
      '#withVolumeClaimTemplatesMixin':: d.fn(help='"VolumeClaimTemplates is a list of persistent volume claims to be used by each Pod in this NodeSet. Every claim in this list must have a matching volumeMount in one of the containers defined in the PodTemplate. Items defined here take precedence over any default claims added by the operator with the same name."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumeClaimTemplates', type=d.T.array)]),
      withVolumeClaimTemplatesMixin(volumeClaimTemplates): { volumeClaimTemplates+: if std.isArray(v=volumeClaimTemplates) then volumeClaimTemplates else [volumeClaimTemplates] },
    },
    '#podDisruptionBudget':: d.obj(help='"PodDisruptionBudget provides access to the default pod disruption budget for the Elasticsearch cluster. The default budget selects all cluster pods and sets `maxUnavailable` to 1. To disable, set `PodDisruptionBudget` to the empty value (`{}` in YAML)."'),
    podDisruptionBudget: {
      '#metadata':: d.obj(help='"ObjectMeta is the metadata of the PDB. The name and namespace provided here are managed by ECK and will be ignored."'),
      metadata: {
        '#withAnnotations':: d.fn(help='', args=[d.arg(name='annotations', type=d.T.object)]),
        withAnnotations(annotations): { spec+: { podDisruptionBudget+: { metadata+: { annotations: annotations } } } },
        '#withAnnotationsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
        withAnnotationsMixin(annotations): { spec+: { podDisruptionBudget+: { metadata+: { annotations+: annotations } } } },
        '#withFinalizers':: d.fn(help='', args=[d.arg(name='finalizers', type=d.T.array)]),
        withFinalizers(finalizers): { spec+: { podDisruptionBudget+: { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } } } },
        '#withFinalizersMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
        withFinalizersMixin(finalizers): { spec+: { podDisruptionBudget+: { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } } } },
        '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
        withLabels(labels): { spec+: { podDisruptionBudget+: { metadata+: { labels: labels } } } },
        '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
        withLabelsMixin(labels): { spec+: { podDisruptionBudget+: { metadata+: { labels+: labels } } } },
        '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { podDisruptionBudget+: { metadata+: { name: name } } } },
        '#withNamespace':: d.fn(help='', args=[d.arg(name='namespace', type=d.T.string)]),
        withNamespace(namespace): { spec+: { podDisruptionBudget+: { metadata+: { namespace: namespace } } } },
      },
      '#spec':: d.obj(help='"Spec is the specification of the PDB."'),
      spec: {
        '#selector':: d.obj(help='"Label query over pods whose evictions are managed by the disruption budget. A null selector selects no pods. An empty selector ({}) also selects no pods, which differs from standard behavior of selecting all pods. In policy/v1, an empty selector will select all pods in the namespace."'),
        selector: {
          '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
          matchExpressions: {
            '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { operator: operator },
            '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
            withValues(values): { values: if std.isArray(v=values) then values else [values] },
            '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
            withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
          },
          '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
          withMatchExpressions(matchExpressions): { spec+: { podDisruptionBudget+: { spec+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } },
          '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
          withMatchExpressionsMixin(matchExpressions): { spec+: { podDisruptionBudget+: { spec+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } },
          '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { spec+: { podDisruptionBudget+: { spec+: { selector+: { matchLabels: matchLabels } } } } },
          '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { spec+: { podDisruptionBudget+: { spec+: { selector+: { matchLabels+: matchLabels } } } } },
        },
        '#withMaxUnavailable':: d.fn(help='"An eviction is allowed if at most \\"maxUnavailable\\" pods selected by \\"selector\\" are unavailable after the eviction, i.e. even in absence of the evicted pod. For example, one can prevent all voluntary evictions by specifying 0. This is a mutually exclusive setting with \\"minAvailable\\"."', args=[d.arg(name='maxUnavailable', type=d.T.any)]),
        withMaxUnavailable(maxUnavailable): { spec+: { podDisruptionBudget+: { spec+: { maxUnavailable: maxUnavailable } } } },
        '#withMinAvailable':: d.fn(help='"An eviction is allowed if at least \\"minAvailable\\" pods selected by \\"selector\\" will still be available after the eviction, i.e. even in the absence of the evicted pod.  So for example you can prevent all voluntary evictions by specifying \\"100%\\"."', args=[d.arg(name='minAvailable', type=d.T.any)]),
        withMinAvailable(minAvailable): { spec+: { podDisruptionBudget+: { spec+: { minAvailable: minAvailable } } } },
      },
    },
    '#remoteClusters':: d.obj(help='"RemoteClusters enables you to establish uni-directional connections to a remote Elasticsearch cluster."'),
    remoteClusters: {
      '#elasticsearchRef':: d.obj(help='"ElasticsearchRef is a reference to an Elasticsearch cluster running within the same k8s cluster."'),
      elasticsearchRef: {
        '#withName':: d.fn(help='"Name of the Kubernetes object."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { elasticsearchRef+: { name: name } },
        '#withNamespace':: d.fn(help='"Namespace of the Kubernetes object. If empty, defaults to the current namespace."', args=[d.arg(name='namespace', type=d.T.string)]),
        withNamespace(namespace): { elasticsearchRef+: { namespace: namespace } },
        '#withServiceName':: d.fn(help='"ServiceName is the name of an existing Kubernetes service which is used to make requests to the referenced object. It has to be in the same namespace as the referenced resource. If left empty, the default HTTP service of the referenced resource is used."', args=[d.arg(name='serviceName', type=d.T.string)]),
        withServiceName(serviceName): { elasticsearchRef+: { serviceName: serviceName } },
      },
      '#withName':: d.fn(help='"Name is the name of the remote cluster as it is set in the Elasticsearch settings. The name is expected to be unique for each remote clusters."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { name: name },
    },
    '#secureSettings':: d.obj(help='"SecureSettings is a list of references to Kubernetes secrets containing sensitive configuration options for Elasticsearch."'),
    secureSettings: {
      '#entries':: d.obj(help='"Entries define how to project each key-value pair in the secret to filesystem paths. If not defined, all keys will be projected to similarly named paths in the filesystem. If defined, only the specified keys will be projected to the corresponding paths."'),
      entries: {
        '#withKey':: d.fn(help='"Key is the key contained in the secret."', args=[d.arg(name='key', type=d.T.string)]),
        withKey(key): { key: key },
        '#withPath':: d.fn(help='"Path is the relative file path to map the key to. Path must not be an absolute file path and must not contain any \\"..\\" components."', args=[d.arg(name='path', type=d.T.string)]),
        withPath(path): { path: path },
      },
      '#withEntries':: d.fn(help='"Entries define how to project each key-value pair in the secret to filesystem paths. If not defined, all keys will be projected to similarly named paths in the filesystem. If defined, only the specified keys will be projected to the corresponding paths."', args=[d.arg(name='entries', type=d.T.array)]),
      withEntries(entries): { entries: if std.isArray(v=entries) then entries else [entries] },
      '#withEntriesMixin':: d.fn(help='"Entries define how to project each key-value pair in the secret to filesystem paths. If not defined, all keys will be projected to similarly named paths in the filesystem. If defined, only the specified keys will be projected to the corresponding paths."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='entries', type=d.T.array)]),
      withEntriesMixin(entries): { entries+: if std.isArray(v=entries) then entries else [entries] },
      '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
      withSecretName(secretName): { secretName: secretName },
    },
    '#transport':: d.obj(help='"Transport holds transport layer settings for Elasticsearch."'),
    transport: {
      '#service':: d.obj(help='"Service defines the template for the associated Kubernetes Service object."'),
      service: {
        '#metadata':: d.obj(help='"ObjectMeta is the metadata of the service. The name and namespace provided here are managed by ECK and will be ignored."'),
        metadata: {
          '#withAnnotations':: d.fn(help='', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotations(annotations): { spec+: { transport+: { service+: { metadata+: { annotations: annotations } } } } },
          '#withAnnotationsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotationsMixin(annotations): { spec+: { transport+: { service+: { metadata+: { annotations+: annotations } } } } },
          '#withFinalizers':: d.fn(help='', args=[d.arg(name='finalizers', type=d.T.array)]),
          withFinalizers(finalizers): { spec+: { transport+: { service+: { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } } } } },
          '#withFinalizersMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
          withFinalizersMixin(finalizers): { spec+: { transport+: { service+: { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } } } } },
          '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { spec+: { transport+: { service+: { metadata+: { labels: labels } } } } },
          '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { spec+: { transport+: { service+: { metadata+: { labels+: labels } } } } },
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { transport+: { service+: { metadata+: { name: name } } } } },
          '#withNamespace':: d.fn(help='', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { spec+: { transport+: { service+: { metadata+: { namespace: namespace } } } } },
        },
        '#spec':: d.obj(help='"Spec is the specification of the service."'),
        spec: {
          '#ports':: d.obj(help='"The list of ports that are exposed by this service. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"'),
          ports: {
            '#withAppProtocol':: d.fn(help='"The application protocol for this port. This field follows standard Kubernetes label syntax. Un-prefixed names are reserved for IANA standard service names (as per RFC-6335 and http://www.iana.org/assignments/service-names). Non-standard protocols should use prefixed names such as mycompany.com/my-custom-protocol. This is a beta field that is guarded by the ServiceAppProtocol feature gate and enabled by default."', args=[d.arg(name='appProtocol', type=d.T.string)]),
            withAppProtocol(appProtocol): { appProtocol: appProtocol },
            '#withName':: d.fn(help="\"The name of this port within the service. This must be a DNS_LABEL. All ports within a ServiceSpec must have unique names. When considering the endpoints for a Service, this must match the 'name' field in the EndpointPort. Optional if only one ServicePort is defined on this service.\"", args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withNodePort':: d.fn(help='"The port on each node on which this service is exposed when type is NodePort or LoadBalancer.  Usually assigned by the system. If a value is specified, in-range, and not in use it will be used, otherwise the operation will fail.  If not specified, a port will be allocated if this Service requires one.  If this field is specified when creating a Service which does not need it, creation will fail. This field will be wiped when updating a Service to no longer need it (e.g. changing type from NodePort to ClusterIP). More info: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport"', args=[d.arg(name='nodePort', type=d.T.integer)]),
            withNodePort(nodePort): { nodePort: nodePort },
            '#withPort':: d.fn(help='"The port that will be exposed by this service."', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { port: port },
            '#withProtocol':: d.fn(help='"The IP protocol for this port. Supports \\"TCP\\", \\"UDP\\", and \\"SCTP\\". Default is TCP."', args=[d.arg(name='protocol', type=d.T.string)]),
            withProtocol(protocol): { protocol: protocol },
            '#withTargetPort':: d.fn(help="\"Number or name of the port to access on the pods targeted by the service. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. If this is a string, it will be looked up as a named port in the target Pod's container ports. If this is not specified, the value of the 'port' field is used (an identity map). This field is ignored for services with clusterIP=None, and should be omitted or set equal to the 'port' field. More info: https://kubernetes.io/docs/concepts/services-networking/service/#defining-a-service\"", args=[d.arg(name='targetPort', type=d.T.any)]),
            withTargetPort(targetPort): { targetPort: targetPort },
          },
          '#sessionAffinityConfig':: d.obj(help='"sessionAffinityConfig contains the configurations of session affinity."'),
          sessionAffinityConfig: {
            '#clientIP':: d.obj(help='"clientIP contains the configurations of Client IP based session affinity."'),
            clientIP: {
              '#withTimeoutSeconds':: d.fn(help='"timeoutSeconds specifies the seconds of ClientIP type session sticky time. The value must be >0 && <=86400(for 1 day) if ServiceAffinity == \\"ClientIP\\". Default value is 10800(for 3 hours)."', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
              withTimeoutSeconds(timeoutSeconds): { spec+: { transport+: { service+: { spec+: { sessionAffinityConfig+: { clientIP+: { timeoutSeconds: timeoutSeconds } } } } } } },
            },
          },
          '#withAllocateLoadBalancerNodePorts':: d.fn(help='"allocateLoadBalancerNodePorts defines if NodePorts will be automatically allocated for services with type LoadBalancer.  Default is \\"true\\". It may be set to \\"false\\" if the cluster load-balancer does not rely on NodePorts. allocateLoadBalancerNodePorts may only be set for services with type LoadBalancer and will be cleared if the type is changed to any other type. This field is alpha-level and is only honored by servers that enable the ServiceLBNodePortControl feature."', args=[d.arg(name='allocateLoadBalancerNodePorts', type=d.T.boolean)]),
          withAllocateLoadBalancerNodePorts(allocateLoadBalancerNodePorts): { spec+: { transport+: { service+: { spec+: { allocateLoadBalancerNodePorts: allocateLoadBalancerNodePorts } } } } },
          '#withClusterIP':: d.fn(help='"clusterIP is the IP address of the service and is usually assigned randomly. If an address is specified manually, is in-range (as per system configuration), and is not in use, it will be allocated to the service; otherwise creation of the service will fail. This field may not be changed through updates unless the type field is also being changed to ExternalName (which requires this field to be blank) or the type field is being changed from ExternalName (in which case this field may optionally be specified, as describe above).  Valid values are \\"None\\", empty string (\\"\\"), or a valid IP address. Setting this to \\"None\\" makes a \\"headless service\\" (no virtual IP), which is useful when direct endpoint connections are preferred and proxying is not required.  Only applies to types ClusterIP, NodePort, and LoadBalancer. If this field is specified when creating a Service of type ExternalName, creation will fail. This field will be wiped when updating a Service to type ExternalName. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"', args=[d.arg(name='clusterIP', type=d.T.string)]),
          withClusterIP(clusterIP): { spec+: { transport+: { service+: { spec+: { clusterIP: clusterIP } } } } },
          '#withClusterIPs':: d.fn(help='"ClusterIPs is a list of IP addresses assigned to this service, and are usually assigned randomly.  If an address is specified manually, is in-range (as per system configuration), and is not in use, it will be allocated to the service; otherwise creation of the service will fail. This field may not be changed through updates unless the type field is also being changed to ExternalName (which requires this field to be empty) or the type field is being changed from ExternalName (in which case this field may optionally be specified, as describe above).  Valid values are \\"None\\", empty string (\\"\\"), or a valid IP address.  Setting this to \\"None\\" makes a \\"headless service\\" (no virtual IP), which is useful when direct endpoint connections are preferred and proxying is not required.  Only applies to types ClusterIP, NodePort, and LoadBalancer. If this field is specified when creating a Service of type ExternalName, creation will fail. This field will be wiped when updating a Service to type ExternalName.  If this field is not specified, it will be initialized from the clusterIP field.  If this field is specified, clients must ensure that clusterIPs[0] and clusterIP have the same value. \\n Unless the \\"IPv6DualStack\\" feature gate is enabled, this field is limited to one value, which must be the same as the clusterIP field.  If the feature gate is enabled, this field may hold a maximum of two entries (dual-stack IPs, in either order).  These IPs must correspond to the values of the ipFamilies field. Both clusterIPs and ipFamilies are governed by the ipFamilyPolicy field. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"', args=[d.arg(name='clusterIPs', type=d.T.array)]),
          withClusterIPs(clusterIPs): { spec+: { transport+: { service+: { spec+: { clusterIPs: if std.isArray(v=clusterIPs) then clusterIPs else [clusterIPs] } } } } },
          '#withClusterIPsMixin':: d.fn(help='"ClusterIPs is a list of IP addresses assigned to this service, and are usually assigned randomly.  If an address is specified manually, is in-range (as per system configuration), and is not in use, it will be allocated to the service; otherwise creation of the service will fail. This field may not be changed through updates unless the type field is also being changed to ExternalName (which requires this field to be empty) or the type field is being changed from ExternalName (in which case this field may optionally be specified, as describe above).  Valid values are \\"None\\", empty string (\\"\\"), or a valid IP address.  Setting this to \\"None\\" makes a \\"headless service\\" (no virtual IP), which is useful when direct endpoint connections are preferred and proxying is not required.  Only applies to types ClusterIP, NodePort, and LoadBalancer. If this field is specified when creating a Service of type ExternalName, creation will fail. This field will be wiped when updating a Service to type ExternalName.  If this field is not specified, it will be initialized from the clusterIP field.  If this field is specified, clients must ensure that clusterIPs[0] and clusterIP have the same value. \\n Unless the \\"IPv6DualStack\\" feature gate is enabled, this field is limited to one value, which must be the same as the clusterIP field.  If the feature gate is enabled, this field may hold a maximum of two entries (dual-stack IPs, in either order).  These IPs must correspond to the values of the ipFamilies field. Both clusterIPs and ipFamilies are governed by the ipFamilyPolicy field. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='clusterIPs', type=d.T.array)]),
          withClusterIPsMixin(clusterIPs): { spec+: { transport+: { service+: { spec+: { clusterIPs+: if std.isArray(v=clusterIPs) then clusterIPs else [clusterIPs] } } } } },
          '#withExternalIPs':: d.fn(help='"externalIPs is a list of IP addresses for which nodes in the cluster will also accept traffic for this service.  These IPs are not managed by Kubernetes.  The user is responsible for ensuring that traffic arrives at a node with this IP.  A common example is external load-balancers that are not part of the Kubernetes system."', args=[d.arg(name='externalIPs', type=d.T.array)]),
          withExternalIPs(externalIPs): { spec+: { transport+: { service+: { spec+: { externalIPs: if std.isArray(v=externalIPs) then externalIPs else [externalIPs] } } } } },
          '#withExternalIPsMixin':: d.fn(help='"externalIPs is a list of IP addresses for which nodes in the cluster will also accept traffic for this service.  These IPs are not managed by Kubernetes.  The user is responsible for ensuring that traffic arrives at a node with this IP.  A common example is external load-balancers that are not part of the Kubernetes system."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='externalIPs', type=d.T.array)]),
          withExternalIPsMixin(externalIPs): { spec+: { transport+: { service+: { spec+: { externalIPs+: if std.isArray(v=externalIPs) then externalIPs else [externalIPs] } } } } },
          '#withExternalName':: d.fn(help='"externalName is the external reference that discovery mechanisms will return as an alias for this service (e.g. a DNS CNAME record). No proxying will be involved.  Must be a lowercase RFC-1123 hostname (https://tools.ietf.org/html/rfc1123) and requires `type` to be \\"ExternalName\\"."', args=[d.arg(name='externalName', type=d.T.string)]),
          withExternalName(externalName): { spec+: { transport+: { service+: { spec+: { externalName: externalName } } } } },
          '#withExternalTrafficPolicy':: d.fn(help='"externalTrafficPolicy denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints. \\"Local\\" preserves the client source IP and avoids a second hop for LoadBalancer and Nodeport type services, but risks potentially imbalanced traffic spreading. \\"Cluster\\" obscures the client source IP and may cause a second hop to another node, but should have good overall load-spreading."', args=[d.arg(name='externalTrafficPolicy', type=d.T.string)]),
          withExternalTrafficPolicy(externalTrafficPolicy): { spec+: { transport+: { service+: { spec+: { externalTrafficPolicy: externalTrafficPolicy } } } } },
          '#withHealthCheckNodePort':: d.fn(help='"healthCheckNodePort specifies the healthcheck nodePort for the service. This only applies when type is set to LoadBalancer and externalTrafficPolicy is set to Local. If a value is specified, is in-range, and is not in use, it will be used.  If not specified, a value will be automatically allocated.  External systems (e.g. load-balancers) can use this port to determine if a given node holds endpoints for this service or not.  If this field is specified when creating a Service which does not need it, creation will fail. This field will be wiped when updating a Service to no longer need it (e.g. changing type)."', args=[d.arg(name='healthCheckNodePort', type=d.T.integer)]),
          withHealthCheckNodePort(healthCheckNodePort): { spec+: { transport+: { service+: { spec+: { healthCheckNodePort: healthCheckNodePort } } } } },
          '#withInternalTrafficPolicy':: d.fn(help='"InternalTrafficPolicy specifies if the cluster internal traffic should be routed to all endpoints or node-local endpoints only. \\"Cluster\\" routes internal traffic to a Service to all endpoints. \\"Local\\" routes traffic to node-local endpoints only, traffic is dropped if no node-local endpoints are ready. The default value is \\"Cluster\\"."', args=[d.arg(name='internalTrafficPolicy', type=d.T.string)]),
          withInternalTrafficPolicy(internalTrafficPolicy): { spec+: { transport+: { service+: { spec+: { internalTrafficPolicy: internalTrafficPolicy } } } } },
          '#withIpFamilies':: d.fn(help='"IPFamilies is a list of IP families (e.g. IPv4, IPv6) assigned to this service, and is gated by the \\"IPv6DualStack\\" feature gate.  This field is usually assigned automatically based on cluster configuration and the ipFamilyPolicy field. If this field is specified manually, the requested family is available in the cluster, and ipFamilyPolicy allows it, it will be used; otherwise creation of the service will fail.  This field is conditionally mutable: it allows for adding or removing a secondary IP family, but it does not allow changing the primary IP family of the Service.  Valid values are \\"IPv4\\" and \\"IPv6\\".  This field only applies to Services of types ClusterIP, NodePort, and LoadBalancer, and does apply to \\"headless\\" services.  This field will be wiped when updating a Service to type ExternalName. \\n This field may hold a maximum of two entries (dual-stack families, in either order).  These families must correspond to the values of the clusterIPs field, if specified. Both clusterIPs and ipFamilies are governed by the ipFamilyPolicy field."', args=[d.arg(name='ipFamilies', type=d.T.array)]),
          withIpFamilies(ipFamilies): { spec+: { transport+: { service+: { spec+: { ipFamilies: if std.isArray(v=ipFamilies) then ipFamilies else [ipFamilies] } } } } },
          '#withIpFamiliesMixin':: d.fn(help='"IPFamilies is a list of IP families (e.g. IPv4, IPv6) assigned to this service, and is gated by the \\"IPv6DualStack\\" feature gate.  This field is usually assigned automatically based on cluster configuration and the ipFamilyPolicy field. If this field is specified manually, the requested family is available in the cluster, and ipFamilyPolicy allows it, it will be used; otherwise creation of the service will fail.  This field is conditionally mutable: it allows for adding or removing a secondary IP family, but it does not allow changing the primary IP family of the Service.  Valid values are \\"IPv4\\" and \\"IPv6\\".  This field only applies to Services of types ClusterIP, NodePort, and LoadBalancer, and does apply to \\"headless\\" services.  This field will be wiped when updating a Service to type ExternalName. \\n This field may hold a maximum of two entries (dual-stack families, in either order).  These families must correspond to the values of the clusterIPs field, if specified. Both clusterIPs and ipFamilies are governed by the ipFamilyPolicy field."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ipFamilies', type=d.T.array)]),
          withIpFamiliesMixin(ipFamilies): { spec+: { transport+: { service+: { spec+: { ipFamilies+: if std.isArray(v=ipFamilies) then ipFamilies else [ipFamilies] } } } } },
          '#withIpFamilyPolicy':: d.fn(help='"IPFamilyPolicy represents the dual-stack-ness requested or required by this Service, and is gated by the \\"IPv6DualStack\\" feature gate.  If there is no value provided, then this field will be set to SingleStack. Services can be \\"SingleStack\\" (a single IP family), \\"PreferDualStack\\" (two IP families on dual-stack configured clusters or a single IP family on single-stack clusters), or \\"RequireDualStack\\" (two IP families on dual-stack configured clusters, otherwise fail). The ipFamilies and clusterIPs fields depend on the value of this field.  This field will be wiped when updating a service to type ExternalName."', args=[d.arg(name='ipFamilyPolicy', type=d.T.string)]),
          withIpFamilyPolicy(ipFamilyPolicy): { spec+: { transport+: { service+: { spec+: { ipFamilyPolicy: ipFamilyPolicy } } } } },
          '#withLoadBalancerClass':: d.fn(help="\"loadBalancerClass is the class of the load balancer implementation this Service belongs to. If specified, the value of this field must be a label-style identifier, with an optional prefix, e.g. \\\"internal-vip\\\" or \\\"example.com/internal-vip\\\". Unprefixed names are reserved for end-users. This field can only be set when the Service type is 'LoadBalancer'. If not set, the default load balancer implementation is used, today this is typically done through the cloud provider integration, but should apply for any default implementation. If set, it is assumed that a load balancer implementation is watching for Services with a matching class. Any default load balancer implementation (e.g. cloud providers) should ignore Services that set this field. This field can only be set when creating or updating a Service to type 'LoadBalancer'. Once set, it can not be changed. This field will be wiped when a service is updated to a non 'LoadBalancer' type.\"", args=[d.arg(name='loadBalancerClass', type=d.T.string)]),
          withLoadBalancerClass(loadBalancerClass): { spec+: { transport+: { service+: { spec+: { loadBalancerClass: loadBalancerClass } } } } },
          '#withLoadBalancerIP':: d.fn(help='"Only applies to Service Type: LoadBalancer LoadBalancer will get created with the IP specified in this field. This feature depends on whether the underlying cloud-provider supports specifying the loadBalancerIP when a load balancer is created. This field will be ignored if the cloud-provider does not support the feature."', args=[d.arg(name='loadBalancerIP', type=d.T.string)]),
          withLoadBalancerIP(loadBalancerIP): { spec+: { transport+: { service+: { spec+: { loadBalancerIP: loadBalancerIP } } } } },
          '#withLoadBalancerSourceRanges':: d.fn(help='"If specified and supported by the platform, this will restrict traffic through the cloud-provider load-balancer will be restricted to the specified client IPs. This field will be ignored if the cloud-provider does not support the feature.\\" More info: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/"', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
          withLoadBalancerSourceRanges(loadBalancerSourceRanges): { spec+: { transport+: { service+: { spec+: { loadBalancerSourceRanges: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } } } },
          '#withLoadBalancerSourceRangesMixin':: d.fn(help='"If specified and supported by the platform, this will restrict traffic through the cloud-provider load-balancer will be restricted to the specified client IPs. This field will be ignored if the cloud-provider does not support the feature.\\" More info: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
          withLoadBalancerSourceRangesMixin(loadBalancerSourceRanges): { spec+: { transport+: { service+: { spec+: { loadBalancerSourceRanges+: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } } } },
          '#withPorts':: d.fn(help='"The list of ports that are exposed by this service. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"', args=[d.arg(name='ports', type=d.T.array)]),
          withPorts(ports): { spec+: { transport+: { service+: { spec+: { ports: if std.isArray(v=ports) then ports else [ports] } } } } },
          '#withPortsMixin':: d.fn(help='"The list of ports that are exposed by this service. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ports', type=d.T.array)]),
          withPortsMixin(ports): { spec+: { transport+: { service+: { spec+: { ports+: if std.isArray(v=ports) then ports else [ports] } } } } },
          '#withPublishNotReadyAddresses':: d.fn(help="\"publishNotReadyAddresses indicates that any agent which deals with endpoints for this Service should disregard any indications of ready/not-ready. The primary use case for setting this field is for a StatefulSet's Headless Service to propagate SRV DNS records for its Pods for the purpose of peer discovery. The Kubernetes controllers that generate Endpoints and EndpointSlice resources for Services interpret this to mean that all endpoints are considered \\\"ready\\\" even if the Pods themselves are not. Agents which consume only Kubernetes generated endpoints through the Endpoints or EndpointSlice resources can safely assume this behavior.\"", args=[d.arg(name='publishNotReadyAddresses', type=d.T.boolean)]),
          withPublishNotReadyAddresses(publishNotReadyAddresses): { spec+: { transport+: { service+: { spec+: { publishNotReadyAddresses: publishNotReadyAddresses } } } } },
          '#withSelector':: d.fn(help='"Route service traffic to pods with label keys and values matching this selector. If empty or not present, the service is assumed to have an external process managing its endpoints, which Kubernetes will not modify. Only applies to types ClusterIP, NodePort, and LoadBalancer. Ignored if type is ExternalName. More info: https://kubernetes.io/docs/concepts/services-networking/service/"', args=[d.arg(name='selector', type=d.T.object)]),
          withSelector(selector): { spec+: { transport+: { service+: { spec+: { selector: selector } } } } },
          '#withSelectorMixin':: d.fn(help='"Route service traffic to pods with label keys and values matching this selector. If empty or not present, the service is assumed to have an external process managing its endpoints, which Kubernetes will not modify. Only applies to types ClusterIP, NodePort, and LoadBalancer. Ignored if type is ExternalName. More info: https://kubernetes.io/docs/concepts/services-networking/service/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='selector', type=d.T.object)]),
          withSelectorMixin(selector): { spec+: { transport+: { service+: { spec+: { selector+: selector } } } } },
          '#withSessionAffinity':: d.fn(help='"Supports \\"ClientIP\\" and \\"None\\". Used to maintain session affinity. Enable client IP based session affinity. Must be ClientIP or None. Defaults to None. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"', args=[d.arg(name='sessionAffinity', type=d.T.string)]),
          withSessionAffinity(sessionAffinity): { spec+: { transport+: { service+: { spec+: { sessionAffinity: sessionAffinity } } } } },
          '#withTopologyKeys':: d.fn(help='"topologyKeys is a preference-order list of topology keys which implementations of services should use to preferentially sort endpoints when accessing this Service, it can not be used at the same time as externalTrafficPolicy=Local. Topology keys must be valid label keys and at most 16 keys may be specified. Endpoints are chosen based on the first topology key with available backends. If this field is specified and all entries have no backends that match the topology of the client, the service has no backends for that client and connections should fail. The special value \\"*\\" may be used to mean \\"any topology\\". This catch-all value, if used, only makes sense as the last value in the list. If this is not specified or empty, no topology constraints will be applied. This field is alpha-level and is only honored by servers that enable the ServiceTopology feature. This field is deprecated and will be removed in a future version."', args=[d.arg(name='topologyKeys', type=d.T.array)]),
          withTopologyKeys(topologyKeys): { spec+: { transport+: { service+: { spec+: { topologyKeys: if std.isArray(v=topologyKeys) then topologyKeys else [topologyKeys] } } } } },
          '#withTopologyKeysMixin':: d.fn(help='"topologyKeys is a preference-order list of topology keys which implementations of services should use to preferentially sort endpoints when accessing this Service, it can not be used at the same time as externalTrafficPolicy=Local. Topology keys must be valid label keys and at most 16 keys may be specified. Endpoints are chosen based on the first topology key with available backends. If this field is specified and all entries have no backends that match the topology of the client, the service has no backends for that client and connections should fail. The special value \\"*\\" may be used to mean \\"any topology\\". This catch-all value, if used, only makes sense as the last value in the list. If this is not specified or empty, no topology constraints will be applied. This field is alpha-level and is only honored by servers that enable the ServiceTopology feature. This field is deprecated and will be removed in a future version."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='topologyKeys', type=d.T.array)]),
          withTopologyKeysMixin(topologyKeys): { spec+: { transport+: { service+: { spec+: { topologyKeys+: if std.isArray(v=topologyKeys) then topologyKeys else [topologyKeys] } } } } },
          '#withType':: d.fn(help='"type determines how the Service is exposed. Defaults to ClusterIP. Valid options are ExternalName, ClusterIP, NodePort, and LoadBalancer. \\"ClusterIP\\" allocates a cluster-internal IP address for load-balancing to endpoints. Endpoints are determined by the selector or if that is not specified, by manual construction of an Endpoints object or EndpointSlice objects. If clusterIP is \\"None\\", no virtual IP is allocated and the endpoints are published as a set of endpoints rather than a virtual IP. \\"NodePort\\" builds on ClusterIP and allocates a port on every node which routes to the same endpoints as the clusterIP. \\"LoadBalancer\\" builds on NodePort and creates an external load-balancer (if supported in the current cloud) which routes to the same endpoints as the clusterIP. \\"ExternalName\\" aliases this service to the specified externalName. Several other fields do not apply to ExternalName services. More info: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types"', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { transport+: { service+: { spec+: { type: type } } } } },
        },
      },
      '#tls':: d.obj(help='"TLS defines options for configuring TLS on the transport layer."'),
      tls: {
        '#certificate':: d.obj(help='"Certificate is a reference to a Kubernetes secret that contains the CA certificate and private key for generating node certificates. The referenced secret should contain the following: \\n - `ca.crt`: The CA certificate in PEM format. - `ca.key`: The private key for the CA certificate in PEM format."'),
        certificate: {
          '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
          withSecretName(secretName): { spec+: { transport+: { tls+: { certificate+: { secretName: secretName } } } } },
        },
        '#subjectAltNames':: d.obj(help='"SubjectAlternativeNames is a list of SANs to include in the generated node transport TLS certificates."'),
        subjectAltNames: {
          '#withDns':: d.fn(help='"DNS is the DNS name of the subject."', args=[d.arg(name='dns', type=d.T.string)]),
          withDns(dns): { dns: dns },
          '#withIp':: d.fn(help='"IP is the IP address of the subject."', args=[d.arg(name='ip', type=d.T.string)]),
          withIp(ip): { ip: ip },
        },
        '#withSubjectAltNames':: d.fn(help='"SubjectAlternativeNames is a list of SANs to include in the generated node transport TLS certificates."', args=[d.arg(name='subjectAltNames', type=d.T.array)]),
        withSubjectAltNames(subjectAltNames): { spec+: { transport+: { tls+: { subjectAltNames: if std.isArray(v=subjectAltNames) then subjectAltNames else [subjectAltNames] } } } },
        '#withSubjectAltNamesMixin':: d.fn(help='"SubjectAlternativeNames is a list of SANs to include in the generated node transport TLS certificates."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='subjectAltNames', type=d.T.array)]),
        withSubjectAltNamesMixin(subjectAltNames): { spec+: { transport+: { tls+: { subjectAltNames+: if std.isArray(v=subjectAltNames) then subjectAltNames else [subjectAltNames] } } } },
      },
    },
    '#updateStrategy':: d.obj(help='"UpdateStrategy specifies how updates to the cluster should be performed."'),
    updateStrategy: {
      '#changeBudget':: d.obj(help='"ChangeBudget defines the constraints to consider when applying changes to the Elasticsearch cluster."'),
      changeBudget: {
        '#withMaxSurge':: d.fn(help='"MaxSurge is the maximum number of new pods that can be created exceeding the original number of pods defined in the specification. MaxSurge is only taken into consideration when scaling up. Setting a negative value will disable the restriction. Defaults to unbounded if not specified."', args=[d.arg(name='maxSurge', type=d.T.integer)]),
        withMaxSurge(maxSurge): { spec+: { updateStrategy+: { changeBudget+: { maxSurge: maxSurge } } } },
        '#withMaxUnavailable':: d.fn(help='"MaxUnavailable is the maximum number of pods that can be unavailable (not ready) during the update due to circumstances under the control of the operator. Setting a negative value will disable this restriction. Defaults to 1 if not specified."', args=[d.arg(name='maxUnavailable', type=d.T.integer)]),
        withMaxUnavailable(maxUnavailable): { spec+: { updateStrategy+: { changeBudget+: { maxUnavailable: maxUnavailable } } } },
      },
    },
    '#withImage':: d.fn(help='"Image is the Elasticsearch Docker image to deploy."', args=[d.arg(name='image', type=d.T.string)]),
    withImage(image): { spec+: { image: image } },
    '#withNodeSets':: d.fn(help='"NodeSets allow specifying groups of Elasticsearch nodes sharing the same configuration and Pod templates."', args=[d.arg(name='nodeSets', type=d.T.array)]),
    withNodeSets(nodeSets): { spec+: { nodeSets: if std.isArray(v=nodeSets) then nodeSets else [nodeSets] } },
    '#withNodeSetsMixin':: d.fn(help='"NodeSets allow specifying groups of Elasticsearch nodes sharing the same configuration and Pod templates."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSets', type=d.T.array)]),
    withNodeSetsMixin(nodeSets): { spec+: { nodeSets+: if std.isArray(v=nodeSets) then nodeSets else [nodeSets] } },
    '#withRemoteClusters':: d.fn(help='"RemoteClusters enables you to establish uni-directional connections to a remote Elasticsearch cluster."', args=[d.arg(name='remoteClusters', type=d.T.array)]),
    withRemoteClusters(remoteClusters): { spec+: { remoteClusters: if std.isArray(v=remoteClusters) then remoteClusters else [remoteClusters] } },
    '#withRemoteClustersMixin':: d.fn(help='"RemoteClusters enables you to establish uni-directional connections to a remote Elasticsearch cluster."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='remoteClusters', type=d.T.array)]),
    withRemoteClustersMixin(remoteClusters): { spec+: { remoteClusters+: if std.isArray(v=remoteClusters) then remoteClusters else [remoteClusters] } },
    '#withSecureSettings':: d.fn(help='"SecureSettings is a list of references to Kubernetes secrets containing sensitive configuration options for Elasticsearch."', args=[d.arg(name='secureSettings', type=d.T.array)]),
    withSecureSettings(secureSettings): { spec+: { secureSettings: if std.isArray(v=secureSettings) then secureSettings else [secureSettings] } },
    '#withSecureSettingsMixin':: d.fn(help='"SecureSettings is a list of references to Kubernetes secrets containing sensitive configuration options for Elasticsearch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='secureSettings', type=d.T.array)]),
    withSecureSettingsMixin(secureSettings): { spec+: { secureSettings+: if std.isArray(v=secureSettings) then secureSettings else [secureSettings] } },
    '#withServiceAccountName':: d.fn(help='"ServiceAccountName is used to check access from the current resource to a resource (eg. a remote Elasticsearch cluster) in a different namespace. Can only be used if ECK is enforcing RBAC on references."', args=[d.arg(name='serviceAccountName', type=d.T.string)]),
    withServiceAccountName(serviceAccountName): { spec+: { serviceAccountName: serviceAccountName } },
    '#withVersion':: d.fn(help='"Version of Elasticsearch."', args=[d.arg(name='version', type=d.T.string)]),
    withVersion(version): { spec+: { version: version } },
    '#withVolumeClaimDeletePolicy':: d.fn(help='"VolumeClaimDeletePolicy sets the policy for handling deletion of PersistentVolumeClaims for all NodeSets. Possible values are DeleteOnScaledownOnly and DeleteOnScaledownAndClusterDeletion. Defaults to DeleteOnScaledownAndClusterDeletion."', args=[d.arg(name='volumeClaimDeletePolicy', type=d.T.string)]),
    withVolumeClaimDeletePolicy(volumeClaimDeletePolicy): { spec+: { volumeClaimDeletePolicy: volumeClaimDeletePolicy } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
