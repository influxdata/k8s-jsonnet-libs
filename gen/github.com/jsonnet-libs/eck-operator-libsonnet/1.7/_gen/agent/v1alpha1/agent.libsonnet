{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='agent', url='', help='"Agent is the Schema for the Agents API."'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of Agent', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'agent.k8s.elastic.co/v1alpha1',
    kind: 'Agent',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help='"AgentSpec defines the desired state of the Agent"'),
  spec: {
    '#configRef':: d.obj(help='"ConfigRef contains a reference to an existing Kubernetes Secret holding the Agent configuration. Agent settings must be specified as yaml, under a single \\"agent.yml\\" entry. At most one of [`Config`, `ConfigRef`] can be specified."'),
    configRef: {
      '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
      withSecretName(secretName): { spec+: { configRef+: { secretName: secretName } } },
    },
    '#daemonSet':: d.obj(help='"DaemonSet specifies the Agent should be deployed as a DaemonSet, and allows providing its spec. Cannot be used along with `deployment`."'),
    daemonSet: {
      '#updateStrategy':: d.obj(help='"DaemonSetUpdateStrategy is a struct used to control the update strategy for a DaemonSet."'),
      updateStrategy: {
        '#rollingUpdate':: d.obj(help='"Rolling update config params. Present only if type = \\"RollingUpdate\\". --- TODO: Update this to follow our convention for oneOf, whatever we decide it to be. Same as Deployment `strategy.rollingUpdate`. See https://github.com/kubernetes/kubernetes/issues/35345"'),
        rollingUpdate: {
          '#withMaxSurge':: d.fn(help='"The maximum number of nodes with an existing available DaemonSet pod that can have an updated DaemonSet pod during during an update. Value can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%). This can not be 0 if MaxUnavailable is 0. Absolute number is calculated from percentage by rounding up to a minimum of 1. Default value is 0. Example: when this is set to 30%, at most 30% of the total number of nodes that should be running the daemon pod (i.e. status.desiredNumberScheduled) can have their a new pod created before the old pod is marked as deleted. The update starts by launching new pods on 30% of nodes. Once an updated pod is available (Ready for at least minReadySeconds) the old DaemonSet pod on that node is marked deleted. If the old pod becomes unavailable for any reason (Ready transitions to false, is evicted, or is drained) an updated pod is immediatedly created on that node without considering surge limits. Allowing surge implies the possibility that the resources consumed by the daemonset on any given node can double if the readiness check fails, and so resource intensive daemonsets should take into account that they may cause evictions during disruption. This is an alpha field and requires enabling DaemonSetUpdateSurge feature gate."', args=[d.arg(name='maxSurge', type=d.T.any)]),
          withMaxSurge(maxSurge): { spec+: { daemonSet+: { updateStrategy+: { rollingUpdate+: { maxSurge: maxSurge } } } } },
          '#withMaxUnavailable':: d.fn(help='"The maximum number of DaemonSet pods that can be unavailable during the update. Value can be an absolute number (ex: 5) or a percentage of total number of DaemonSet pods at the start of the update (ex: 10%). Absolute number is calculated from percentage by rounding down to a minimum of one. This cannot be 0 if MaxSurge is 0 Default value is 1. Example: when this is set to 30%, at most 30% of the total number of nodes that should be running the daemon pod (i.e. status.desiredNumberScheduled) can have their pods stopped for an update at any given time. The update starts by stopping at most 30% of those DaemonSet pods and then brings up new DaemonSet pods in their place. Once the new pods are available, it then proceeds onto other DaemonSet pods, thus ensuring that at least 70% of original number of DaemonSet pods are available at all times during the update."', args=[d.arg(name='maxUnavailable', type=d.T.any)]),
          withMaxUnavailable(maxUnavailable): { spec+: { daemonSet+: { updateStrategy+: { rollingUpdate+: { maxUnavailable: maxUnavailable } } } } },
        },
        '#withType':: d.fn(help='"Type of daemon set update. Can be \\"RollingUpdate\\" or \\"OnDelete\\". Default is RollingUpdate."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { spec+: { daemonSet+: { updateStrategy+: { type: type } } } },
      },
      '#withPodTemplate':: d.fn(help='"PodTemplateSpec describes the data a pod should have when created from a template"', args=[d.arg(name='podTemplate', type=d.T.object)]),
      withPodTemplate(podTemplate): { spec+: { daemonSet+: { podTemplate: podTemplate } } },
      '#withPodTemplateMixin':: d.fn(help='"PodTemplateSpec describes the data a pod should have when created from a template"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='podTemplate', type=d.T.object)]),
      withPodTemplateMixin(podTemplate): { spec+: { daemonSet+: { podTemplate+: podTemplate } } },
    },
    '#deployment':: d.obj(help='"Deployment specifies the Agent should be deployed as a Deployment, and allows providing its spec. Cannot be used along with `daemonSet`."'),
    deployment: {
      '#strategy':: d.obj(help='"DeploymentStrategy describes how to replace existing pods with new ones."'),
      strategy: {
        '#rollingUpdate':: d.obj(help='"Rolling update config params. Present only if DeploymentStrategyType = RollingUpdate. --- TODO: Update this to follow our convention for oneOf, whatever we decide it to be."'),
        rollingUpdate: {
          '#withMaxSurge':: d.fn(help='"The maximum number of pods that can be scheduled above the desired number of pods. Value can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%). This can not be 0 if MaxUnavailable is 0. Absolute number is calculated from percentage by rounding up. Defaults to 25%. Example: when this is set to 30%, the new ReplicaSet can be scaled up immediately when the rolling update starts, such that the total number of old and new pods do not exceed 130% of desired pods. Once old pods have been killed, new ReplicaSet can be scaled up further, ensuring that total number of pods running at any time during the update is at most 130% of desired pods."', args=[d.arg(name='maxSurge', type=d.T.any)]),
          withMaxSurge(maxSurge): { spec+: { deployment+: { strategy+: { rollingUpdate+: { maxSurge: maxSurge } } } } },
          '#withMaxUnavailable':: d.fn(help='"The maximum number of pods that can be unavailable during the update. Value can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%). Absolute number is calculated from percentage by rounding down. This can not be 0 if MaxSurge is 0. Defaults to 25%. Example: when this is set to 30%, the old ReplicaSet can be scaled down to 70% of desired pods immediately when the rolling update starts. Once new pods are ready, old ReplicaSet can be scaled down further, followed by scaling up the new ReplicaSet, ensuring that the total number of pods available at all times during the update is at least 70% of desired pods."', args=[d.arg(name='maxUnavailable', type=d.T.any)]),
          withMaxUnavailable(maxUnavailable): { spec+: { deployment+: { strategy+: { rollingUpdate+: { maxUnavailable: maxUnavailable } } } } },
        },
        '#withType':: d.fn(help='"Type of deployment. Can be \\"Recreate\\" or \\"RollingUpdate\\". Default is RollingUpdate."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { spec+: { deployment+: { strategy+: { type: type } } } },
      },
      '#withPodTemplate':: d.fn(help='"PodTemplateSpec describes the data a pod should have when created from a template"', args=[d.arg(name='podTemplate', type=d.T.object)]),
      withPodTemplate(podTemplate): { spec+: { deployment+: { podTemplate: podTemplate } } },
      '#withPodTemplateMixin':: d.fn(help='"PodTemplateSpec describes the data a pod should have when created from a template"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='podTemplate', type=d.T.object)]),
      withPodTemplateMixin(podTemplate): { spec+: { deployment+: { podTemplate+: podTemplate } } },
      '#withReplicas':: d.fn(help='', args=[d.arg(name='replicas', type=d.T.integer)]),
      withReplicas(replicas): { spec+: { deployment+: { replicas: replicas } } },
    },
    '#elasticsearchRefs':: d.obj(help='"ElasticsearchRefs is a reference to a list of Elasticsearch clusters running in the same Kubernetes cluster. Due to existing limitations, only a single ES cluster is currently supported."'),
    elasticsearchRefs: {
      '#withName':: d.fn(help='"Name of the Kubernetes object."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { name: name },
      '#withNamespace':: d.fn(help='"Namespace of the Kubernetes object. If empty, defaults to the current namespace."', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { namespace: namespace },
      '#withOutputName':: d.fn(help='', args=[d.arg(name='outputName', type=d.T.string)]),
      withOutputName(outputName): { outputName: outputName },
      '#withServiceName':: d.fn(help='"ServiceName is the name of an existing Kubernetes service which is used to make requests to the referenced object. It has to be in the same namespace as the referenced resource. If left empty, the default HTTP service of the referenced resource is used."', args=[d.arg(name='serviceName', type=d.T.string)]),
      withServiceName(serviceName): { serviceName: serviceName },
    },
    '#fleetServerRef':: d.obj(help="\"FleetServerRef is a reference to Fleet Server that this Agent should connect to to obtain it's configuration. Don't set unless `mode` is set to `fleet`.\""),
    fleetServerRef: {
      '#withName':: d.fn(help='"Name of the Kubernetes object."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { fleetServerRef+: { name: name } } },
      '#withNamespace':: d.fn(help='"Namespace of the Kubernetes object. If empty, defaults to the current namespace."', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { spec+: { fleetServerRef+: { namespace: namespace } } },
      '#withServiceName':: d.fn(help='"ServiceName is the name of an existing Kubernetes service which is used to make requests to the referenced object. It has to be in the same namespace as the referenced resource. If left empty, the default HTTP service of the referenced resource is used."', args=[d.arg(name='serviceName', type=d.T.string)]),
      withServiceName(serviceName): { spec+: { fleetServerRef+: { serviceName: serviceName } } },
    },
    '#http':: d.obj(help='"HTTP holds the HTTP layer configuration for the Agent in Fleet mode with Fleet Server enabled."'),
    http: {
      '#service':: d.obj(help='"Service defines the template for the associated Kubernetes Service object."'),
      service: {
        '#metadata':: d.obj(help='"ObjectMeta is the metadata of the service. The name and namespace provided here are managed by ECK and will be ignored."'),
        metadata: {
          '#withAnnotations':: d.fn(help='', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotations(annotations): { spec+: { http+: { service+: { metadata+: { annotations: annotations } } } } },
          '#withAnnotationsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotationsMixin(annotations): { spec+: { http+: { service+: { metadata+: { annotations+: annotations } } } } },
          '#withFinalizers':: d.fn(help='', args=[d.arg(name='finalizers', type=d.T.array)]),
          withFinalizers(finalizers): { spec+: { http+: { service+: { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } } } } },
          '#withFinalizersMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
          withFinalizersMixin(finalizers): { spec+: { http+: { service+: { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } } } } },
          '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { spec+: { http+: { service+: { metadata+: { labels: labels } } } } },
          '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { spec+: { http+: { service+: { metadata+: { labels+: labels } } } } },
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { http+: { service+: { metadata+: { name: name } } } } },
          '#withNamespace':: d.fn(help='', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { spec+: { http+: { service+: { metadata+: { namespace: namespace } } } } },
        },
        '#spec':: d.obj(help='"Spec is the specification of the service."'),
        spec: {
          '#ports':: d.obj(help='"The list of ports that are exposed by this service. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"'),
          ports: {
            '#withAppProtocol':: d.fn(help='"The application protocol for this port. This field follows standard Kubernetes label syntax. Un-prefixed names are reserved for IANA standard service names (as per RFC-6335 and http://www.iana.org/assignments/service-names). Non-standard protocols should use prefixed names such as mycompany.com/my-custom-protocol. This is a beta field that is guarded by the ServiceAppProtocol feature gate and enabled by default."', args=[d.arg(name='appProtocol', type=d.T.string)]),
            withAppProtocol(appProtocol): { appProtocol: appProtocol },
            '#withName':: d.fn(help="\"The name of this port within the service. This must be a DNS_LABEL. All ports within a ServiceSpec must have unique names. When considering the endpoints for a Service, this must match the 'name' field in the EndpointPort. Optional if only one ServicePort is defined on this service.\"", args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withNodePort':: d.fn(help='"The port on each node on which this service is exposed when type is NodePort or LoadBalancer.  Usually assigned by the system. If a value is specified, in-range, and not in use it will be used, otherwise the operation will fail.  If not specified, a port will be allocated if this Service requires one.  If this field is specified when creating a Service which does not need it, creation will fail. This field will be wiped when updating a Service to no longer need it (e.g. changing type from NodePort to ClusterIP). More info: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport"', args=[d.arg(name='nodePort', type=d.T.integer)]),
            withNodePort(nodePort): { nodePort: nodePort },
            '#withPort':: d.fn(help='"The port that will be exposed by this service."', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { port: port },
            '#withProtocol':: d.fn(help='"The IP protocol for this port. Supports \\"TCP\\", \\"UDP\\", and \\"SCTP\\". Default is TCP."', args=[d.arg(name='protocol', type=d.T.string)]),
            withProtocol(protocol): { protocol: protocol },
            '#withTargetPort':: d.fn(help="\"Number or name of the port to access on the pods targeted by the service. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME. If this is a string, it will be looked up as a named port in the target Pod's container ports. If this is not specified, the value of the 'port' field is used (an identity map). This field is ignored for services with clusterIP=None, and should be omitted or set equal to the 'port' field. More info: https://kubernetes.io/docs/concepts/services-networking/service/#defining-a-service\"", args=[d.arg(name='targetPort', type=d.T.any)]),
            withTargetPort(targetPort): { targetPort: targetPort },
          },
          '#sessionAffinityConfig':: d.obj(help='"sessionAffinityConfig contains the configurations of session affinity."'),
          sessionAffinityConfig: {
            '#clientIP':: d.obj(help='"clientIP contains the configurations of Client IP based session affinity."'),
            clientIP: {
              '#withTimeoutSeconds':: d.fn(help='"timeoutSeconds specifies the seconds of ClientIP type session sticky time. The value must be >0 && <=86400(for 1 day) if ServiceAffinity == \\"ClientIP\\". Default value is 10800(for 3 hours)."', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
              withTimeoutSeconds(timeoutSeconds): { spec+: { http+: { service+: { spec+: { sessionAffinityConfig+: { clientIP+: { timeoutSeconds: timeoutSeconds } } } } } } },
            },
          },
          '#withAllocateLoadBalancerNodePorts':: d.fn(help='"allocateLoadBalancerNodePorts defines if NodePorts will be automatically allocated for services with type LoadBalancer.  Default is \\"true\\". It may be set to \\"false\\" if the cluster load-balancer does not rely on NodePorts. allocateLoadBalancerNodePorts may only be set for services with type LoadBalancer and will be cleared if the type is changed to any other type. This field is alpha-level and is only honored by servers that enable the ServiceLBNodePortControl feature."', args=[d.arg(name='allocateLoadBalancerNodePorts', type=d.T.boolean)]),
          withAllocateLoadBalancerNodePorts(allocateLoadBalancerNodePorts): { spec+: { http+: { service+: { spec+: { allocateLoadBalancerNodePorts: allocateLoadBalancerNodePorts } } } } },
          '#withClusterIP':: d.fn(help='"clusterIP is the IP address of the service and is usually assigned randomly. If an address is specified manually, is in-range (as per system configuration), and is not in use, it will be allocated to the service; otherwise creation of the service will fail. This field may not be changed through updates unless the type field is also being changed to ExternalName (which requires this field to be blank) or the type field is being changed from ExternalName (in which case this field may optionally be specified, as describe above).  Valid values are \\"None\\", empty string (\\"\\"), or a valid IP address. Setting this to \\"None\\" makes a \\"headless service\\" (no virtual IP), which is useful when direct endpoint connections are preferred and proxying is not required.  Only applies to types ClusterIP, NodePort, and LoadBalancer. If this field is specified when creating a Service of type ExternalName, creation will fail. This field will be wiped when updating a Service to type ExternalName. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"', args=[d.arg(name='clusterIP', type=d.T.string)]),
          withClusterIP(clusterIP): { spec+: { http+: { service+: { spec+: { clusterIP: clusterIP } } } } },
          '#withClusterIPs':: d.fn(help='"ClusterIPs is a list of IP addresses assigned to this service, and are usually assigned randomly.  If an address is specified manually, is in-range (as per system configuration), and is not in use, it will be allocated to the service; otherwise creation of the service will fail. This field may not be changed through updates unless the type field is also being changed to ExternalName (which requires this field to be empty) or the type field is being changed from ExternalName (in which case this field may optionally be specified, as describe above).  Valid values are \\"None\\", empty string (\\"\\"), or a valid IP address.  Setting this to \\"None\\" makes a \\"headless service\\" (no virtual IP), which is useful when direct endpoint connections are preferred and proxying is not required.  Only applies to types ClusterIP, NodePort, and LoadBalancer. If this field is specified when creating a Service of type ExternalName, creation will fail. This field will be wiped when updating a Service to type ExternalName.  If this field is not specified, it will be initialized from the clusterIP field.  If this field is specified, clients must ensure that clusterIPs[0] and clusterIP have the same value. \\n Unless the \\"IPv6DualStack\\" feature gate is enabled, this field is limited to one value, which must be the same as the clusterIP field.  If the feature gate is enabled, this field may hold a maximum of two entries (dual-stack IPs, in either order).  These IPs must correspond to the values of the ipFamilies field. Both clusterIPs and ipFamilies are governed by the ipFamilyPolicy field. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"', args=[d.arg(name='clusterIPs', type=d.T.array)]),
          withClusterIPs(clusterIPs): { spec+: { http+: { service+: { spec+: { clusterIPs: if std.isArray(v=clusterIPs) then clusterIPs else [clusterIPs] } } } } },
          '#withClusterIPsMixin':: d.fn(help='"ClusterIPs is a list of IP addresses assigned to this service, and are usually assigned randomly.  If an address is specified manually, is in-range (as per system configuration), and is not in use, it will be allocated to the service; otherwise creation of the service will fail. This field may not be changed through updates unless the type field is also being changed to ExternalName (which requires this field to be empty) or the type field is being changed from ExternalName (in which case this field may optionally be specified, as describe above).  Valid values are \\"None\\", empty string (\\"\\"), or a valid IP address.  Setting this to \\"None\\" makes a \\"headless service\\" (no virtual IP), which is useful when direct endpoint connections are preferred and proxying is not required.  Only applies to types ClusterIP, NodePort, and LoadBalancer. If this field is specified when creating a Service of type ExternalName, creation will fail. This field will be wiped when updating a Service to type ExternalName.  If this field is not specified, it will be initialized from the clusterIP field.  If this field is specified, clients must ensure that clusterIPs[0] and clusterIP have the same value. \\n Unless the \\"IPv6DualStack\\" feature gate is enabled, this field is limited to one value, which must be the same as the clusterIP field.  If the feature gate is enabled, this field may hold a maximum of two entries (dual-stack IPs, in either order).  These IPs must correspond to the values of the ipFamilies field. Both clusterIPs and ipFamilies are governed by the ipFamilyPolicy field. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='clusterIPs', type=d.T.array)]),
          withClusterIPsMixin(clusterIPs): { spec+: { http+: { service+: { spec+: { clusterIPs+: if std.isArray(v=clusterIPs) then clusterIPs else [clusterIPs] } } } } },
          '#withExternalIPs':: d.fn(help='"externalIPs is a list of IP addresses for which nodes in the cluster will also accept traffic for this service.  These IPs are not managed by Kubernetes.  The user is responsible for ensuring that traffic arrives at a node with this IP.  A common example is external load-balancers that are not part of the Kubernetes system."', args=[d.arg(name='externalIPs', type=d.T.array)]),
          withExternalIPs(externalIPs): { spec+: { http+: { service+: { spec+: { externalIPs: if std.isArray(v=externalIPs) then externalIPs else [externalIPs] } } } } },
          '#withExternalIPsMixin':: d.fn(help='"externalIPs is a list of IP addresses for which nodes in the cluster will also accept traffic for this service.  These IPs are not managed by Kubernetes.  The user is responsible for ensuring that traffic arrives at a node with this IP.  A common example is external load-balancers that are not part of the Kubernetes system."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='externalIPs', type=d.T.array)]),
          withExternalIPsMixin(externalIPs): { spec+: { http+: { service+: { spec+: { externalIPs+: if std.isArray(v=externalIPs) then externalIPs else [externalIPs] } } } } },
          '#withExternalName':: d.fn(help='"externalName is the external reference that discovery mechanisms will return as an alias for this service (e.g. a DNS CNAME record). No proxying will be involved.  Must be a lowercase RFC-1123 hostname (https://tools.ietf.org/html/rfc1123) and requires `type` to be \\"ExternalName\\"."', args=[d.arg(name='externalName', type=d.T.string)]),
          withExternalName(externalName): { spec+: { http+: { service+: { spec+: { externalName: externalName } } } } },
          '#withExternalTrafficPolicy':: d.fn(help='"externalTrafficPolicy denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints. \\"Local\\" preserves the client source IP and avoids a second hop for LoadBalancer and Nodeport type services, but risks potentially imbalanced traffic spreading. \\"Cluster\\" obscures the client source IP and may cause a second hop to another node, but should have good overall load-spreading."', args=[d.arg(name='externalTrafficPolicy', type=d.T.string)]),
          withExternalTrafficPolicy(externalTrafficPolicy): { spec+: { http+: { service+: { spec+: { externalTrafficPolicy: externalTrafficPolicy } } } } },
          '#withHealthCheckNodePort':: d.fn(help='"healthCheckNodePort specifies the healthcheck nodePort for the service. This only applies when type is set to LoadBalancer and externalTrafficPolicy is set to Local. If a value is specified, is in-range, and is not in use, it will be used.  If not specified, a value will be automatically allocated.  External systems (e.g. load-balancers) can use this port to determine if a given node holds endpoints for this service or not.  If this field is specified when creating a Service which does not need it, creation will fail. This field will be wiped when updating a Service to no longer need it (e.g. changing type)."', args=[d.arg(name='healthCheckNodePort', type=d.T.integer)]),
          withHealthCheckNodePort(healthCheckNodePort): { spec+: { http+: { service+: { spec+: { healthCheckNodePort: healthCheckNodePort } } } } },
          '#withInternalTrafficPolicy':: d.fn(help='"InternalTrafficPolicy specifies if the cluster internal traffic should be routed to all endpoints or node-local endpoints only. \\"Cluster\\" routes internal traffic to a Service to all endpoints. \\"Local\\" routes traffic to node-local endpoints only, traffic is dropped if no node-local endpoints are ready. The default value is \\"Cluster\\"."', args=[d.arg(name='internalTrafficPolicy', type=d.T.string)]),
          withInternalTrafficPolicy(internalTrafficPolicy): { spec+: { http+: { service+: { spec+: { internalTrafficPolicy: internalTrafficPolicy } } } } },
          '#withIpFamilies':: d.fn(help='"IPFamilies is a list of IP families (e.g. IPv4, IPv6) assigned to this service, and is gated by the \\"IPv6DualStack\\" feature gate.  This field is usually assigned automatically based on cluster configuration and the ipFamilyPolicy field. If this field is specified manually, the requested family is available in the cluster, and ipFamilyPolicy allows it, it will be used; otherwise creation of the service will fail.  This field is conditionally mutable: it allows for adding or removing a secondary IP family, but it does not allow changing the primary IP family of the Service.  Valid values are \\"IPv4\\" and \\"IPv6\\".  This field only applies to Services of types ClusterIP, NodePort, and LoadBalancer, and does apply to \\"headless\\" services.  This field will be wiped when updating a Service to type ExternalName. \\n This field may hold a maximum of two entries (dual-stack families, in either order).  These families must correspond to the values of the clusterIPs field, if specified. Both clusterIPs and ipFamilies are governed by the ipFamilyPolicy field."', args=[d.arg(name='ipFamilies', type=d.T.array)]),
          withIpFamilies(ipFamilies): { spec+: { http+: { service+: { spec+: { ipFamilies: if std.isArray(v=ipFamilies) then ipFamilies else [ipFamilies] } } } } },
          '#withIpFamiliesMixin':: d.fn(help='"IPFamilies is a list of IP families (e.g. IPv4, IPv6) assigned to this service, and is gated by the \\"IPv6DualStack\\" feature gate.  This field is usually assigned automatically based on cluster configuration and the ipFamilyPolicy field. If this field is specified manually, the requested family is available in the cluster, and ipFamilyPolicy allows it, it will be used; otherwise creation of the service will fail.  This field is conditionally mutable: it allows for adding or removing a secondary IP family, but it does not allow changing the primary IP family of the Service.  Valid values are \\"IPv4\\" and \\"IPv6\\".  This field only applies to Services of types ClusterIP, NodePort, and LoadBalancer, and does apply to \\"headless\\" services.  This field will be wiped when updating a Service to type ExternalName. \\n This field may hold a maximum of two entries (dual-stack families, in either order).  These families must correspond to the values of the clusterIPs field, if specified. Both clusterIPs and ipFamilies are governed by the ipFamilyPolicy field."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ipFamilies', type=d.T.array)]),
          withIpFamiliesMixin(ipFamilies): { spec+: { http+: { service+: { spec+: { ipFamilies+: if std.isArray(v=ipFamilies) then ipFamilies else [ipFamilies] } } } } },
          '#withIpFamilyPolicy':: d.fn(help='"IPFamilyPolicy represents the dual-stack-ness requested or required by this Service, and is gated by the \\"IPv6DualStack\\" feature gate.  If there is no value provided, then this field will be set to SingleStack. Services can be \\"SingleStack\\" (a single IP family), \\"PreferDualStack\\" (two IP families on dual-stack configured clusters or a single IP family on single-stack clusters), or \\"RequireDualStack\\" (two IP families on dual-stack configured clusters, otherwise fail). The ipFamilies and clusterIPs fields depend on the value of this field.  This field will be wiped when updating a service to type ExternalName."', args=[d.arg(name='ipFamilyPolicy', type=d.T.string)]),
          withIpFamilyPolicy(ipFamilyPolicy): { spec+: { http+: { service+: { spec+: { ipFamilyPolicy: ipFamilyPolicy } } } } },
          '#withLoadBalancerClass':: d.fn(help="\"loadBalancerClass is the class of the load balancer implementation this Service belongs to. If specified, the value of this field must be a label-style identifier, with an optional prefix, e.g. \\\"internal-vip\\\" or \\\"example.com/internal-vip\\\". Unprefixed names are reserved for end-users. This field can only be set when the Service type is 'LoadBalancer'. If not set, the default load balancer implementation is used, today this is typically done through the cloud provider integration, but should apply for any default implementation. If set, it is assumed that a load balancer implementation is watching for Services with a matching class. Any default load balancer implementation (e.g. cloud providers) should ignore Services that set this field. This field can only be set when creating or updating a Service to type 'LoadBalancer'. Once set, it can not be changed. This field will be wiped when a service is updated to a non 'LoadBalancer' type.\"", args=[d.arg(name='loadBalancerClass', type=d.T.string)]),
          withLoadBalancerClass(loadBalancerClass): { spec+: { http+: { service+: { spec+: { loadBalancerClass: loadBalancerClass } } } } },
          '#withLoadBalancerIP':: d.fn(help='"Only applies to Service Type: LoadBalancer LoadBalancer will get created with the IP specified in this field. This feature depends on whether the underlying cloud-provider supports specifying the loadBalancerIP when a load balancer is created. This field will be ignored if the cloud-provider does not support the feature."', args=[d.arg(name='loadBalancerIP', type=d.T.string)]),
          withLoadBalancerIP(loadBalancerIP): { spec+: { http+: { service+: { spec+: { loadBalancerIP: loadBalancerIP } } } } },
          '#withLoadBalancerSourceRanges':: d.fn(help='"If specified and supported by the platform, this will restrict traffic through the cloud-provider load-balancer will be restricted to the specified client IPs. This field will be ignored if the cloud-provider does not support the feature.\\" More info: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/"', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
          withLoadBalancerSourceRanges(loadBalancerSourceRanges): { spec+: { http+: { service+: { spec+: { loadBalancerSourceRanges: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } } } },
          '#withLoadBalancerSourceRangesMixin':: d.fn(help='"If specified and supported by the platform, this will restrict traffic through the cloud-provider load-balancer will be restricted to the specified client IPs. This field will be ignored if the cloud-provider does not support the feature.\\" More info: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
          withLoadBalancerSourceRangesMixin(loadBalancerSourceRanges): { spec+: { http+: { service+: { spec+: { loadBalancerSourceRanges+: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } } } },
          '#withPorts':: d.fn(help='"The list of ports that are exposed by this service. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"', args=[d.arg(name='ports', type=d.T.array)]),
          withPorts(ports): { spec+: { http+: { service+: { spec+: { ports: if std.isArray(v=ports) then ports else [ports] } } } } },
          '#withPortsMixin':: d.fn(help='"The list of ports that are exposed by this service. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ports', type=d.T.array)]),
          withPortsMixin(ports): { spec+: { http+: { service+: { spec+: { ports+: if std.isArray(v=ports) then ports else [ports] } } } } },
          '#withPublishNotReadyAddresses':: d.fn(help="\"publishNotReadyAddresses indicates that any agent which deals with endpoints for this Service should disregard any indications of ready/not-ready. The primary use case for setting this field is for a StatefulSet's Headless Service to propagate SRV DNS records for its Pods for the purpose of peer discovery. The Kubernetes controllers that generate Endpoints and EndpointSlice resources for Services interpret this to mean that all endpoints are considered \\\"ready\\\" even if the Pods themselves are not. Agents which consume only Kubernetes generated endpoints through the Endpoints or EndpointSlice resources can safely assume this behavior.\"", args=[d.arg(name='publishNotReadyAddresses', type=d.T.boolean)]),
          withPublishNotReadyAddresses(publishNotReadyAddresses): { spec+: { http+: { service+: { spec+: { publishNotReadyAddresses: publishNotReadyAddresses } } } } },
          '#withSelector':: d.fn(help='"Route service traffic to pods with label keys and values matching this selector. If empty or not present, the service is assumed to have an external process managing its endpoints, which Kubernetes will not modify. Only applies to types ClusterIP, NodePort, and LoadBalancer. Ignored if type is ExternalName. More info: https://kubernetes.io/docs/concepts/services-networking/service/"', args=[d.arg(name='selector', type=d.T.object)]),
          withSelector(selector): { spec+: { http+: { service+: { spec+: { selector: selector } } } } },
          '#withSelectorMixin':: d.fn(help='"Route service traffic to pods with label keys and values matching this selector. If empty or not present, the service is assumed to have an external process managing its endpoints, which Kubernetes will not modify. Only applies to types ClusterIP, NodePort, and LoadBalancer. Ignored if type is ExternalName. More info: https://kubernetes.io/docs/concepts/services-networking/service/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='selector', type=d.T.object)]),
          withSelectorMixin(selector): { spec+: { http+: { service+: { spec+: { selector+: selector } } } } },
          '#withSessionAffinity':: d.fn(help='"Supports \\"ClientIP\\" and \\"None\\". Used to maintain session affinity. Enable client IP based session affinity. Must be ClientIP or None. Defaults to None. More info: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies"', args=[d.arg(name='sessionAffinity', type=d.T.string)]),
          withSessionAffinity(sessionAffinity): { spec+: { http+: { service+: { spec+: { sessionAffinity: sessionAffinity } } } } },
          '#withTopologyKeys':: d.fn(help='"topologyKeys is a preference-order list of topology keys which implementations of services should use to preferentially sort endpoints when accessing this Service, it can not be used at the same time as externalTrafficPolicy=Local. Topology keys must be valid label keys and at most 16 keys may be specified. Endpoints are chosen based on the first topology key with available backends. If this field is specified and all entries have no backends that match the topology of the client, the service has no backends for that client and connections should fail. The special value \\"*\\" may be used to mean \\"any topology\\". This catch-all value, if used, only makes sense as the last value in the list. If this is not specified or empty, no topology constraints will be applied. This field is alpha-level and is only honored by servers that enable the ServiceTopology feature. This field is deprecated and will be removed in a future version."', args=[d.arg(name='topologyKeys', type=d.T.array)]),
          withTopologyKeys(topologyKeys): { spec+: { http+: { service+: { spec+: { topologyKeys: if std.isArray(v=topologyKeys) then topologyKeys else [topologyKeys] } } } } },
          '#withTopologyKeysMixin':: d.fn(help='"topologyKeys is a preference-order list of topology keys which implementations of services should use to preferentially sort endpoints when accessing this Service, it can not be used at the same time as externalTrafficPolicy=Local. Topology keys must be valid label keys and at most 16 keys may be specified. Endpoints are chosen based on the first topology key with available backends. If this field is specified and all entries have no backends that match the topology of the client, the service has no backends for that client and connections should fail. The special value \\"*\\" may be used to mean \\"any topology\\". This catch-all value, if used, only makes sense as the last value in the list. If this is not specified or empty, no topology constraints will be applied. This field is alpha-level and is only honored by servers that enable the ServiceTopology feature. This field is deprecated and will be removed in a future version."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='topologyKeys', type=d.T.array)]),
          withTopologyKeysMixin(topologyKeys): { spec+: { http+: { service+: { spec+: { topologyKeys+: if std.isArray(v=topologyKeys) then topologyKeys else [topologyKeys] } } } } },
          '#withType':: d.fn(help='"type determines how the Service is exposed. Defaults to ClusterIP. Valid options are ExternalName, ClusterIP, NodePort, and LoadBalancer. \\"ClusterIP\\" allocates a cluster-internal IP address for load-balancing to endpoints. Endpoints are determined by the selector or if that is not specified, by manual construction of an Endpoints object or EndpointSlice objects. If clusterIP is \\"None\\", no virtual IP is allocated and the endpoints are published as a set of endpoints rather than a virtual IP. \\"NodePort\\" builds on ClusterIP and allocates a port on every node which routes to the same endpoints as the clusterIP. \\"LoadBalancer\\" builds on NodePort and creates an external load-balancer (if supported in the current cloud) which routes to the same endpoints as the clusterIP. \\"ExternalName\\" aliases this service to the specified externalName. Several other fields do not apply to ExternalName services. More info: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types"', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { http+: { service+: { spec+: { type: type } } } } },
        },
      },
      '#tls':: d.obj(help='"TLS defines options for configuring TLS for HTTP."'),
      tls: {
        '#certificate':: d.obj(help='"Certificate is a reference to a Kubernetes secret that contains the certificate and private key for enabling TLS. The referenced secret should contain the following: \\n - `ca.crt`: The certificate authority (optional). - `tls.crt`: The certificate (or a chain). - `tls.key`: The private key to the first certificate in the certificate chain."'),
        certificate: {
          '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
          withSecretName(secretName): { spec+: { http+: { tls+: { certificate+: { secretName: secretName } } } } },
        },
        '#selfSignedCertificate':: d.obj(help='"SelfSignedCertificate allows configuring the self-signed certificate generated by the operator."'),
        selfSignedCertificate: {
          '#subjectAltNames':: d.obj(help='"SubjectAlternativeNames is a list of SANs to include in the generated HTTP TLS certificate."'),
          subjectAltNames: {
            '#withDns':: d.fn(help='"DNS is the DNS name of the subject."', args=[d.arg(name='dns', type=d.T.string)]),
            withDns(dns): { dns: dns },
            '#withIp':: d.fn(help='"IP is the IP address of the subject."', args=[d.arg(name='ip', type=d.T.string)]),
            withIp(ip): { ip: ip },
          },
          '#withDisabled':: d.fn(help='"Disabled indicates that the provisioning of the self-signed certifcate should be disabled."', args=[d.arg(name='disabled', type=d.T.boolean)]),
          withDisabled(disabled): { spec+: { http+: { tls+: { selfSignedCertificate+: { disabled: disabled } } } } },
          '#withSubjectAltNames':: d.fn(help='"SubjectAlternativeNames is a list of SANs to include in the generated HTTP TLS certificate."', args=[d.arg(name='subjectAltNames', type=d.T.array)]),
          withSubjectAltNames(subjectAltNames): { spec+: { http+: { tls+: { selfSignedCertificate+: { subjectAltNames: if std.isArray(v=subjectAltNames) then subjectAltNames else [subjectAltNames] } } } } },
          '#withSubjectAltNamesMixin':: d.fn(help='"SubjectAlternativeNames is a list of SANs to include in the generated HTTP TLS certificate."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='subjectAltNames', type=d.T.array)]),
          withSubjectAltNamesMixin(subjectAltNames): { spec+: { http+: { tls+: { selfSignedCertificate+: { subjectAltNames+: if std.isArray(v=subjectAltNames) then subjectAltNames else [subjectAltNames] } } } } },
        },
      },
    },
    '#kibanaRef':: d.obj(help="\"KibanaRef is a reference to Kibana where Fleet should be set up and this Agent should be enrolled. Don't set unless `mode` is set to `fleet`.\""),
    kibanaRef: {
      '#withName':: d.fn(help='"Name of the Kubernetes object."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { kibanaRef+: { name: name } } },
      '#withNamespace':: d.fn(help='"Namespace of the Kubernetes object. If empty, defaults to the current namespace."', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { spec+: { kibanaRef+: { namespace: namespace } } },
      '#withServiceName':: d.fn(help='"ServiceName is the name of an existing Kubernetes service which is used to make requests to the referenced object. It has to be in the same namespace as the referenced resource. If left empty, the default HTTP service of the referenced resource is used."', args=[d.arg(name='serviceName', type=d.T.string)]),
      withServiceName(serviceName): { spec+: { kibanaRef+: { serviceName: serviceName } } },
    },
    '#secureSettings':: d.obj(help="\"SecureSettings is a list of references to Kubernetes Secrets containing sensitive configuration options for the Agent. Secrets data can be then referenced in the Agent config using the Secret's keys or as specified in `Entries` field of each SecureSetting.\""),
    secureSettings: {
      '#entries':: d.obj(help='"Entries define how to project each key-value pair in the secret to filesystem paths. If not defined, all keys will be projected to similarly named paths in the filesystem. If defined, only the specified keys will be projected to the corresponding paths."'),
      entries: {
        '#withKey':: d.fn(help='"Key is the key contained in the secret."', args=[d.arg(name='key', type=d.T.string)]),
        withKey(key): { key: key },
        '#withPath':: d.fn(help='"Path is the relative file path to map the key to. Path must not be an absolute file path and must not contain any \\"..\\" components."', args=[d.arg(name='path', type=d.T.string)]),
        withPath(path): { path: path },
      },
      '#withEntries':: d.fn(help='"Entries define how to project each key-value pair in the secret to filesystem paths. If not defined, all keys will be projected to similarly named paths in the filesystem. If defined, only the specified keys will be projected to the corresponding paths."', args=[d.arg(name='entries', type=d.T.array)]),
      withEntries(entries): { entries: if std.isArray(v=entries) then entries else [entries] },
      '#withEntriesMixin':: d.fn(help='"Entries define how to project each key-value pair in the secret to filesystem paths. If not defined, all keys will be projected to similarly named paths in the filesystem. If defined, only the specified keys will be projected to the corresponding paths."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='entries', type=d.T.array)]),
      withEntriesMixin(entries): { entries+: if std.isArray(v=entries) then entries else [entries] },
      '#withSecretName':: d.fn(help='"SecretName is the name of the secret."', args=[d.arg(name='secretName', type=d.T.string)]),
      withSecretName(secretName): { secretName: secretName },
    },
    '#withConfig':: d.fn(help='"Config holds the Agent configuration. At most one of [`Config`, `ConfigRef`] can be specified."', args=[d.arg(name='config', type=d.T.object)]),
    withConfig(config): { spec+: { config: config } },
    '#withConfigMixin':: d.fn(help='"Config holds the Agent configuration. At most one of [`Config`, `ConfigRef`] can be specified."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='config', type=d.T.object)]),
    withConfigMixin(config): { spec+: { config+: config } },
    '#withElasticsearchRefs':: d.fn(help='"ElasticsearchRefs is a reference to a list of Elasticsearch clusters running in the same Kubernetes cluster. Due to existing limitations, only a single ES cluster is currently supported."', args=[d.arg(name='elasticsearchRefs', type=d.T.array)]),
    withElasticsearchRefs(elasticsearchRefs): { spec+: { elasticsearchRefs: if std.isArray(v=elasticsearchRefs) then elasticsearchRefs else [elasticsearchRefs] } },
    '#withElasticsearchRefsMixin':: d.fn(help='"ElasticsearchRefs is a reference to a list of Elasticsearch clusters running in the same Kubernetes cluster. Due to existing limitations, only a single ES cluster is currently supported."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='elasticsearchRefs', type=d.T.array)]),
    withElasticsearchRefsMixin(elasticsearchRefs): { spec+: { elasticsearchRefs+: if std.isArray(v=elasticsearchRefs) then elasticsearchRefs else [elasticsearchRefs] } },
    '#withFleetServerEnabled':: d.fn(help="\"FleetServerEnabled determines whether this Agent will launch Fleet Server. Don't set unless `mode` is set to `fleet`.\"", args=[d.arg(name='fleetServerEnabled', type=d.T.boolean)]),
    withFleetServerEnabled(fleetServerEnabled): { spec+: { fleetServerEnabled: fleetServerEnabled } },
    '#withImage':: d.fn(help='"Image is the Agent Docker image to deploy. Version has to match the Agent in the image."', args=[d.arg(name='image', type=d.T.string)]),
    withImage(image): { spec+: { image: image } },
    '#withMode':: d.fn(help='"Mode specifies the source of configuration for the Agent. The configuration can be specified locally through `config` or `configRef` (`standalone` mode), or come from Fleet during runtime (`fleet` mode). Defaults to `standalone` mode."', args=[d.arg(name='mode', type=d.T.string)]),
    withMode(mode): { spec+: { mode: mode } },
    '#withSecureSettings':: d.fn(help="\"SecureSettings is a list of references to Kubernetes Secrets containing sensitive configuration options for the Agent. Secrets data can be then referenced in the Agent config using the Secret's keys or as specified in `Entries` field of each SecureSetting.\"", args=[d.arg(name='secureSettings', type=d.T.array)]),
    withSecureSettings(secureSettings): { spec+: { secureSettings: if std.isArray(v=secureSettings) then secureSettings else [secureSettings] } },
    '#withSecureSettingsMixin':: d.fn(help="\"SecureSettings is a list of references to Kubernetes Secrets containing sensitive configuration options for the Agent. Secrets data can be then referenced in the Agent config using the Secret's keys or as specified in `Entries` field of each SecureSetting.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='secureSettings', type=d.T.array)]),
    withSecureSettingsMixin(secureSettings): { spec+: { secureSettings+: if std.isArray(v=secureSettings) then secureSettings else [secureSettings] } },
    '#withServiceAccountName':: d.fn(help='"ServiceAccountName is used to check access from the current resource to an Elasticsearch resource in a different namespace. Can only be used if ECK is enforcing RBAC on references."', args=[d.arg(name='serviceAccountName', type=d.T.string)]),
    withServiceAccountName(serviceAccountName): { spec+: { serviceAccountName: serviceAccountName } },
    '#withVersion':: d.fn(help='"Version of the Agent."', args=[d.arg(name='version', type=d.T.string)]),
    withVersion(version): { spec+: { version: version } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
