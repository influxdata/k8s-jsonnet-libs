{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='prometheus', url='', help='"Prometheus defines a Prometheus deployment."'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withManagedFields':: d.fn(help="\"ManagedFields maps workflow-id and version to the set of fields that are managed by that workflow. This is mostly for internal housekeeping, and users typically shouldn't need to set or understand this field. A workflow can be the user's name, a controller's name, or the name of a specific apply path like \\\"ci-cd\\\". The set of fields is always in the version that the workflow used when modifying the object.\"", args=[d.arg(name='managedFields', type=d.T.array)]),
    withManagedFields(managedFields): { metadata+: { managedFields: if std.isArray(v=managedFields) then managedFields else [managedFields] } },
    '#withManagedFieldsMixin':: d.fn(help="\"ManagedFields maps workflow-id and version to the set of fields that are managed by that workflow. This is mostly for internal housekeeping, and users typically shouldn't need to set or understand this field. A workflow can be the user's name, a controller's name, or the name of a specific apply path like \\\"ci-cd\\\". The set of fields is always in the version that the workflow used when modifying the object.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='managedFields', type=d.T.array)]),
    withManagedFieldsMixin(managedFields): { metadata+: { managedFields+: if std.isArray(v=managedFields) then managedFields else [managedFields] } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of Prometheus', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'monitoring.coreos.com/v1',
    kind: 'Prometheus',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help='"Specification of the desired behavior of the Prometheus cluster. More info: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status"'),
  spec: {
    '#additionalAlertManagerConfigs':: d.obj(help='"AdditionalAlertManagerConfigs allows specifying a key of a Secret containing additional Prometheus AlertManager configurations. AlertManager configurations specified are appended to the configurations generated by the Prometheus Operator. Job configurations specified must have the form as specified in the official Prometheus documentation: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#alertmanager_config. As AlertManager configs are appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible AlertManager configs are going to break Prometheus after the upgrade."'),
    additionalAlertManagerConfigs: {
      '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
      withKey(key): { spec+: { additionalAlertManagerConfigs+: { key: key } } },
      '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { additionalAlertManagerConfigs+: { name: name } } },
      '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
      withOptional(optional): { spec+: { additionalAlertManagerConfigs+: { optional: optional } } },
    },
    '#additionalAlertRelabelConfigs':: d.obj(help='"AdditionalAlertRelabelConfigs allows specifying a key of a Secret containing additional Prometheus alert relabel configurations. Alert relabel configurations specified are appended to the configurations generated by the Prometheus Operator. Alert relabel configurations specified must have the form as specified in the official Prometheus documentation: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#alert_relabel_configs. As alert relabel configs are appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible alert relabel configs are going to break Prometheus after the upgrade."'),
    additionalAlertRelabelConfigs: {
      '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
      withKey(key): { spec+: { additionalAlertRelabelConfigs+: { key: key } } },
      '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { additionalAlertRelabelConfigs+: { name: name } } },
      '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
      withOptional(optional): { spec+: { additionalAlertRelabelConfigs+: { optional: optional } } },
    },
    '#additionalScrapeConfigs':: d.obj(help='"AdditionalScrapeConfigs allows specifying a key of a Secret containing additional Prometheus scrape configurations. Scrape configurations specified are appended to the configurations generated by the Prometheus Operator. Job configurations specified must have the form as specified in the official Prometheus documentation: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config. As scrape configs are appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible scrape configs are going to break Prometheus after the upgrade."'),
    additionalScrapeConfigs: {
      '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
      withKey(key): { spec+: { additionalScrapeConfigs+: { key: key } } },
      '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { additionalScrapeConfigs+: { name: name } } },
      '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
      withOptional(optional): { spec+: { additionalScrapeConfigs+: { optional: optional } } },
    },
    '#affinity':: d.obj(help="\"If specified, the pod's scheduling constraints.\""),
    affinity: {
      '#nodeAffinity':: d.obj(help='"Describes node affinity scheduling rules for the pod."'),
      nodeAffinity: {
        '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node."'),
        requiredDuringSchedulingIgnoredDuringExecution: {
          '#withNodeSelectorTerms':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
          withNodeSelectorTerms(nodeSelectorTerms): { spec+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } },
          '#withNodeSelectorTermsMixin':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
          withNodeSelectorTermsMixin(nodeSelectorTerms): { spec+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms+: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } },
        },
        '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding \\"weight\\" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
        withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } },
        '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding \\"weight\\" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
        withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } },
      },
      '#podAffinity':: d.obj(help='"Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s))."'),
      podAffinity: {
        '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding \\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
        withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } },
        '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding \\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
        withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } },
        '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
        withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } },
        '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
        withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } },
      },
      '#podAntiAffinity':: d.obj(help='"Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s))."'),
      podAntiAffinity: {
        '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding \\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
        withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } },
        '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding \\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
        withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } },
        '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
        withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } },
        '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
        withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } },
      },
    },
    '#alerting':: d.obj(help='"Define details regarding alerting."'),
    alerting: {
      '#withAlertmanagers':: d.fn(help='"AlertmanagerEndpoints Prometheus should fire alerts against."', args=[d.arg(name='alertmanagers', type=d.T.array)]),
      withAlertmanagers(alertmanagers): { spec+: { alerting+: { alertmanagers: if std.isArray(v=alertmanagers) then alertmanagers else [alertmanagers] } } },
      '#withAlertmanagersMixin':: d.fn(help='"AlertmanagerEndpoints Prometheus should fire alerts against."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='alertmanagers', type=d.T.array)]),
      withAlertmanagersMixin(alertmanagers): { spec+: { alerting+: { alertmanagers+: if std.isArray(v=alertmanagers) then alertmanagers else [alertmanagers] } } },
    },
    '#apiserverConfig':: d.obj(help="\"APIServerConfig allows specifying a host and auth methods to access apiserver. If left empty, Prometheus is assumed to run inside of the cluster and will discover API servers automatically and use the pod's CA certificate and bearer token file at /var/run/secrets/kubernetes.io/serviceaccount/.\""),
    apiserverConfig: {
      '#authorization':: d.obj(help='"Authorization section for accessing apiserver"'),
      authorization: {
        '#credentials':: d.obj(help="\"The secret's key that contains the credentials of the request\""),
        credentials: {
          '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { spec+: { apiserverConfig+: { authorization+: { credentials+: { key: key } } } } },
          '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { apiserverConfig+: { authorization+: { credentials+: { name: name } } } } },
          '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
          withOptional(optional): { spec+: { apiserverConfig+: { authorization+: { credentials+: { optional: optional } } } } },
        },
        '#withCredentialsFile':: d.fn(help='"File to read a secret from, mutually exclusive with Credentials (from SafeAuthorization)"', args=[d.arg(name='credentialsFile', type=d.T.string)]),
        withCredentialsFile(credentialsFile): { spec+: { apiserverConfig+: { authorization+: { credentialsFile: credentialsFile } } } },
        '#withType':: d.fn(help='"Set the authentication type. Defaults to Bearer, Basic will cause an error"', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { spec+: { apiserverConfig+: { authorization+: { type: type } } } },
      },
      '#basicAuth':: d.obj(help='"BasicAuth allow an endpoint to authenticate over basic authentication"'),
      basicAuth: {
        '#password':: d.obj(help='"The secret in the service monitor namespace that contains the password for authentication."'),
        password: {
          '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { spec+: { apiserverConfig+: { basicAuth+: { password+: { key: key } } } } },
          '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { apiserverConfig+: { basicAuth+: { password+: { name: name } } } } },
          '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
          withOptional(optional): { spec+: { apiserverConfig+: { basicAuth+: { password+: { optional: optional } } } } },
        },
        '#username':: d.obj(help='"The secret in the service monitor namespace that contains the username for authentication."'),
        username: {
          '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { spec+: { apiserverConfig+: { basicAuth+: { username+: { key: key } } } } },
          '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { apiserverConfig+: { basicAuth+: { username+: { name: name } } } } },
          '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
          withOptional(optional): { spec+: { apiserverConfig+: { basicAuth+: { username+: { optional: optional } } } } },
        },
      },
      '#tlsConfig':: d.obj(help='"TLS Config to use for accessing apiserver."'),
      tlsConfig: {
        '#ca':: d.obj(help='"Struct containing the CA cert to use for the targets."'),
        ca: {
          '#configMap':: d.obj(help='"ConfigMap containing data to use for the targets."'),
          configMap: {
            '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { apiserverConfig+: { tlsConfig+: { ca+: { configMap+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { apiserverConfig+: { tlsConfig+: { ca+: { configMap+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { apiserverConfig+: { tlsConfig+: { ca+: { configMap+: { optional: optional } } } } } },
          },
          '#secret':: d.obj(help='"Secret containing data to use for the targets."'),
          secret: {
            '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { apiserverConfig+: { tlsConfig+: { ca+: { secret+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { apiserverConfig+: { tlsConfig+: { ca+: { secret+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { apiserverConfig+: { tlsConfig+: { ca+: { secret+: { optional: optional } } } } } },
          },
        },
        '#cert':: d.obj(help='"Struct containing the client cert file for the targets."'),
        cert: {
          '#configMap':: d.obj(help='"ConfigMap containing data to use for the targets."'),
          configMap: {
            '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { apiserverConfig+: { tlsConfig+: { cert+: { configMap+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { apiserverConfig+: { tlsConfig+: { cert+: { configMap+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { apiserverConfig+: { tlsConfig+: { cert+: { configMap+: { optional: optional } } } } } },
          },
          '#secret':: d.obj(help='"Secret containing data to use for the targets."'),
          secret: {
            '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { apiserverConfig+: { tlsConfig+: { cert+: { secret+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { apiserverConfig+: { tlsConfig+: { cert+: { secret+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { apiserverConfig+: { tlsConfig+: { cert+: { secret+: { optional: optional } } } } } },
          },
        },
        '#keySecret':: d.obj(help='"Secret containing the client key file for the targets."'),
        keySecret: {
          '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { spec+: { apiserverConfig+: { tlsConfig+: { keySecret+: { key: key } } } } },
          '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { apiserverConfig+: { tlsConfig+: { keySecret+: { name: name } } } } },
          '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
          withOptional(optional): { spec+: { apiserverConfig+: { tlsConfig+: { keySecret+: { optional: optional } } } } },
        },
        '#withCaFile':: d.fn(help='"Path to the CA cert in the Prometheus container to use for the targets."', args=[d.arg(name='caFile', type=d.T.string)]),
        withCaFile(caFile): { spec+: { apiserverConfig+: { tlsConfig+: { caFile: caFile } } } },
        '#withCertFile':: d.fn(help='"Path to the client cert file in the Prometheus container for the targets."', args=[d.arg(name='certFile', type=d.T.string)]),
        withCertFile(certFile): { spec+: { apiserverConfig+: { tlsConfig+: { certFile: certFile } } } },
        '#withInsecureSkipVerify':: d.fn(help='"Disable target certificate validation."', args=[d.arg(name='insecureSkipVerify', type=d.T.boolean)]),
        withInsecureSkipVerify(insecureSkipVerify): { spec+: { apiserverConfig+: { tlsConfig+: { insecureSkipVerify: insecureSkipVerify } } } },
        '#withKeyFile':: d.fn(help='"Path to the client key file in the Prometheus container for the targets."', args=[d.arg(name='keyFile', type=d.T.string)]),
        withKeyFile(keyFile): { spec+: { apiserverConfig+: { tlsConfig+: { keyFile: keyFile } } } },
        '#withServerName':: d.fn(help='"Used to verify the hostname for the targets."', args=[d.arg(name='serverName', type=d.T.string)]),
        withServerName(serverName): { spec+: { apiserverConfig+: { tlsConfig+: { serverName: serverName } } } },
      },
      '#withBearerToken':: d.fn(help='"Bearer token for accessing apiserver."', args=[d.arg(name='bearerToken', type=d.T.string)]),
      withBearerToken(bearerToken): { spec+: { apiserverConfig+: { bearerToken: bearerToken } } },
      '#withBearerTokenFile':: d.fn(help='"File to read bearer token for accessing apiserver."', args=[d.arg(name='bearerTokenFile', type=d.T.string)]),
      withBearerTokenFile(bearerTokenFile): { spec+: { apiserverConfig+: { bearerTokenFile: bearerTokenFile } } },
      '#withHost':: d.fn(help='"Host of apiserver. A valid string consisting of a hostname or IP followed by an optional port number"', args=[d.arg(name='host', type=d.T.string)]),
      withHost(host): { spec+: { apiserverConfig+: { host: host } } },
    },
    '#arbitraryFSAccessThroughSMs':: d.obj(help='"ArbitraryFSAccessThroughSMs configures whether configuration based on a service monitor can access arbitrary files on the file system of the Prometheus container e.g. bearer token files."'),
    arbitraryFSAccessThroughSMs: {
      '#withDeny':: d.fn(help='', args=[d.arg(name='deny', type=d.T.boolean)]),
      withDeny(deny): { spec+: { arbitraryFSAccessThroughSMs+: { deny: deny } } },
    },
    '#podMetadata':: d.obj(help='"PodMetadata configures Labels and Annotations which are propagated to the prometheus pods."'),
    podMetadata: {
      '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotations(annotations): { spec+: { podMetadata+: { annotations: annotations } } },
      '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotationsMixin(annotations): { spec+: { podMetadata+: { annotations+: annotations } } },
      '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
      withLabels(labels): { spec+: { podMetadata+: { labels: labels } } },
      '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
      withLabelsMixin(labels): { spec+: { podMetadata+: { labels+: labels } } },
      '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { podMetadata+: { name: name } } },
    },
    '#podMonitorNamespaceSelector':: d.obj(help="\"Namespace's labels to match for PodMonitor discovery. If nil, only check own namespace.\""),
    podMonitorNamespaceSelector: {
      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressions(matchExpressions): { spec+: { podMonitorNamespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressionsMixin(matchExpressions): { spec+: { podMonitorNamespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabels(matchLabels): { spec+: { podMonitorNamespaceSelector+: { matchLabels: matchLabels } } },
      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabelsMixin(matchLabels): { spec+: { podMonitorNamespaceSelector+: { matchLabels+: matchLabels } } },
    },
    '#podMonitorSelector':: d.obj(help='"*Experimental* PodMonitors to be selected for target discovery. *Deprecated:* if neither this nor serviceMonitorSelector are specified, configuration is unmanaged."'),
    podMonitorSelector: {
      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressions(matchExpressions): { spec+: { podMonitorSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressionsMixin(matchExpressions): { spec+: { podMonitorSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabels(matchLabels): { spec+: { podMonitorSelector+: { matchLabels: matchLabels } } },
      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabelsMixin(matchLabels): { spec+: { podMonitorSelector+: { matchLabels+: matchLabels } } },
    },
    '#probeNamespaceSelector':: d.obj(help='"*Experimental* Namespaces to be selected for Probe discovery. If nil, only check own namespace."'),
    probeNamespaceSelector: {
      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressions(matchExpressions): { spec+: { probeNamespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressionsMixin(matchExpressions): { spec+: { probeNamespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabels(matchLabels): { spec+: { probeNamespaceSelector+: { matchLabels: matchLabels } } },
      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabelsMixin(matchLabels): { spec+: { probeNamespaceSelector+: { matchLabels+: matchLabels } } },
    },
    '#probeSelector':: d.obj(help='"*Experimental* Probes to be selected for target discovery."'),
    probeSelector: {
      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressions(matchExpressions): { spec+: { probeSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressionsMixin(matchExpressions): { spec+: { probeSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabels(matchLabels): { spec+: { probeSelector+: { matchLabels: matchLabels } } },
      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabelsMixin(matchLabels): { spec+: { probeSelector+: { matchLabels+: matchLabels } } },
    },
    '#query':: d.obj(help='"QuerySpec defines the query command line flags when starting Prometheus."'),
    query: {
      '#withLookbackDelta':: d.fn(help='"The delta difference allowed for retrieving metrics during expression evaluations."', args=[d.arg(name='lookbackDelta', type=d.T.string)]),
      withLookbackDelta(lookbackDelta): { spec+: { query+: { lookbackDelta: lookbackDelta } } },
      '#withMaxConcurrency':: d.fn(help='"Number of concurrent queries that can be run at once."', args=[d.arg(name='maxConcurrency', type=d.T.integer)]),
      withMaxConcurrency(maxConcurrency): { spec+: { query+: { maxConcurrency: maxConcurrency } } },
      '#withMaxSamples':: d.fn(help='"Maximum number of samples a single query can load into memory. Note that queries will fail if they would load more samples than this into memory, so this also limits the number of samples a query can return."', args=[d.arg(name='maxSamples', type=d.T.integer)]),
      withMaxSamples(maxSamples): { spec+: { query+: { maxSamples: maxSamples } } },
      '#withTimeout':: d.fn(help='"Maximum time a query may take before being aborted."', args=[d.arg(name='timeout', type=d.T.string)]),
      withTimeout(timeout): { spec+: { query+: { timeout: timeout } } },
    },
    '#resources':: d.obj(help='"Define resources requests and limits for single Pods."'),
    resources: {
      '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
      withLimits(limits): { spec+: { resources+: { limits: limits } } },
      '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
      withLimitsMixin(limits): { spec+: { resources+: { limits+: limits } } },
      '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
      withRequests(requests): { spec+: { resources+: { requests: requests } } },
      '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
      withRequestsMixin(requests): { spec+: { resources+: { requests+: requests } } },
    },
    '#ruleNamespaceSelector':: d.obj(help='"Namespaces to be selected for PrometheusRules discovery. If unspecified, only the same namespace as the Prometheus object is in is used."'),
    ruleNamespaceSelector: {
      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressions(matchExpressions): { spec+: { ruleNamespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressionsMixin(matchExpressions): { spec+: { ruleNamespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabels(matchLabels): { spec+: { ruleNamespaceSelector+: { matchLabels: matchLabels } } },
      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabelsMixin(matchLabels): { spec+: { ruleNamespaceSelector+: { matchLabels+: matchLabels } } },
    },
    '#ruleSelector':: d.obj(help='"A selector to select which PrometheusRules to mount for loading alerting/recording rules from. Until (excluding) Prometheus Operator v0.24.0 Prometheus Operator will migrate any legacy rule ConfigMaps to PrometheusRule custom resources selected by RuleSelector. Make sure it does not match any config maps that you do not want to be migrated."'),
    ruleSelector: {
      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressions(matchExpressions): { spec+: { ruleSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressionsMixin(matchExpressions): { spec+: { ruleSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabels(matchLabels): { spec+: { ruleSelector+: { matchLabels: matchLabels } } },
      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabelsMixin(matchLabels): { spec+: { ruleSelector+: { matchLabels+: matchLabels } } },
    },
    '#rules':: d.obj(help='"/--rules.*/ command-line arguments."'),
    rules: {
      '#alert':: d.obj(help='"/--rules.alert.*/ command-line arguments"'),
      alert: {
        '#withForGracePeriod':: d.fn(help="\"Minimum duration between alert and restored 'for' state. This is maintained only for alerts with configured 'for' time greater than grace period.\"", args=[d.arg(name='forGracePeriod', type=d.T.string)]),
        withForGracePeriod(forGracePeriod): { spec+: { rules+: { alert+: { forGracePeriod: forGracePeriod } } } },
        '#withForOutageTolerance':: d.fn(help="\"Max time to tolerate prometheus outage for restoring 'for' state of alert.\"", args=[d.arg(name='forOutageTolerance', type=d.T.string)]),
        withForOutageTolerance(forOutageTolerance): { spec+: { rules+: { alert+: { forOutageTolerance: forOutageTolerance } } } },
        '#withResendDelay':: d.fn(help='"Minimum amount of time to wait before resending an alert to Alertmanager."', args=[d.arg(name='resendDelay', type=d.T.string)]),
        withResendDelay(resendDelay): { spec+: { rules+: { alert+: { resendDelay: resendDelay } } } },
      },
    },
    '#securityContext':: d.obj(help='"SecurityContext holds pod-level security attributes and common container settings. This defaults to the default PodSecurityContext."'),
    securityContext: {
      '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to all containers. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container. Note that this field cannot be set when spec.os.name is windows."'),
      seLinuxOptions: {
        '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
        withLevel(level): { spec+: { securityContext+: { seLinuxOptions+: { level: level } } } },
        '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
        withRole(role): { spec+: { securityContext+: { seLinuxOptions+: { role: role } } } },
        '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { spec+: { securityContext+: { seLinuxOptions+: { type: type } } } },
        '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
        withUser(user): { spec+: { securityContext+: { seLinuxOptions+: { user: user } } } },
      },
      '#seccompProfile':: d.obj(help='"The seccomp options to use by the containers in this pod. Note that this field cannot be set when spec.os.name is windows."'),
      seccompProfile: {
        '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used. The profile must be preconfigured on the node to work. Must be a descending path, relative to the kubelet's configured seccomp profile location. Must only be set if type is \\\"Localhost\\\".\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
        withLocalhostProfile(localhostProfile): { spec+: { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } },
        '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied. Valid options are: \\n Localhost - a profile defined in a file on the node should be used. RuntimeDefault - the container runtime default profile should be used. Unconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { spec+: { securityContext+: { seccompProfile+: { type: type } } } },
      },
      '#windowsOptions':: d.obj(help="\"The Windows specific settings applied to all containers. If unspecified, the options within a container's SecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence. Note that this field cannot be set when spec.os.name is linux.\""),
      windowsOptions: {
        '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
        withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } },
        '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
        withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } },
        '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container. This field is alpha-level and will only be honored by components that enable the WindowsHostProcessContainers feature flag. Setting this field without the feature flag will result in errors when validating the Pod. All of a Pod's containers must have the same effective HostProcess value (it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).  In addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
        withHostProcess(hostProcess): { spec+: { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } } },
        '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
        withRunAsUserName(runAsUserName): { spec+: { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } },
      },
      '#withFsGroup':: d.fn(help="\"A special supplemental group that applies to all containers in a pod. Some volume types allow the Kubelet to change the ownership of that volume to be owned by the pod: \\n 1. The owning GID will be the FSGroup 2. The setgid bit is set (new files created in the volume will be owned by FSGroup) 3. The permission bits are OR'd with rw-rw---- \\n If unset, the Kubelet will not modify the ownership and permissions of any volume. Note that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='fsGroup', type=d.T.integer)]),
      withFsGroup(fsGroup): { spec+: { securityContext+: { fsGroup: fsGroup } } },
      '#withFsGroupChangePolicy':: d.fn(help='"fsGroupChangePolicy defines behavior of changing ownership and permission of the volume before being exposed inside Pod. This field will only apply to volume types which support fsGroup based ownership(and permissions). It will have no effect on ephemeral volume types such as: secret, configmaps and emptydir. Valid values are \\"OnRootMismatch\\" and \\"Always\\". If not specified, \\"Always\\" is used. Note that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='fsGroupChangePolicy', type=d.T.string)]),
      withFsGroupChangePolicy(fsGroupChangePolicy): { spec+: { securityContext+: { fsGroupChangePolicy: fsGroupChangePolicy } } },
      '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container. Note that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
      withRunAsGroup(runAsGroup): { spec+: { securityContext+: { runAsGroup: runAsGroup } } },
      '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
      withRunAsNonRoot(runAsNonRoot): { spec+: { securityContext+: { runAsNonRoot: runAsNonRoot } } },
      '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container. Note that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
      withRunAsUser(runAsUser): { spec+: { securityContext+: { runAsUser: runAsUser } } },
      '#withSupplementalGroups':: d.fn(help="\"A list of groups applied to the first process run in each container, in addition to the container's primary GID.  If unspecified, no groups will be added to any container. Note that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
      withSupplementalGroups(supplementalGroups): { spec+: { securityContext+: { supplementalGroups: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } },
      '#withSupplementalGroupsMixin':: d.fn(help="\"A list of groups applied to the first process run in each container, in addition to the container's primary GID.  If unspecified, no groups will be added to any container. Note that this field cannot be set when spec.os.name is windows.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
      withSupplementalGroupsMixin(supplementalGroups): { spec+: { securityContext+: { supplementalGroups+: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } },
      '#withSysctls':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported sysctls (by the container runtime) might fail to launch. Note that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='sysctls', type=d.T.array)]),
      withSysctls(sysctls): { spec+: { securityContext+: { sysctls: if std.isArray(v=sysctls) then sysctls else [sysctls] } } },
      '#withSysctlsMixin':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported sysctls (by the container runtime) might fail to launch. Note that this field cannot be set when spec.os.name is windows."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sysctls', type=d.T.array)]),
      withSysctlsMixin(sysctls): { spec+: { securityContext+: { sysctls+: if std.isArray(v=sysctls) then sysctls else [sysctls] } } },
    },
    '#serviceMonitorNamespaceSelector':: d.obj(help="\"Namespace's labels to match for ServiceMonitor discovery. If nil, only check own namespace.\""),
    serviceMonitorNamespaceSelector: {
      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressions(matchExpressions): { spec+: { serviceMonitorNamespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressionsMixin(matchExpressions): { spec+: { serviceMonitorNamespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabels(matchLabels): { spec+: { serviceMonitorNamespaceSelector+: { matchLabels: matchLabels } } },
      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabelsMixin(matchLabels): { spec+: { serviceMonitorNamespaceSelector+: { matchLabels+: matchLabels } } },
    },
    '#serviceMonitorSelector':: d.obj(help='"ServiceMonitors to be selected for target discovery. *Deprecated:* if neither this nor podMonitorSelector are specified, configuration is unmanaged."'),
    serviceMonitorSelector: {
      '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressions(matchExpressions): { spec+: { serviceMonitorSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
      withMatchExpressionsMixin(matchExpressions): { spec+: { serviceMonitorSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
      '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabels(matchLabels): { spec+: { serviceMonitorSelector+: { matchLabels: matchLabels } } },
      '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
      withMatchLabelsMixin(matchLabels): { spec+: { serviceMonitorSelector+: { matchLabels+: matchLabels } } },
    },
    '#storage':: d.obj(help='"Storage spec to specify how storage shall be used."'),
    storage: {
      '#emptyDir':: d.obj(help='"EmptyDirVolumeSource to be used by the Prometheus StatefulSets. If specified, used in place of any volumeClaimTemplate. More info: https://kubernetes.io/docs/concepts/storage/volumes/#emptydir"'),
      emptyDir: {
        '#withMedium':: d.fn(help="\"What type of storage medium should back this directory. The default is \\\"\\\" which means to use the node's default medium. Must be an empty string (default) or Memory. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir\"", args=[d.arg(name='medium', type=d.T.string)]),
        withMedium(medium): { spec+: { storage+: { emptyDir+: { medium: medium } } } },
        '#withSizeLimit':: d.fn(help='"Total amount of local storage required for this EmptyDir volume. The size limit is also applicable for memory medium. The maximum usage on memory medium EmptyDir would be the minimum value between the SizeLimit specified here and the sum of memory limits of all containers in a pod. The default is nil which means that the limit is undefined. More info: http://kubernetes.io/docs/user-guide/volumes#emptydir"', args=[d.arg(name='sizeLimit', type=d.T.any)]),
        withSizeLimit(sizeLimit): { spec+: { storage+: { emptyDir+: { sizeLimit: sizeLimit } } } },
      },
      '#ephemeral':: d.obj(help='"EphemeralVolumeSource to be used by the Prometheus StatefulSets. This is a beta field in k8s 1.21, for lower versions, starting with k8s 1.19, it requires enabling the GenericEphemeralVolume feature gate. More info: https://kubernetes.io/docs/concepts/storage/ephemeral-volumes/#generic-ephemeral-volumes"'),
      ephemeral: {
        '#volumeClaimTemplate':: d.obj(help='"Will be used to create a stand-alone PVC to provision the volume. The pod in which this EphemeralVolumeSource is embedded will be the owner of the PVC, i.e. the PVC will be deleted together with the pod.  The name of the PVC will be `<pod name>-<volume name>` where `<volume name>` is the name from the `PodSpec.Volumes` array entry. Pod validation will reject the pod if the concatenated name is not valid for a PVC (for example, too long). \\n An existing PVC with that name that is not owned by the pod will *not* be used for the pod to avoid using an unrelated volume by mistake. Starting the pod is then blocked until the unrelated PVC is removed. If such a pre-created PVC is meant to be used by the pod, the PVC has to updated with an owner reference to the pod once the pod exists. Normally this should not be necessary, but it may be useful when manually reconstructing a broken cluster. \\n This field is read-only and no changes will be made by Kubernetes to the PVC after it has been created. \\n Required, must not be nil."'),
        volumeClaimTemplate: {
          '#spec':: d.obj(help='"The specification for the PersistentVolumeClaim. The entire content is copied unchanged into the PVC that gets created from this template. The same fields as in a PersistentVolumeClaim are also valid here."'),
          spec: {
            '#dataSource':: d.obj(help='"This field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field."'),
            dataSource: {
              '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
              withApiGroup(apiGroup): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSource+: { apiGroup: apiGroup } } } } } } },
              '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
              withKind(kind): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSource+: { kind: kind } } } } } } },
              '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSource+: { name: name } } } } } } },
            },
            '#dataSourceRef':: d.obj(help='"Specifies the object from which to populate the volume with data, if a non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef: * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Alpha) Using this field requires the AnyVolumeDataSource feature gate to be enabled."'),
            dataSourceRef: {
              '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
              withApiGroup(apiGroup): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { apiGroup: apiGroup } } } } } } },
              '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
              withKind(kind): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { kind: kind } } } } } } },
              '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { name: name } } } } } } },
            },
            '#resources':: d.obj(help='"Resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"'),
            resources: {
              '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
              withLimits(limits): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { limits: limits } } } } } } },
              '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
              withLimitsMixin(limits): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { limits+: limits } } } } } } },
              '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
              withRequests(requests): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { requests: requests } } } } } } },
              '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
              withRequestsMixin(requests): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { resources+: { requests+: requests } } } } } } },
            },
            '#selector':: d.obj(help='"A label query over volumes to consider for binding."'),
            selector: {
              '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } } } },
              '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } } } },
              '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchLabels: matchLabels } } } } } } },
              '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { selector+: { matchLabels+: matchLabels } } } } } } },
            },
            '#withAccessModes':: d.fn(help='"AccessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"', args=[d.arg(name='accessModes', type=d.T.array)]),
            withAccessModes(accessModes): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { accessModes: if std.isArray(v=accessModes) then accessModes else [accessModes] } } } } } },
            '#withAccessModesMixin':: d.fn(help='"AccessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessModes', type=d.T.array)]),
            withAccessModesMixin(accessModes): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { accessModes+: if std.isArray(v=accessModes) then accessModes else [accessModes] } } } } } },
            '#withStorageClassName':: d.fn(help='"Name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1"', args=[d.arg(name='storageClassName', type=d.T.string)]),
            withStorageClassName(storageClassName): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { storageClassName: storageClassName } } } } } },
            '#withVolumeMode':: d.fn(help='"volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec."', args=[d.arg(name='volumeMode', type=d.T.string)]),
            withVolumeMode(volumeMode): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { volumeMode: volumeMode } } } } } },
            '#withVolumeName':: d.fn(help='"VolumeName is the binding reference to the PersistentVolume backing this claim."', args=[d.arg(name='volumeName', type=d.T.string)]),
            withVolumeName(volumeName): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { spec+: { volumeName: volumeName } } } } } },
          },
          '#withMetadata':: d.fn(help='"May contain labels and annotations that will be copied into the PVC when creating it. No other fields are allowed and will be rejected during validation."', args=[d.arg(name='metadata', type=d.T.object)]),
          withMetadata(metadata): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { metadata: metadata } } } } },
          '#withMetadataMixin':: d.fn(help='"May contain labels and annotations that will be copied into the PVC when creating it. No other fields are allowed and will be rejected during validation."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='metadata', type=d.T.object)]),
          withMetadataMixin(metadata): { spec+: { storage+: { ephemeral+: { volumeClaimTemplate+: { metadata+: metadata } } } } },
        },
      },
      '#volumeClaimTemplate':: d.obj(help='"A PVC spec to be used by the Prometheus StatefulSets."'),
      volumeClaimTemplate: {
        '#metadata':: d.obj(help='"EmbeddedMetadata contains metadata relevant to an EmbeddedResource."'),
        metadata: {
          '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotations(annotations): { spec+: { storage+: { volumeClaimTemplate+: { metadata+: { annotations: annotations } } } } },
          '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotationsMixin(annotations): { spec+: { storage+: { volumeClaimTemplate+: { metadata+: { annotations+: annotations } } } } },
          '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { spec+: { storage+: { volumeClaimTemplate+: { metadata+: { labels: labels } } } } },
          '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { spec+: { storage+: { volumeClaimTemplate+: { metadata+: { labels+: labels } } } } },
          '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { storage+: { volumeClaimTemplate+: { metadata+: { name: name } } } } },
        },
        '#spec':: d.obj(help='"Spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims"'),
        spec: {
          '#dataSource':: d.obj(help='"This field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field."'),
          dataSource: {
            '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
            withApiGroup(apiGroup): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { dataSource+: { apiGroup: apiGroup } } } } } },
            '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
            withKind(kind): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { dataSource+: { kind: kind } } } } } },
            '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { dataSource+: { name: name } } } } } },
          },
          '#dataSourceRef':: d.obj(help='"Specifies the object from which to populate the volume with data, if a non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef: * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Alpha) Using this field requires the AnyVolumeDataSource feature gate to be enabled."'),
          dataSourceRef: {
            '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
            withApiGroup(apiGroup): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { apiGroup: apiGroup } } } } } },
            '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
            withKind(kind): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { kind: kind } } } } } },
            '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { dataSourceRef+: { name: name } } } } } },
          },
          '#resources':: d.obj(help='"Resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"'),
          resources: {
            '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
            withLimits(limits): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { resources+: { limits: limits } } } } } },
            '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
            withLimitsMixin(limits): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { resources+: { limits+: limits } } } } } },
            '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
            withRequests(requests): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { resources+: { requests: requests } } } } } },
            '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
            withRequestsMixin(requests): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { resources+: { requests+: requests } } } } } },
          },
          '#selector':: d.obj(help='"A label query over volumes to consider for binding."'),
          selector: {
            '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
            withMatchExpressions(matchExpressions): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } } },
            '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
            withMatchExpressionsMixin(matchExpressions): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } } },
            '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabels(matchLabels): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { selector+: { matchLabels: matchLabels } } } } } },
            '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\"key\\", the operator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabelsMixin(matchLabels): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { selector+: { matchLabels+: matchLabels } } } } } },
          },
          '#withAccessModes':: d.fn(help='"AccessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"', args=[d.arg(name='accessModes', type=d.T.array)]),
          withAccessModes(accessModes): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { accessModes: if std.isArray(v=accessModes) then accessModes else [accessModes] } } } } },
          '#withAccessModesMixin':: d.fn(help='"AccessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessModes', type=d.T.array)]),
          withAccessModesMixin(accessModes): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { accessModes+: if std.isArray(v=accessModes) then accessModes else [accessModes] } } } } },
          '#withStorageClassName':: d.fn(help='"Name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1"', args=[d.arg(name='storageClassName', type=d.T.string)]),
          withStorageClassName(storageClassName): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { storageClassName: storageClassName } } } } },
          '#withVolumeMode':: d.fn(help='"volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec."', args=[d.arg(name='volumeMode', type=d.T.string)]),
          withVolumeMode(volumeMode): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { volumeMode: volumeMode } } } } },
          '#withVolumeName':: d.fn(help='"VolumeName is the binding reference to the PersistentVolume backing this claim."', args=[d.arg(name='volumeName', type=d.T.string)]),
          withVolumeName(volumeName): { spec+: { storage+: { volumeClaimTemplate+: { spec+: { volumeName: volumeName } } } } },
        },
        '#withApiVersion':: d.fn(help='"APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources"', args=[d.arg(name='apiVersion', type=d.T.string)]),
        withApiVersion(apiVersion): { spec+: { storage+: { volumeClaimTemplate+: { apiVersion: apiVersion } } } },
        '#withKind':: d.fn(help='"Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds"', args=[d.arg(name='kind', type=d.T.string)]),
        withKind(kind): { spec+: { storage+: { volumeClaimTemplate+: { kind: kind } } } },
      },
      '#withDisableMountSubPath':: d.fn(help='"Deprecated: subPath usage will be disabled by default in a future release, this option will become unnecessary. DisableMountSubPath allows to remove any subPath usage in volume mounts."', args=[d.arg(name='disableMountSubPath', type=d.T.boolean)]),
      withDisableMountSubPath(disableMountSubPath): { spec+: { storage+: { disableMountSubPath: disableMountSubPath } } },
    },
    '#thanos':: d.obj(help='"Thanos configuration allows configuring various aspects of a Prometheus server in a Thanos environment. \\n This section is experimental, it may change significantly without deprecation notice in any release. \\n This is experimental and may change significantly without backward compatibility in any release."'),
    thanos: {
      '#grpcServerTlsConfig':: d.obj(help="\"GRPCServerTLSConfig configures the gRPC server from which Thanos Querier reads recorded rule data. Note: Currently only the CAFile, CertFile, and KeyFile fields are supported. Maps to the '--grpc-server-tls-*' CLI args.\""),
      grpcServerTlsConfig: {
        '#ca':: d.obj(help='"Struct containing the CA cert to use for the targets."'),
        ca: {
          '#configMap':: d.obj(help='"ConfigMap containing data to use for the targets."'),
          configMap: {
            '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { thanos+: { grpcServerTlsConfig+: { ca+: { configMap+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { thanos+: { grpcServerTlsConfig+: { ca+: { configMap+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { thanos+: { grpcServerTlsConfig+: { ca+: { configMap+: { optional: optional } } } } } },
          },
          '#secret':: d.obj(help='"Secret containing data to use for the targets."'),
          secret: {
            '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { thanos+: { grpcServerTlsConfig+: { ca+: { secret+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { thanos+: { grpcServerTlsConfig+: { ca+: { secret+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { thanos+: { grpcServerTlsConfig+: { ca+: { secret+: { optional: optional } } } } } },
          },
        },
        '#cert':: d.obj(help='"Struct containing the client cert file for the targets."'),
        cert: {
          '#configMap':: d.obj(help='"ConfigMap containing data to use for the targets."'),
          configMap: {
            '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { thanos+: { grpcServerTlsConfig+: { cert+: { configMap+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { thanos+: { grpcServerTlsConfig+: { cert+: { configMap+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { thanos+: { grpcServerTlsConfig+: { cert+: { configMap+: { optional: optional } } } } } },
          },
          '#secret':: d.obj(help='"Secret containing data to use for the targets."'),
          secret: {
            '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { thanos+: { grpcServerTlsConfig+: { cert+: { secret+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { thanos+: { grpcServerTlsConfig+: { cert+: { secret+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { thanos+: { grpcServerTlsConfig+: { cert+: { secret+: { optional: optional } } } } } },
          },
        },
        '#keySecret':: d.obj(help='"Secret containing the client key file for the targets."'),
        keySecret: {
          '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { spec+: { thanos+: { grpcServerTlsConfig+: { keySecret+: { key: key } } } } },
          '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { thanos+: { grpcServerTlsConfig+: { keySecret+: { name: name } } } } },
          '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
          withOptional(optional): { spec+: { thanos+: { grpcServerTlsConfig+: { keySecret+: { optional: optional } } } } },
        },
        '#withCaFile':: d.fn(help='"Path to the CA cert in the Prometheus container to use for the targets."', args=[d.arg(name='caFile', type=d.T.string)]),
        withCaFile(caFile): { spec+: { thanos+: { grpcServerTlsConfig+: { caFile: caFile } } } },
        '#withCertFile':: d.fn(help='"Path to the client cert file in the Prometheus container for the targets."', args=[d.arg(name='certFile', type=d.T.string)]),
        withCertFile(certFile): { spec+: { thanos+: { grpcServerTlsConfig+: { certFile: certFile } } } },
        '#withInsecureSkipVerify':: d.fn(help='"Disable target certificate validation."', args=[d.arg(name='insecureSkipVerify', type=d.T.boolean)]),
        withInsecureSkipVerify(insecureSkipVerify): { spec+: { thanos+: { grpcServerTlsConfig+: { insecureSkipVerify: insecureSkipVerify } } } },
        '#withKeyFile':: d.fn(help='"Path to the client key file in the Prometheus container for the targets."', args=[d.arg(name='keyFile', type=d.T.string)]),
        withKeyFile(keyFile): { spec+: { thanos+: { grpcServerTlsConfig+: { keyFile: keyFile } } } },
        '#withServerName':: d.fn(help='"Used to verify the hostname for the targets."', args=[d.arg(name='serverName', type=d.T.string)]),
        withServerName(serverName): { spec+: { thanos+: { grpcServerTlsConfig+: { serverName: serverName } } } },
      },
      '#objectStorageConfig':: d.obj(help='"ObjectStorageConfig configures object storage in Thanos. Alternative to ObjectStorageConfigFile, and lower order priority."'),
      objectStorageConfig: {
        '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
        withKey(key): { spec+: { thanos+: { objectStorageConfig+: { key: key } } } },
        '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { thanos+: { objectStorageConfig+: { name: name } } } },
        '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
        withOptional(optional): { spec+: { thanos+: { objectStorageConfig+: { optional: optional } } } },
      },
      '#resources':: d.obj(help='"Resources defines the resource requirements for the Thanos sidecar. If not provided, no requests/limits will be set"'),
      resources: {
        '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
        withLimits(limits): { spec+: { thanos+: { resources+: { limits: limits } } } },
        '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
        withLimitsMixin(limits): { spec+: { thanos+: { resources+: { limits+: limits } } } },
        '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
        withRequests(requests): { spec+: { thanos+: { resources+: { requests: requests } } } },
        '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
        withRequestsMixin(requests): { spec+: { thanos+: { resources+: { requests+: requests } } } },
      },
      '#tracingConfig':: d.obj(help='"TracingConfig configures tracing in Thanos. This is an experimental feature, it may change in any upcoming release in a breaking way."'),
      tracingConfig: {
        '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
        withKey(key): { spec+: { thanos+: { tracingConfig+: { key: key } } } },
        '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { thanos+: { tracingConfig+: { name: name } } } },
        '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
        withOptional(optional): { spec+: { thanos+: { tracingConfig+: { optional: optional } } } },
      },
      '#withBaseImage':: d.fn(help="\"Thanos base image if other than default. Deprecated: use 'image' instead\"", args=[d.arg(name='baseImage', type=d.T.string)]),
      withBaseImage(baseImage): { spec+: { thanos+: { baseImage: baseImage } } },
      '#withImage':: d.fn(help='"Image if specified has precedence over baseImage, tag and sha combinations. Specifying the version is still necessary to ensure the Prometheus Operator knows what version of Thanos is being configured."', args=[d.arg(name='image', type=d.T.string)]),
      withImage(image): { spec+: { thanos+: { image: image } } },
      '#withListenLocal':: d.fn(help='"ListenLocal makes the Thanos sidecar listen on loopback, so that it does not bind against the Pod IP."', args=[d.arg(name='listenLocal', type=d.T.boolean)]),
      withListenLocal(listenLocal): { spec+: { thanos+: { listenLocal: listenLocal } } },
      '#withLogFormat':: d.fn(help='"LogFormat for Thanos sidecar to be configured with."', args=[d.arg(name='logFormat', type=d.T.string)]),
      withLogFormat(logFormat): { spec+: { thanos+: { logFormat: logFormat } } },
      '#withLogLevel':: d.fn(help='"LogLevel for Thanos sidecar to be configured with."', args=[d.arg(name='logLevel', type=d.T.string)]),
      withLogLevel(logLevel): { spec+: { thanos+: { logLevel: logLevel } } },
      '#withMinTime':: d.fn(help='"MinTime for Thanos sidecar to be configured with. Option can be a constant time in RFC3339 format or time duration relative to current time, such as -1d or 2h45m. Valid duration units are ms, s, m, h, d, w, y."', args=[d.arg(name='minTime', type=d.T.string)]),
      withMinTime(minTime): { spec+: { thanos+: { minTime: minTime } } },
      '#withObjectStorageConfigFile':: d.fn(help='"ObjectStorageConfigFile specifies the path of the object storage configuration file. When used alongside with ObjectStorageConfig, ObjectStorageConfigFile takes precedence."', args=[d.arg(name='objectStorageConfigFile', type=d.T.string)]),
      withObjectStorageConfigFile(objectStorageConfigFile): { spec+: { thanos+: { objectStorageConfigFile: objectStorageConfigFile } } },
      '#withReadyTimeout':: d.fn(help='"ReadyTimeout is the maximum time Thanos sidecar will wait for Prometheus to start. Eg 10m"', args=[d.arg(name='readyTimeout', type=d.T.string)]),
      withReadyTimeout(readyTimeout): { spec+: { thanos+: { readyTimeout: readyTimeout } } },
      '#withSha':: d.fn(help="\"SHA of Thanos container image to be deployed. Defaults to the value of `version`. Similar to a tag, but the SHA explicitly deploys an immutable container image. Version and Tag are ignored if SHA is set. Deprecated: use 'image' instead.  The image digest can be specified as part of the image URL.\"", args=[d.arg(name='sha', type=d.T.string)]),
      withSha(sha): { spec+: { thanos+: { sha: sha } } },
      '#withTag':: d.fn(help="\"Tag of Thanos sidecar container image to be deployed. Defaults to the value of `version`. Version is ignored if Tag is set. Deprecated: use 'image' instead.  The image tag can be specified as part of the image URL.\"", args=[d.arg(name='tag', type=d.T.string)]),
      withTag(tag): { spec+: { thanos+: { tag: tag } } },
      '#withTracingConfigFile':: d.fn(help='"TracingConfig specifies the path of the tracing configuration file. When used alongside with TracingConfig, TracingConfigFile takes precedence."', args=[d.arg(name='tracingConfigFile', type=d.T.string)]),
      withTracingConfigFile(tracingConfigFile): { spec+: { thanos+: { tracingConfigFile: tracingConfigFile } } },
      '#withVersion':: d.fn(help='"Version describes the version of Thanos to use."', args=[d.arg(name='version', type=d.T.string)]),
      withVersion(version): { spec+: { thanos+: { version: version } } },
      '#withVolumeMounts':: d.fn(help='"VolumeMounts allows configuration of additional VolumeMounts on the output StatefulSet definition. VolumeMounts specified will be appended to other VolumeMounts in the thanos-sidecar container."', args=[d.arg(name='volumeMounts', type=d.T.array)]),
      withVolumeMounts(volumeMounts): { spec+: { thanos+: { volumeMounts: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] } } },
      '#withVolumeMountsMixin':: d.fn(help='"VolumeMounts allows configuration of additional VolumeMounts on the output StatefulSet definition. VolumeMounts specified will be appended to other VolumeMounts in the thanos-sidecar container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumeMounts', type=d.T.array)]),
      withVolumeMountsMixin(volumeMounts): { spec+: { thanos+: { volumeMounts+: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] } } },
    },
    '#web':: d.obj(help='"WebSpec defines the web command line flags when starting Prometheus."'),
    web: {
      '#tlsConfig':: d.obj(help='"WebTLSConfig defines the TLS parameters for HTTPS."'),
      tlsConfig: {
        '#cert':: d.obj(help='"Contains the TLS certificate for the server."'),
        cert: {
          '#configMap':: d.obj(help='"ConfigMap containing data to use for the targets."'),
          configMap: {
            '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { web+: { tlsConfig+: { cert+: { configMap+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { web+: { tlsConfig+: { cert+: { configMap+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { web+: { tlsConfig+: { cert+: { configMap+: { optional: optional } } } } } },
          },
          '#secret':: d.obj(help='"Secret containing data to use for the targets."'),
          secret: {
            '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { web+: { tlsConfig+: { cert+: { secret+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { web+: { tlsConfig+: { cert+: { secret+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { web+: { tlsConfig+: { cert+: { secret+: { optional: optional } } } } } },
          },
        },
        '#client_ca':: d.obj(help='"Contains the CA certificate for client certificate authentication to the server."'),
        client_ca: {
          '#configMap':: d.obj(help='"ConfigMap containing data to use for the targets."'),
          configMap: {
            '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { web+: { tlsConfig+: { client_ca+: { configMap+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { web+: { tlsConfig+: { client_ca+: { configMap+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { web+: { tlsConfig+: { client_ca+: { configMap+: { optional: optional } } } } } },
          },
          '#secret':: d.obj(help='"Secret containing data to use for the targets."'),
          secret: {
            '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { spec+: { web+: { tlsConfig+: { client_ca+: { secret+: { key: key } } } } } },
            '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { web+: { tlsConfig+: { client_ca+: { secret+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { web+: { tlsConfig+: { client_ca+: { secret+: { optional: optional } } } } } },
          },
        },
        '#keySecret':: d.obj(help='"Secret containing the TLS key for the server."'),
        keySecret: {
          '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { spec+: { web+: { tlsConfig+: { keySecret+: { key: key } } } } },
          '#withName':: d.fn(help='"Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { web+: { tlsConfig+: { keySecret+: { name: name } } } } },
          '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
          withOptional(optional): { spec+: { web+: { tlsConfig+: { keySecret+: { optional: optional } } } } },
        },
        '#withCipherSuites':: d.fn(help='"List of supported cipher suites for TLS versions up to TLS 1.2. If empty, Go default cipher suites are used. Available cipher suites are documented in the go documentation: https://golang.org/pkg/crypto/tls/#pkg-constants"', args=[d.arg(name='cipherSuites', type=d.T.array)]),
        withCipherSuites(cipherSuites): { spec+: { web+: { tlsConfig+: { cipherSuites: if std.isArray(v=cipherSuites) then cipherSuites else [cipherSuites] } } } },
        '#withCipherSuitesMixin':: d.fn(help='"List of supported cipher suites for TLS versions up to TLS 1.2. If empty, Go default cipher suites are used. Available cipher suites are documented in the go documentation: https://golang.org/pkg/crypto/tls/#pkg-constants"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='cipherSuites', type=d.T.array)]),
        withCipherSuitesMixin(cipherSuites): { spec+: { web+: { tlsConfig+: { cipherSuites+: if std.isArray(v=cipherSuites) then cipherSuites else [cipherSuites] } } } },
        '#withClientAuthType':: d.fn(help='"Server policy for client authentication. Maps to ClientAuth Policies. For more detail on clientAuth options: https://golang.org/pkg/crypto/tls/#ClientAuthType"', args=[d.arg(name='clientAuthType', type=d.T.string)]),
        withClientAuthType(clientAuthType): { spec+: { web+: { tlsConfig+: { clientAuthType: clientAuthType } } } },
        '#withCurvePreferences':: d.fn(help='"Elliptic curves that will be used in an ECDHE handshake, in preference order. Available curves are documented in the go documentation: https://golang.org/pkg/crypto/tls/#CurveID"', args=[d.arg(name='curvePreferences', type=d.T.array)]),
        withCurvePreferences(curvePreferences): { spec+: { web+: { tlsConfig+: { curvePreferences: if std.isArray(v=curvePreferences) then curvePreferences else [curvePreferences] } } } },
        '#withCurvePreferencesMixin':: d.fn(help='"Elliptic curves that will be used in an ECDHE handshake, in preference order. Available curves are documented in the go documentation: https://golang.org/pkg/crypto/tls/#CurveID"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='curvePreferences', type=d.T.array)]),
        withCurvePreferencesMixin(curvePreferences): { spec+: { web+: { tlsConfig+: { curvePreferences+: if std.isArray(v=curvePreferences) then curvePreferences else [curvePreferences] } } } },
        '#withMaxVersion':: d.fn(help='"Maximum TLS version that is acceptable. Defaults to TLS13."', args=[d.arg(name='maxVersion', type=d.T.string)]),
        withMaxVersion(maxVersion): { spec+: { web+: { tlsConfig+: { maxVersion: maxVersion } } } },
        '#withMinVersion':: d.fn(help='"Minimum TLS version that is acceptable. Defaults to TLS12."', args=[d.arg(name='minVersion', type=d.T.string)]),
        withMinVersion(minVersion): { spec+: { web+: { tlsConfig+: { minVersion: minVersion } } } },
        '#withPreferServerCipherSuites':: d.fn(help="\"Controls whether the server selects the client's most preferred cipher suite, or the server's most preferred cipher suite. If true then the server's preference, as expressed in the order of elements in cipherSuites, is used.\"", args=[d.arg(name='preferServerCipherSuites', type=d.T.boolean)]),
        withPreferServerCipherSuites(preferServerCipherSuites): { spec+: { web+: { tlsConfig+: { preferServerCipherSuites: preferServerCipherSuites } } } },
      },
      '#withPageTitle':: d.fn(help='"The prometheus web page title"', args=[d.arg(name='pageTitle', type=d.T.string)]),
      withPageTitle(pageTitle): { spec+: { web+: { pageTitle: pageTitle } } },
    },
    '#withAllowOverlappingBlocks':: d.fn(help='"AllowOverlappingBlocks enables vertical compaction and vertical query merge in Prometheus. This is still experimental in Prometheus so it may change in any upcoming release."', args=[d.arg(name='allowOverlappingBlocks', type=d.T.boolean)]),
    withAllowOverlappingBlocks(allowOverlappingBlocks): { spec+: { allowOverlappingBlocks: allowOverlappingBlocks } },
    '#withBaseImage':: d.fn(help="\"Base image to use for a Prometheus deployment. Deprecated: use 'image' instead\"", args=[d.arg(name='baseImage', type=d.T.string)]),
    withBaseImage(baseImage): { spec+: { baseImage: baseImage } },
    '#withConfigMaps':: d.fn(help='"ConfigMaps is a list of ConfigMaps in the same namespace as the Prometheus object, which shall be mounted into the Prometheus Pods. The ConfigMaps are mounted into /etc/prometheus/configmaps/<configmap-name>."', args=[d.arg(name='configMaps', type=d.T.array)]),
    withConfigMaps(configMaps): { spec+: { configMaps: if std.isArray(v=configMaps) then configMaps else [configMaps] } },
    '#withConfigMapsMixin':: d.fn(help='"ConfigMaps is a list of ConfigMaps in the same namespace as the Prometheus object, which shall be mounted into the Prometheus Pods. The ConfigMaps are mounted into /etc/prometheus/configmaps/<configmap-name>."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='configMaps', type=d.T.array)]),
    withConfigMapsMixin(configMaps): { spec+: { configMaps+: if std.isArray(v=configMaps) then configMaps else [configMaps] } },
    '#withContainers':: d.fn(help='"Containers allows injecting additional containers or modifying operator generated containers. This can be used to allow adding an authentication proxy to a Prometheus pod or to change the behavior of an operator generated container. Containers described here modify an operator generated container if they share the same name and modifications are done via a strategic merge patch. The current container names are: `prometheus`, `config-reloader`, and `thanos-sidecar`. Overriding containers is entirely outside the scope of what the maintainers will support and by doing so, you accept that this behaviour may break at any time without notice."', args=[d.arg(name='containers', type=d.T.array)]),
    withContainers(containers): { spec+: { containers: if std.isArray(v=containers) then containers else [containers] } },
    '#withContainersMixin':: d.fn(help='"Containers allows injecting additional containers or modifying operator generated containers. This can be used to allow adding an authentication proxy to a Prometheus pod or to change the behavior of an operator generated container. Containers described here modify an operator generated container if they share the same name and modifications are done via a strategic merge patch. The current container names are: `prometheus`, `config-reloader`, and `thanos-sidecar`. Overriding containers is entirely outside the scope of what the maintainers will support and by doing so, you accept that this behaviour may break at any time without notice."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='containers', type=d.T.array)]),
    withContainersMixin(containers): { spec+: { containers+: if std.isArray(v=containers) then containers else [containers] } },
    '#withDisableCompaction':: d.fn(help='"Disable prometheus compaction."', args=[d.arg(name='disableCompaction', type=d.T.boolean)]),
    withDisableCompaction(disableCompaction): { spec+: { disableCompaction: disableCompaction } },
    '#withEnableAdminAPI':: d.fn(help='"Enable access to prometheus web admin API. Defaults to the value of `false`. WARNING: Enabling the admin APIs enables mutating endpoints, to delete data, shutdown Prometheus, and more. Enabling this should be done with care and the user is advised to add additional authentication authorization via a proxy to ensure only clients authorized to perform these actions can do so. For more information see https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis"', args=[d.arg(name='enableAdminAPI', type=d.T.boolean)]),
    withEnableAdminAPI(enableAdminAPI): { spec+: { enableAdminAPI: enableAdminAPI } },
    '#withEnableFeatures':: d.fn(help='"Enable access to Prometheus disabled features. By default, no features are enabled. Enabling disabled features is entirely outside the scope of what the maintainers will support and by doing so, you accept that this behaviour may break at any time without notice. For more information see https://prometheus.io/docs/prometheus/latest/disabled_features/"', args=[d.arg(name='enableFeatures', type=d.T.array)]),
    withEnableFeatures(enableFeatures): { spec+: { enableFeatures: if std.isArray(v=enableFeatures) then enableFeatures else [enableFeatures] } },
    '#withEnableFeaturesMixin':: d.fn(help='"Enable access to Prometheus disabled features. By default, no features are enabled. Enabling disabled features is entirely outside the scope of what the maintainers will support and by doing so, you accept that this behaviour may break at any time without notice. For more information see https://prometheus.io/docs/prometheus/latest/disabled_features/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='enableFeatures', type=d.T.array)]),
    withEnableFeaturesMixin(enableFeatures): { spec+: { enableFeatures+: if std.isArray(v=enableFeatures) then enableFeatures else [enableFeatures] } },
    '#withEnforcedBodySizeLimit':: d.fn(help='"EnforcedBodySizeLimit defines the maximum size of uncompressed response body that will be accepted by Prometheus. Targets responding with a body larger than this many bytes will cause the scrape to fail. Example: 100MB. If defined, the limit will apply to all service/pod monitors and probes. This is an experimental feature, this behaviour could change or be removed in the future. Only valid in Prometheus versions 2.28.0 and newer."', args=[d.arg(name='enforcedBodySizeLimit', type=d.T.string)]),
    withEnforcedBodySizeLimit(enforcedBodySizeLimit): { spec+: { enforcedBodySizeLimit: enforcedBodySizeLimit } },
    '#withEnforcedLabelLimit':: d.fn(help='"Per-scrape limit on number of labels that will be accepted for a sample. If more than this number of labels are present post metric-relabeling, the entire scrape will be treated as failed. 0 means no limit. Only valid in Prometheus versions 2.27.0 and newer."', args=[d.arg(name='enforcedLabelLimit', type=d.T.integer)]),
    withEnforcedLabelLimit(enforcedLabelLimit): { spec+: { enforcedLabelLimit: enforcedLabelLimit } },
    '#withEnforcedLabelNameLengthLimit':: d.fn(help='"Per-scrape limit on length of labels name that will be accepted for a sample. If a label name is longer than this number post metric-relabeling, the entire scrape will be treated as failed. 0 means no limit. Only valid in Prometheus versions 2.27.0 and newer."', args=[d.arg(name='enforcedLabelNameLengthLimit', type=d.T.integer)]),
    withEnforcedLabelNameLengthLimit(enforcedLabelNameLengthLimit): { spec+: { enforcedLabelNameLengthLimit: enforcedLabelNameLengthLimit } },
    '#withEnforcedLabelValueLengthLimit':: d.fn(help='"Per-scrape limit on length of labels value that will be accepted for a sample. If a label value is longer than this number post metric-relabeling, the entire scrape will be treated as failed. 0 means no limit. Only valid in Prometheus versions 2.27.0 and newer."', args=[d.arg(name='enforcedLabelValueLengthLimit', type=d.T.integer)]),
    withEnforcedLabelValueLengthLimit(enforcedLabelValueLengthLimit): { spec+: { enforcedLabelValueLengthLimit: enforcedLabelValueLengthLimit } },
    '#withEnforcedNamespaceLabel':: d.fn(help="\"EnforcedNamespaceLabel If set, a label will be added to \\n 1. all user-metrics (created by `ServiceMonitor`, `PodMonitor` and `ProbeConfig` object) and 2. in all `PrometheusRule` objects (except the ones excluded in `prometheusRulesExcludedFromEnforce`) to    * alerting \u0026 recording rules and    * the metrics used in their expressions (`expr`). \\n Label name is this field's value. Label value is the namespace of the created object (mentioned above).\"", args=[d.arg(name='enforcedNamespaceLabel', type=d.T.string)]),
    withEnforcedNamespaceLabel(enforcedNamespaceLabel): { spec+: { enforcedNamespaceLabel: enforcedNamespaceLabel } },
    '#withEnforcedSampleLimit':: d.fn(help='"EnforcedSampleLimit defines global limit on number of scraped samples that will be accepted. This overrides any SampleLimit set per ServiceMonitor or/and PodMonitor. It is meant to be used by admins to enforce the SampleLimit to keep overall number of samples/series under the desired limit. Note that if SampleLimit is lower that value will be taken instead."', args=[d.arg(name='enforcedSampleLimit', type=d.T.integer)]),
    withEnforcedSampleLimit(enforcedSampleLimit): { spec+: { enforcedSampleLimit: enforcedSampleLimit } },
    '#withEnforcedTargetLimit':: d.fn(help='"EnforcedTargetLimit defines a global limit on the number of scraped targets.  This overrides any TargetLimit set per ServiceMonitor or/and PodMonitor.  It is meant to be used by admins to enforce the TargetLimit to keep the overall number of targets under the desired limit. Note that if TargetLimit is lower, that value will be taken instead, except if either value is zero, in which case the non-zero value will be used.  If both values are zero, no limit is enforced."', args=[d.arg(name='enforcedTargetLimit', type=d.T.integer)]),
    withEnforcedTargetLimit(enforcedTargetLimit): { spec+: { enforcedTargetLimit: enforcedTargetLimit } },
    '#withEvaluationInterval':: d.fn(help='"Interval between consecutive evaluations. Default: `1m`"', args=[d.arg(name='evaluationInterval', type=d.T.string)]),
    withEvaluationInterval(evaluationInterval): { spec+: { evaluationInterval: evaluationInterval } },
    '#withExternalLabels':: d.fn(help='"The labels to add to any time series or alerts when communicating with external systems (federation, remote storage, Alertmanager)."', args=[d.arg(name='externalLabels', type=d.T.object)]),
    withExternalLabels(externalLabels): { spec+: { externalLabels: externalLabels } },
    '#withExternalLabelsMixin':: d.fn(help='"The labels to add to any time series or alerts when communicating with external systems (federation, remote storage, Alertmanager)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='externalLabels', type=d.T.object)]),
    withExternalLabelsMixin(externalLabels): { spec+: { externalLabels+: externalLabels } },
    '#withExternalUrl':: d.fn(help='"The external URL the Prometheus instances will be available under. This is necessary to generate correct URLs. This is necessary if Prometheus is not served from root of a DNS name."', args=[d.arg(name='externalUrl', type=d.T.string)]),
    withExternalUrl(externalUrl): { spec+: { externalUrl: externalUrl } },
    '#withIgnoreNamespaceSelectors':: d.fn(help='"IgnoreNamespaceSelectors if set to true will ignore NamespaceSelector settings from the podmonitor and servicemonitor configs, and they will only discover endpoints within their current namespace.  Defaults to false."', args=[d.arg(name='ignoreNamespaceSelectors', type=d.T.boolean)]),
    withIgnoreNamespaceSelectors(ignoreNamespaceSelectors): { spec+: { ignoreNamespaceSelectors: ignoreNamespaceSelectors } },
    '#withImage':: d.fn(help='"Image if specified has precedence over baseImage, tag and sha combinations. Specifying the version is still necessary to ensure the Prometheus Operator knows what version of Prometheus is being configured."', args=[d.arg(name='image', type=d.T.string)]),
    withImage(image): { spec+: { image: image } },
    '#withImagePullSecrets':: d.fn(help='"An optional list of references to secrets in the same namespace to use for pulling prometheus and alertmanager images from registries see http://kubernetes.io/docs/user-guide/images#specifying-imagepullsecrets-on-a-pod"', args=[d.arg(name='imagePullSecrets', type=d.T.array)]),
    withImagePullSecrets(imagePullSecrets): { spec+: { imagePullSecrets: if std.isArray(v=imagePullSecrets) then imagePullSecrets else [imagePullSecrets] } },
    '#withImagePullSecretsMixin':: d.fn(help='"An optional list of references to secrets in the same namespace to use for pulling prometheus and alertmanager images from registries see http://kubernetes.io/docs/user-guide/images#specifying-imagepullsecrets-on-a-pod"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='imagePullSecrets', type=d.T.array)]),
    withImagePullSecretsMixin(imagePullSecrets): { spec+: { imagePullSecrets+: if std.isArray(v=imagePullSecrets) then imagePullSecrets else [imagePullSecrets] } },
    '#withInitContainers':: d.fn(help='"InitContainers allows adding initContainers to the pod definition. Those can be used to e.g. fetch secrets for injection into the Prometheus configuration from external sources. Any errors during the execution of an initContainer will lead to a restart of the Pod. More info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/ InitContainers described here modify an operator generated init containers if they share the same name and modifications are done via a strategic merge patch. The current init container name is: `init-config-reloader`. Overriding init containers is entirely outside the scope of what the maintainers will support and by doing so, you accept that this behaviour may break at any time without notice."', args=[d.arg(name='initContainers', type=d.T.array)]),
    withInitContainers(initContainers): { spec+: { initContainers: if std.isArray(v=initContainers) then initContainers else [initContainers] } },
    '#withInitContainersMixin':: d.fn(help='"InitContainers allows adding initContainers to the pod definition. Those can be used to e.g. fetch secrets for injection into the Prometheus configuration from external sources. Any errors during the execution of an initContainer will lead to a restart of the Pod. More info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/ InitContainers described here modify an operator generated init containers if they share the same name and modifications are done via a strategic merge patch. The current init container name is: `init-config-reloader`. Overriding init containers is entirely outside the scope of what the maintainers will support and by doing so, you accept that this behaviour may break at any time without notice."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='initContainers', type=d.T.array)]),
    withInitContainersMixin(initContainers): { spec+: { initContainers+: if std.isArray(v=initContainers) then initContainers else [initContainers] } },
    '#withListenLocal':: d.fn(help='"ListenLocal makes the Prometheus server listen on loopback, so that it does not bind against the Pod IP."', args=[d.arg(name='listenLocal', type=d.T.boolean)]),
    withListenLocal(listenLocal): { spec+: { listenLocal: listenLocal } },
    '#withLogFormat':: d.fn(help='"Log format for Prometheus to be configured with."', args=[d.arg(name='logFormat', type=d.T.string)]),
    withLogFormat(logFormat): { spec+: { logFormat: logFormat } },
    '#withLogLevel':: d.fn(help='"Log level for Prometheus to be configured with."', args=[d.arg(name='logLevel', type=d.T.string)]),
    withLogLevel(logLevel): { spec+: { logLevel: logLevel } },
    '#withMinReadySeconds':: d.fn(help='"Minimum number of seconds for which a newly created pod should be ready without any of its container crashing for it to be considered available. Defaults to 0 (pod will be considered available as soon as it is ready) This is an alpha field and requires enabling StatefulSetMinReadySeconds feature gate."', args=[d.arg(name='minReadySeconds', type=d.T.integer)]),
    withMinReadySeconds(minReadySeconds): { spec+: { minReadySeconds: minReadySeconds } },
    '#withNodeSelector':: d.fn(help='"Define which Nodes the Pods are scheduled on."', args=[d.arg(name='nodeSelector', type=d.T.object)]),
    withNodeSelector(nodeSelector): { spec+: { nodeSelector: nodeSelector } },
    '#withNodeSelectorMixin':: d.fn(help='"Define which Nodes the Pods are scheduled on."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelector', type=d.T.object)]),
    withNodeSelectorMixin(nodeSelector): { spec+: { nodeSelector+: nodeSelector } },
    '#withOverrideHonorLabels':: d.fn(help='"OverrideHonorLabels if set to true overrides all user configured honor_labels. If HonorLabels is set in ServiceMonitor or PodMonitor to true, this overrides honor_labels to false."', args=[d.arg(name='overrideHonorLabels', type=d.T.boolean)]),
    withOverrideHonorLabels(overrideHonorLabels): { spec+: { overrideHonorLabels: overrideHonorLabels } },
    '#withOverrideHonorTimestamps':: d.fn(help='"OverrideHonorTimestamps allows to globally enforce honoring timestamps in all scrape configs."', args=[d.arg(name='overrideHonorTimestamps', type=d.T.boolean)]),
    withOverrideHonorTimestamps(overrideHonorTimestamps): { spec+: { overrideHonorTimestamps: overrideHonorTimestamps } },
    '#withPaused':: d.fn(help='"When a Prometheus deployment is paused, no actions except for deletion will be performed on the underlying objects."', args=[d.arg(name='paused', type=d.T.boolean)]),
    withPaused(paused): { spec+: { paused: paused } },
    '#withPortName':: d.fn(help='"Port name used for the pods and governing service. This defaults to web"', args=[d.arg(name='portName', type=d.T.string)]),
    withPortName(portName): { spec+: { portName: portName } },
    '#withPriorityClassName':: d.fn(help='"Priority class assigned to the Pods"', args=[d.arg(name='priorityClassName', type=d.T.string)]),
    withPriorityClassName(priorityClassName): { spec+: { priorityClassName: priorityClassName } },
    '#withPrometheusExternalLabelName':: d.fn(help='"Name of Prometheus external label used to denote Prometheus instance name. Defaults to the value of `prometheus`. External label will _not_ be added when value is set to empty string (`\\"\\"`)."', args=[d.arg(name='prometheusExternalLabelName', type=d.T.string)]),
    withPrometheusExternalLabelName(prometheusExternalLabelName): { spec+: { prometheusExternalLabelName: prometheusExternalLabelName } },
    '#withPrometheusRulesExcludedFromEnforce':: d.fn(help='"PrometheusRulesExcludedFromEnforce - list of prometheus rules to be excluded from enforcing of adding namespace labels. Works only if enforcedNamespaceLabel set to true. Make sure both ruleNamespace and ruleName are set for each pair"', args=[d.arg(name='prometheusRulesExcludedFromEnforce', type=d.T.array)]),
    withPrometheusRulesExcludedFromEnforce(prometheusRulesExcludedFromEnforce): { spec+: { prometheusRulesExcludedFromEnforce: if std.isArray(v=prometheusRulesExcludedFromEnforce) then prometheusRulesExcludedFromEnforce else [prometheusRulesExcludedFromEnforce] } },
    '#withPrometheusRulesExcludedFromEnforceMixin':: d.fn(help='"PrometheusRulesExcludedFromEnforce - list of prometheus rules to be excluded from enforcing of adding namespace labels. Works only if enforcedNamespaceLabel set to true. Make sure both ruleNamespace and ruleName are set for each pair"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='prometheusRulesExcludedFromEnforce', type=d.T.array)]),
    withPrometheusRulesExcludedFromEnforceMixin(prometheusRulesExcludedFromEnforce): { spec+: { prometheusRulesExcludedFromEnforce+: if std.isArray(v=prometheusRulesExcludedFromEnforce) then prometheusRulesExcludedFromEnforce else [prometheusRulesExcludedFromEnforce] } },
    '#withQueryLogFile':: d.fn(help='"QueryLogFile specifies the file to which PromQL queries are logged. Note that this location must be writable, and can be persisted using an attached volume. Alternatively, the location can be set to a stdout location such as `/dev/stdout` to log querie information to the default Prometheus log stream. This is only available in versions of Prometheus >= 2.16.0. For more details, see the Prometheus docs (https://prometheus.io/docs/guides/query-log/)"', args=[d.arg(name='queryLogFile', type=d.T.string)]),
    withQueryLogFile(queryLogFile): { spec+: { queryLogFile: queryLogFile } },
    '#withRemoteRead':: d.fn(help='"If specified, the remote_read spec. This is an experimental feature, it may change in any upcoming release in a breaking way."', args=[d.arg(name='remoteRead', type=d.T.array)]),
    withRemoteRead(remoteRead): { spec+: { remoteRead: if std.isArray(v=remoteRead) then remoteRead else [remoteRead] } },
    '#withRemoteReadMixin':: d.fn(help='"If specified, the remote_read spec. This is an experimental feature, it may change in any upcoming release in a breaking way."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='remoteRead', type=d.T.array)]),
    withRemoteReadMixin(remoteRead): { spec+: { remoteRead+: if std.isArray(v=remoteRead) then remoteRead else [remoteRead] } },
    '#withRemoteWrite':: d.fn(help='"If specified, the remote_write spec. This is an experimental feature, it may change in any upcoming release in a breaking way."', args=[d.arg(name='remoteWrite', type=d.T.array)]),
    withRemoteWrite(remoteWrite): { spec+: { remoteWrite: if std.isArray(v=remoteWrite) then remoteWrite else [remoteWrite] } },
    '#withRemoteWriteMixin':: d.fn(help='"If specified, the remote_write spec. This is an experimental feature, it may change in any upcoming release in a breaking way."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='remoteWrite', type=d.T.array)]),
    withRemoteWriteMixin(remoteWrite): { spec+: { remoteWrite+: if std.isArray(v=remoteWrite) then remoteWrite else [remoteWrite] } },
    '#withReplicaExternalLabelName':: d.fn(help='"Name of Prometheus external label used to denote replica name. Defaults to the value of `prometheus_replica`. External label will _not_ be added when value is set to empty string (`\\"\\"`)."', args=[d.arg(name='replicaExternalLabelName', type=d.T.string)]),
    withReplicaExternalLabelName(replicaExternalLabelName): { spec+: { replicaExternalLabelName: replicaExternalLabelName } },
    '#withReplicas':: d.fn(help='"Number of replicas of each shard to deploy for a Prometheus deployment. Number of replicas multiplied by shards is the total number of Pods created."', args=[d.arg(name='replicas', type=d.T.integer)]),
    withReplicas(replicas): { spec+: { replicas: replicas } },
    '#withRetention':: d.fn(help="\"Time duration Prometheus shall retain data for. Default is '24h', and must match the regular expression `[0-9]+(ms|s|m|h|d|w|y)` (milliseconds seconds minutes hours days weeks years).\"", args=[d.arg(name='retention', type=d.T.string)]),
    withRetention(retention): { spec+: { retention: retention } },
    '#withRetentionSize':: d.fn(help='"Maximum amount of disk space used by blocks. Supported units: B, KB, MB, GB, TB, PB, EB. Ex: `512MB`."', args=[d.arg(name='retentionSize', type=d.T.string)]),
    withRetentionSize(retentionSize): { spec+: { retentionSize: retentionSize } },
    '#withRoutePrefix':: d.fn(help='"The route prefix Prometheus registers HTTP handlers for. This is useful, if using ExternalURL and a proxy is rewriting HTTP routes of a request, and the actual ExternalURL is still true, but the server serves requests under a different route prefix. For example for use with `kubectl proxy`."', args=[d.arg(name='routePrefix', type=d.T.string)]),
    withRoutePrefix(routePrefix): { spec+: { routePrefix: routePrefix } },
    '#withScrapeInterval':: d.fn(help='"Interval between consecutive scrapes. Default: `1m`"', args=[d.arg(name='scrapeInterval', type=d.T.string)]),
    withScrapeInterval(scrapeInterval): { spec+: { scrapeInterval: scrapeInterval } },
    '#withScrapeTimeout':: d.fn(help='"Number of seconds to wait for target to respond before erroring."', args=[d.arg(name='scrapeTimeout', type=d.T.string)]),
    withScrapeTimeout(scrapeTimeout): { spec+: { scrapeTimeout: scrapeTimeout } },
    '#withSecrets':: d.fn(help='"Secrets is a list of Secrets in the same namespace as the Prometheus object, which shall be mounted into the Prometheus Pods. The Secrets are mounted into /etc/prometheus/secrets/<secret-name>."', args=[d.arg(name='secrets', type=d.T.array)]),
    withSecrets(secrets): { spec+: { secrets: if std.isArray(v=secrets) then secrets else [secrets] } },
    '#withSecretsMixin':: d.fn(help='"Secrets is a list of Secrets in the same namespace as the Prometheus object, which shall be mounted into the Prometheus Pods. The Secrets are mounted into /etc/prometheus/secrets/<secret-name>."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='secrets', type=d.T.array)]),
    withSecretsMixin(secrets): { spec+: { secrets+: if std.isArray(v=secrets) then secrets else [secrets] } },
    '#withServiceAccountName':: d.fn(help='"ServiceAccountName is the name of the ServiceAccount to use to run the Prometheus Pods."', args=[d.arg(name='serviceAccountName', type=d.T.string)]),
    withServiceAccountName(serviceAccountName): { spec+: { serviceAccountName: serviceAccountName } },
    '#withSha':: d.fn(help="\"SHA of Prometheus container image to be deployed. Defaults to the value of `version`. Similar to a tag, but the SHA explicitly deploys an immutable container image. Version and Tag are ignored if SHA is set. Deprecated: use 'image' instead.  The image digest can be specified as part of the image URL.\"", args=[d.arg(name='sha', type=d.T.string)]),
    withSha(sha): { spec+: { sha: sha } },
    '#withShards':: d.fn(help='"EXPERIMENTAL: Number of shards to distribute targets onto. Number of replicas multiplied by shards is the total number of Pods created. Note that scaling down shards will not reshard data onto remaining instances, it must be manually moved. Increasing shards will not reshard data either but it will continue to be available from the same instances. To query globally use Thanos sidecar and Thanos querier or remote write data to a central location. Sharding is done on the content of the `__address__` target meta-label."', args=[d.arg(name='shards', type=d.T.integer)]),
    withShards(shards): { spec+: { shards: shards } },
    '#withTag':: d.fn(help="\"Tag of Prometheus container image to be deployed. Defaults to the value of `version`. Version is ignored if Tag is set. Deprecated: use 'image' instead.  The image tag can be specified as part of the image URL.\"", args=[d.arg(name='tag', type=d.T.string)]),
    withTag(tag): { spec+: { tag: tag } },
    '#withTolerations':: d.fn(help="\"If specified, the pod's tolerations.\"", args=[d.arg(name='tolerations', type=d.T.array)]),
    withTolerations(tolerations): { spec+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } },
    '#withTolerationsMixin':: d.fn(help="\"If specified, the pod's tolerations.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='tolerations', type=d.T.array)]),
    withTolerationsMixin(tolerations): { spec+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } },
    '#withTopologySpreadConstraints':: d.fn(help="\"If specified, the pod's topology spread constraints.\"", args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
    withTopologySpreadConstraints(topologySpreadConstraints): { spec+: { topologySpreadConstraints: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } },
    '#withTopologySpreadConstraintsMixin':: d.fn(help="\"If specified, the pod's topology spread constraints.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
    withTopologySpreadConstraintsMixin(topologySpreadConstraints): { spec+: { topologySpreadConstraints+: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } },
    '#withVersion':: d.fn(help='"Version of Prometheus to be deployed."', args=[d.arg(name='version', type=d.T.string)]),
    withVersion(version): { spec+: { version: version } },
    '#withVolumeMounts':: d.fn(help='"VolumeMounts allows configuration of additional VolumeMounts on the output StatefulSet definition. VolumeMounts specified will be appended to other VolumeMounts in the prometheus container, that are generated as a result of StorageSpec objects."', args=[d.arg(name='volumeMounts', type=d.T.array)]),
    withVolumeMounts(volumeMounts): { spec+: { volumeMounts: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] } },
    '#withVolumeMountsMixin':: d.fn(help='"VolumeMounts allows configuration of additional VolumeMounts on the output StatefulSet definition. VolumeMounts specified will be appended to other VolumeMounts in the prometheus container, that are generated as a result of StorageSpec objects."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumeMounts', type=d.T.array)]),
    withVolumeMountsMixin(volumeMounts): { spec+: { volumeMounts+: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] } },
    '#withVolumes':: d.fn(help='"Volumes allows configuration of additional volumes on the output StatefulSet definition. Volumes specified will be appended to other volumes that are generated as a result of StorageSpec objects."', args=[d.arg(name='volumes', type=d.T.array)]),
    withVolumes(volumes): { spec+: { volumes: if std.isArray(v=volumes) then volumes else [volumes] } },
    '#withVolumesMixin':: d.fn(help='"Volumes allows configuration of additional volumes on the output StatefulSet definition. Volumes specified will be appended to other volumes that are generated as a result of StorageSpec objects."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumes', type=d.T.array)]),
    withVolumesMixin(volumes): { spec+: { volumes+: if std.isArray(v=volumes) then volumes else [volumes] } },
    '#withWalCompression':: d.fn(help='"Enable compression of the write-ahead log using Snappy. This flag is only available in versions of Prometheus >= 2.11.0."', args=[d.arg(name='walCompression', type=d.T.boolean)]),
    withWalCompression(walCompression): { spec+: { walCompression: walCompression } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
