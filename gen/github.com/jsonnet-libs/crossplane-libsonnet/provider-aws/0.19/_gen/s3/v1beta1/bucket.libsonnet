{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='bucket', url='', help='"An Bucket is a managed resource that represents an AWS S3 Bucket."'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of Bucket', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 's3.aws.crossplane.io/v1beta1',
    kind: 'Bucket',
  } + self.metadata.withName(name=name) + self.metadata.withAnnotations(annotations={
    'tanka.dev/namespaced': 'false',
  }),
  '#spec':: d.obj(help='"BucketSpec represents the desired state of the Bucket."'),
  spec: {
    '#forProvider':: d.obj(help='"BucketParameters are parameters for configuring the calls made to AWS Bucket API."'),
    forProvider: {
      '#accelerateConfiguration':: d.obj(help='"AccelerateConfiguration configures the transfer acceleration state for an Amazon S3 bucket. For more information, see Amazon S3 Transfer Acceleration (https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html) in the Amazon Simple Storage Service Developer Guide."'),
      accelerateConfiguration: {},
      '#corsConfiguration':: d.obj(help='"Describes the cross-origin access configuration for objects in an Amazon S3 bucket. For more information, see Enabling Cross-Origin Resource Sharing (https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html) in the Amazon Simple Storage Service Developer Guide."'),
      corsConfiguration: {
        '#corsRules':: d.obj(help='"A set of origins and methods (cross-origin access that you want to allow). You can add up to 100 rules to the configuration."'),
        corsRules: {
          '#withAllowedHeaders':: d.fn(help='"Headers that are specified in the Access-Control-Request-Headers header. These headers are allowed in a preflight OPTIONS request. In response to any preflight OPTIONS request, Amazon S3 returns any requested headers that are allowed."', args=[d.arg(name='allowedHeaders', type=d.T.array)]),
          withAllowedHeaders(allowedHeaders): { allowedHeaders: if std.isArray(v=allowedHeaders) then allowedHeaders else [allowedHeaders] },
          '#withAllowedHeadersMixin':: d.fn(help='"Headers that are specified in the Access-Control-Request-Headers header. These headers are allowed in a preflight OPTIONS request. In response to any preflight OPTIONS request, Amazon S3 returns any requested headers that are allowed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='allowedHeaders', type=d.T.array)]),
          withAllowedHeadersMixin(allowedHeaders): { allowedHeaders+: if std.isArray(v=allowedHeaders) then allowedHeaders else [allowedHeaders] },
          '#withAllowedMethods':: d.fn(help='"An HTTP method that you allow the origin to execute. Valid values are GET, PUT, HEAD, POST, and DELETE."', args=[d.arg(name='allowedMethods', type=d.T.array)]),
          withAllowedMethods(allowedMethods): { allowedMethods: if std.isArray(v=allowedMethods) then allowedMethods else [allowedMethods] },
          '#withAllowedMethodsMixin':: d.fn(help='"An HTTP method that you allow the origin to execute. Valid values are GET, PUT, HEAD, POST, and DELETE."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='allowedMethods', type=d.T.array)]),
          withAllowedMethodsMixin(allowedMethods): { allowedMethods+: if std.isArray(v=allowedMethods) then allowedMethods else [allowedMethods] },
          '#withAllowedOrigins':: d.fn(help='"One or more origins you want customers to be able to access the bucket from."', args=[d.arg(name='allowedOrigins', type=d.T.array)]),
          withAllowedOrigins(allowedOrigins): { allowedOrigins: if std.isArray(v=allowedOrigins) then allowedOrigins else [allowedOrigins] },
          '#withAllowedOriginsMixin':: d.fn(help='"One or more origins you want customers to be able to access the bucket from."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='allowedOrigins', type=d.T.array)]),
          withAllowedOriginsMixin(allowedOrigins): { allowedOrigins+: if std.isArray(v=allowedOrigins) then allowedOrigins else [allowedOrigins] },
          '#withExposeHeaders':: d.fn(help='"One or more headers in the response that you want customers to be able to access from their applications (for example, from a JavaScript XMLHttpRequest object)."', args=[d.arg(name='exposeHeaders', type=d.T.array)]),
          withExposeHeaders(exposeHeaders): { exposeHeaders: if std.isArray(v=exposeHeaders) then exposeHeaders else [exposeHeaders] },
          '#withExposeHeadersMixin':: d.fn(help='"One or more headers in the response that you want customers to be able to access from their applications (for example, from a JavaScript XMLHttpRequest object)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='exposeHeaders', type=d.T.array)]),
          withExposeHeadersMixin(exposeHeaders): { exposeHeaders+: if std.isArray(v=exposeHeaders) then exposeHeaders else [exposeHeaders] },
          '#withMaxAgeSeconds':: d.fn(help='"The time in seconds that your browser is to cache the preflight response for the specified resource."', args=[d.arg(name='maxAgeSeconds', type=d.T.integer)]),
          withMaxAgeSeconds(maxAgeSeconds): { maxAgeSeconds: maxAgeSeconds },
        },
        '#withCorsRules':: d.fn(help='"A set of origins and methods (cross-origin access that you want to allow). You can add up to 100 rules to the configuration."', args=[d.arg(name='corsRules', type=d.T.array)]),
        withCorsRules(corsRules): { spec+: { forProvider+: { corsConfiguration+: { corsRules: if std.isArray(v=corsRules) then corsRules else [corsRules] } } } },
        '#withCorsRulesMixin':: d.fn(help='"A set of origins and methods (cross-origin access that you want to allow). You can add up to 100 rules to the configuration."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='corsRules', type=d.T.array)]),
        withCorsRulesMixin(corsRules): { spec+: { forProvider+: { corsConfiguration+: { corsRules+: if std.isArray(v=corsRules) then corsRules else [corsRules] } } } },
      },
      '#lifecycleConfiguration':: d.obj(help='"Creates a new lifecycle configuration for the bucket or replaces an existing lifecycle configuration. For information about lifecycle configuration, see Managing Access Permissions to Your Amazon S3 Resources (https://docs.aws.amazon.com/AmazonS3/latest/dev/s3-access-control.html)."'),
      lifecycleConfiguration: {
        '#rules':: d.obj(help='"A lifecycle rule for individual objects in an Amazon S3 bucket. \\n Rules is a required field"'),
        rules: {
          '#abortIncompleteMultipartUpload':: d.obj(help='"Specifies the days since the initiation of an incomplete multipart upload that Amazon S3 will wait before permanently removing all parts of the upload. For more information, see Aborting Incomplete Multipart Uploads Using a Bucket Lifecycle Policy (https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html#mpu-abort-incomplete-mpu-lifecycle-config) in the Amazon Simple Storage Service Developer Guide."'),
          abortIncompleteMultipartUpload: {
            '#withDaysAfterInitiation':: d.fn(help='"Specifies the number of days after which Amazon S3 aborts an incomplete multipart upload."', args=[d.arg(name='daysAfterInitiation', type=d.T.integer)]),
            withDaysAfterInitiation(daysAfterInitiation): { abortIncompleteMultipartUpload+: { daysAfterInitiation: daysAfterInitiation } },
          },
          '#expiration':: d.obj(help='"Specifies the expiration for the lifecycle of the object in the form of date, days and, whether the object has a delete marker."'),
          expiration: {
            '#withDate':: d.fn(help='"Indicates at what date the object is to be moved or deleted."', args=[d.arg(name='date', type=d.T.string)]),
            withDate(date): { expiration+: { date: date } },
            '#withDays':: d.fn(help='"Indicates the lifetime, in days, of the objects that are subject to the rule. The value must be a non-zero positive integer."', args=[d.arg(name='days', type=d.T.integer)]),
            withDays(days): { expiration+: { days: days } },
            '#withExpiredObjectDeleteMarker':: d.fn(help='"Indicates whether Amazon S3 will remove a delete marker with no noncurrent versions. If set to true, the delete marker will be expired; if set to false the policy takes no action. This cannot be specified with Days or Date in a Lifecycle Expiration Policy."', args=[d.arg(name='expiredObjectDeleteMarker', type=d.T.boolean)]),
            withExpiredObjectDeleteMarker(expiredObjectDeleteMarker): { expiration+: { expiredObjectDeleteMarker: expiredObjectDeleteMarker } },
          },
          '#filter':: d.obj(help='"The Filter is used to identify objects that a Lifecycle Rule applies to. A Filter must have exactly one of Prefix, Tag, or And specified."'),
          filter: {
            '#and':: d.obj(help='"This is used in a Lifecycle Rule Filter to apply a logical AND to two or more predicates. The Lifecycle Rule will apply to any object matching all of the predicates configured inside the And operator."'),
            and: {
              '#tags':: d.obj(help="\"All of these tags must exist in the object's tag set in order for the rule to apply.\""),
              tags: {
                '#withKey':: d.fn(help='"Name of the tag. Key is a required field"', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withValue':: d.fn(help='"Value of the tag. Value is a required field"', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#withPrefix':: d.fn(help='"Prefix identifying one or more objects to which the rule applies."', args=[d.arg(name='prefix', type=d.T.string)]),
              withPrefix(prefix): { filter+: { and+: { prefix: prefix } } },
              '#withTags':: d.fn(help="\"All of these tags must exist in the object's tag set in order for the rule to apply.\"", args=[d.arg(name='tags', type=d.T.array)]),
              withTags(tags): { filter+: { and+: { tags: if std.isArray(v=tags) then tags else [tags] } } },
              '#withTagsMixin':: d.fn(help="\"All of these tags must exist in the object's tag set in order for the rule to apply.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='tags', type=d.T.array)]),
              withTagsMixin(tags): { filter+: { and+: { tags+: if std.isArray(v=tags) then tags else [tags] } } },
            },
            '#tag':: d.obj(help="\"This tag must exist in the object's tag set in order for the rule to apply.\""),
            tag: {
              '#withKey':: d.fn(help='"Name of the tag. Key is a required field"', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { filter+: { tag+: { key: key } } },
              '#withValue':: d.fn(help='"Value of the tag. Value is a required field"', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { filter+: { tag+: { value: value } } },
            },
            '#withPrefix':: d.fn(help='"Prefix identifying one or more objects to which the rule applies."', args=[d.arg(name='prefix', type=d.T.string)]),
            withPrefix(prefix): { filter+: { prefix: prefix } },
          },
          '#noncurrentVersionExpiration':: d.obj(help="\"Specifies when noncurrent object versions expire. Upon expiration, Amazon S3 permanently deletes the noncurrent object versions. You set this lifecycle configuration action on a bucket that has versioning enabled (or suspended) to request that Amazon S3 delete noncurrent object versions at a specific period in the object's lifetime.\""),
          noncurrentVersionExpiration: {
            '#withNoncurrentDays':: d.fn(help='"Specifies the number of days an object is noncurrent before Amazon S3 can perform the associated action. For information about the noncurrent days calculations, see How Amazon S3 Calculates When an Object Became Noncurrent (https://docs.aws.amazon.com/AmazonS3/latest/dev/intro-lifecycle-rules.html#non-current-days-calculations) in the Amazon Simple Storage Service Developer Guide."', args=[d.arg(name='noncurrentDays', type=d.T.integer)]),
            withNoncurrentDays(noncurrentDays): { noncurrentVersionExpiration+: { noncurrentDays: noncurrentDays } },
          },
          '#noncurrentVersionTransitions':: d.obj(help="\"Specifies the transition rule for the lifecycle rule that describes when noncurrent objects transition to a specific storage class. If your bucket is versioning-enabled (or versioning is suspended), you can set this action to request that Amazon S3 transition noncurrent object versions to a specific storage class at a set period in the object's lifetime.\""),
          noncurrentVersionTransitions: {
            '#withNoncurrentDays':: d.fn(help='"Specifies the number of days an object is noncurrent before Amazon S3 can perform the associated action. For information about the noncurrent days calculations, see How Amazon S3 Calculates How Long an Object Has Been Noncurrent (https://docs.aws.amazon.com/AmazonS3/latest/dev/intro-lifecycle-rules.html#non-current-days-calculations) in the Amazon Simple Storage Service Developer Guide."', args=[d.arg(name='noncurrentDays', type=d.T.integer)]),
            withNoncurrentDays(noncurrentDays): { noncurrentDays: noncurrentDays },
            '#withStorageClass':: d.fn(help='"The class of storage used to store the object. Valid values are: GLACIER, STANDARD_IA, ONEZONE_IA, INTELLIGENT_TIERING, DEEP_ARCHIVE"', args=[d.arg(name='storageClass', type=d.T.string)]),
            withStorageClass(storageClass): { storageClass: storageClass },
          },
          '#transitions':: d.obj(help='"Specifies when an Amazon S3 object transitions to a specified storage class."'),
          transitions: {
            '#withDate':: d.fn(help='"Indicates when objects are transitioned to the specified storage class. The date value must be in ISO 8601 format. The time is always midnight UTC."', args=[d.arg(name='date', type=d.T.string)]),
            withDate(date): { date: date },
            '#withDays':: d.fn(help='"Indicates the number of days after creation when objects are transitioned to the specified storage class. The value must be a positive integer."', args=[d.arg(name='days', type=d.T.integer)]),
            withDays(days): { days: days },
            '#withStorageClass':: d.fn(help='"The storage class to which you want the object to transition. Valid values are: GLACIER, STANDARD_IA, ONEZONE_IA, INTELLIGENT_TIERING, DEEP_ARCHIVE"', args=[d.arg(name='storageClass', type=d.T.string)]),
            withStorageClass(storageClass): { storageClass: storageClass },
          },
          '#withId':: d.fn(help='"Unique identifier for the rule. The value cannot be longer than 255 characters."', args=[d.arg(name='id', type=d.T.string)]),
          withId(id): { id: id },
          '#withNoncurrentVersionTransitions':: d.fn(help="\"Specifies the transition rule for the lifecycle rule that describes when noncurrent objects transition to a specific storage class. If your bucket is versioning-enabled (or versioning is suspended), you can set this action to request that Amazon S3 transition noncurrent object versions to a specific storage class at a set period in the object's lifetime.\"", args=[d.arg(name='noncurrentVersionTransitions', type=d.T.array)]),
          withNoncurrentVersionTransitions(noncurrentVersionTransitions): { noncurrentVersionTransitions: if std.isArray(v=noncurrentVersionTransitions) then noncurrentVersionTransitions else [noncurrentVersionTransitions] },
          '#withNoncurrentVersionTransitionsMixin':: d.fn(help="\"Specifies the transition rule for the lifecycle rule that describes when noncurrent objects transition to a specific storage class. If your bucket is versioning-enabled (or versioning is suspended), you can set this action to request that Amazon S3 transition noncurrent object versions to a specific storage class at a set period in the object's lifetime.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='noncurrentVersionTransitions', type=d.T.array)]),
          withNoncurrentVersionTransitionsMixin(noncurrentVersionTransitions): { noncurrentVersionTransitions+: if std.isArray(v=noncurrentVersionTransitions) then noncurrentVersionTransitions else [noncurrentVersionTransitions] },
          '#withTransitions':: d.fn(help='"Specifies when an Amazon S3 object transitions to a specified storage class."', args=[d.arg(name='transitions', type=d.T.array)]),
          withTransitions(transitions): { transitions: if std.isArray(v=transitions) then transitions else [transitions] },
          '#withTransitionsMixin':: d.fn(help='"Specifies when an Amazon S3 object transitions to a specified storage class."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='transitions', type=d.T.array)]),
          withTransitionsMixin(transitions): { transitions+: if std.isArray(v=transitions) then transitions else [transitions] },
        },
        '#withRules':: d.fn(help='"A lifecycle rule for individual objects in an Amazon S3 bucket. \\n Rules is a required field"', args=[d.arg(name='rules', type=d.T.array)]),
        withRules(rules): { spec+: { forProvider+: { lifecycleConfiguration+: { rules: if std.isArray(v=rules) then rules else [rules] } } } },
        '#withRulesMixin':: d.fn(help='"A lifecycle rule for individual objects in an Amazon S3 bucket. \\n Rules is a required field"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='rules', type=d.T.array)]),
        withRulesMixin(rules): { spec+: { forProvider+: { lifecycleConfiguration+: { rules+: if std.isArray(v=rules) then rules else [rules] } } } },
      },
      '#loggingConfiguration':: d.obj(help="\"Specifies logging parameters for an Amazon S3 bucket. Set the logging parameters for a bucket and to specify permissions for who can view and modify the logging parameters. See the AWS API reference guide for Amazon Simple Storage Service's API operation PutBucketLogging for usage and error information. See also, https://docs.aws.amazon.com/goto/WebAPI/s3-2006-03-01/PutBucketLogging\""),
      loggingConfiguration: {
        '#targetBucketRef':: d.obj(help='"TargetBucketRef references an S3Bucket to retrieve its name"'),
        targetBucketRef: {
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { forProvider+: { loggingConfiguration+: { targetBucketRef+: { name: name } } } } },
        },
        '#targetBucketSelector':: d.obj(help='"TargetBucketSelector selects a reference to an S3Bucket to retrieve its name"'),
        targetBucketSelector: {
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { spec+: { forProvider+: { loggingConfiguration+: { targetBucketSelector+: { matchControllerRef: matchControllerRef } } } } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { spec+: { forProvider+: { loggingConfiguration+: { targetBucketSelector+: { matchLabels: matchLabels } } } } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { spec+: { forProvider+: { loggingConfiguration+: { targetBucketSelector+: { matchLabels+: matchLabels } } } } },
        },
        '#targetGrants':: d.obj(help='"Container for granting information."'),
        targetGrants: {
          '#targetGrantee':: d.obj(help='"Container for the person being granted permissions."'),
          targetGrantee: {
            '#withDisplayName':: d.fn(help='"Screen name of the grantee."', args=[d.arg(name='displayName', type=d.T.string)]),
            withDisplayName(displayName): { targetGrantee+: { displayName: displayName } },
            '#withEmailAddress':: d.fn(help='"Email address of the grantee. For a list of all the Amazon S3 supported Regions and endpoints, see Regions and Endpoints (https://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region) in the AWS General Reference."', args=[d.arg(name='emailAddress', type=d.T.string)]),
            withEmailAddress(emailAddress): { targetGrantee+: { emailAddress: emailAddress } },
            '#withId':: d.fn(help='"The canonical user ID of the grantee."', args=[d.arg(name='id', type=d.T.string)]),
            withId(id): { targetGrantee+: { id: id } },
            '#withType':: d.fn(help='"Type of grantee Type is a required field"', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { targetGrantee+: { type: type } },
            '#withUri':: d.fn(help='"URI of the grantee group."', args=[d.arg(name='uri', type=d.T.string)]),
            withUri(uri): { targetGrantee+: { uri: uri } },
          },
          '#withBucketLogsPermission':: d.fn(help='"Logging permissions assigned to the Grantee for the bucket. Valid values are \\"FULL_CONTROL\\", \\"READ\\", \\"WRITE\\', args=[d.arg(name='bucketLogsPermission', type=d.T.string)]),
          withBucketLogsPermission(bucketLogsPermission): { bucketLogsPermission: bucketLogsPermission },
        },
        '#withTargetBucket':: d.fn(help='"TargetBucket where logs will be stored, it can be the same bucket. At least one of targetBucket, targetBucketRef or targetBucketSelector is required."', args=[d.arg(name='targetBucket', type=d.T.string)]),
        withTargetBucket(targetBucket): { spec+: { forProvider+: { loggingConfiguration+: { targetBucket: targetBucket } } } },
        '#withTargetGrants':: d.fn(help='"Container for granting information."', args=[d.arg(name='targetGrants', type=d.T.array)]),
        withTargetGrants(targetGrants): { spec+: { forProvider+: { loggingConfiguration+: { targetGrants: if std.isArray(v=targetGrants) then targetGrants else [targetGrants] } } } },
        '#withTargetGrantsMixin':: d.fn(help='"Container for granting information."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='targetGrants', type=d.T.array)]),
        withTargetGrantsMixin(targetGrants): { spec+: { forProvider+: { loggingConfiguration+: { targetGrants+: if std.isArray(v=targetGrants) then targetGrants else [targetGrants] } } } },
        '#withTargetPrefix':: d.fn(help='"A prefix for all log object keys."', args=[d.arg(name='targetPrefix', type=d.T.string)]),
        withTargetPrefix(targetPrefix): { spec+: { forProvider+: { loggingConfiguration+: { targetPrefix: targetPrefix } } } },
      },
      '#notificationConfiguration':: d.obj(help='"Enables notifications of specified events for a bucket. For more information about event notifications, see Configuring Event Notifications (https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html)."'),
      notificationConfiguration: {
        '#lambdaFunctionConfigurations':: d.obj(help='"Describes the AWS Lambda functions to invoke and the events for which to invoke them."'),
        lambdaFunctionConfigurations: {
          '#filter':: d.obj(help='"Specifies object key name filtering rules. For information about key name filtering, see Configuring Event Notifications (https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html) in the Amazon Simple Storage Service Developer Guide."'),
          filter: {
            '#key':: d.obj(help='"A container for object key name prefix and suffix filtering rules."'),
            key: {
              '#filterRules':: d.obj(help='"A list of containers for the key-value pair that defines the criteria for the filter rule."'),
              filterRules: {
                '#withName':: d.fn(help='"The object key name prefix or suffix identifying one or more objects to which the filtering rule applies. The maximum length is 1,024 characters. Overlapping prefixes and suffixes are not supported. For more information, see Configuring Event Notifications (https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html) in the Amazon Simple Storage Service Developer Guide. Valid values are \\"prefix\\" or \\"suffix\\', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withValue':: d.fn(help='"The value that the filter searches for in object key names."', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#withFilterRules':: d.fn(help='"A list of containers for the key-value pair that defines the criteria for the filter rule."', args=[d.arg(name='filterRules', type=d.T.array)]),
              withFilterRules(filterRules): { filter+: { key+: { filterRules: if std.isArray(v=filterRules) then filterRules else [filterRules] } } },
              '#withFilterRulesMixin':: d.fn(help='"A list of containers for the key-value pair that defines the criteria for the filter rule."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='filterRules', type=d.T.array)]),
              withFilterRulesMixin(filterRules): { filter+: { key+: { filterRules+: if std.isArray(v=filterRules) then filterRules else [filterRules] } } },
            },
          },
          '#withEvents':: d.fn(help='"The Amazon S3 bucket event for which to invoke the AWS Lambda function. For more information, see Supported Event Types (https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html) in the Amazon Simple Storage Service Developer Guide. \\n Events is a required field A full list of valid events can be found in the Amazon S3 Developer guide https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations"', args=[d.arg(name='events', type=d.T.array)]),
          withEvents(events): { events: if std.isArray(v=events) then events else [events] },
          '#withEventsMixin':: d.fn(help='"The Amazon S3 bucket event for which to invoke the AWS Lambda function. For more information, see Supported Event Types (https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html) in the Amazon Simple Storage Service Developer Guide. \\n Events is a required field A full list of valid events can be found in the Amazon S3 Developer guide https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='events', type=d.T.array)]),
          withEventsMixin(events): { events+: if std.isArray(v=events) then events else [events] },
          '#withId':: d.fn(help="\"An optional unique identifier for configurations in a notification configuration. If you don't provide one, Amazon S3 will assign an ID.\"", args=[d.arg(name='id', type=d.T.string)]),
          withId(id): { id: id },
          '#withLambdaFunctionArn':: d.fn(help='"The Amazon Resource Name (ARN) of the AWS Lambda function that Amazon S3 invokes when the specified event type occurs. \\n LambdaFunctionArn is a required field"', args=[d.arg(name='lambdaFunctionArn', type=d.T.string)]),
          withLambdaFunctionArn(lambdaFunctionArn): { lambdaFunctionArn: lambdaFunctionArn },
        },
        '#queueConfigurations':: d.obj(help='"The Amazon Simple Queue Service queues to publish messages to and the events for which to publish messages."'),
        queueConfigurations: {
          '#filter':: d.obj(help='"Specifies object key name filtering rules. For information about key name filtering, see Configuring Event Notifications (https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html) in the Amazon Simple Storage Service Developer Guide."'),
          filter: {
            '#key':: d.obj(help='"A container for object key name prefix and suffix filtering rules."'),
            key: {
              '#filterRules':: d.obj(help='"A list of containers for the key-value pair that defines the criteria for the filter rule."'),
              filterRules: {
                '#withName':: d.fn(help='"The object key name prefix or suffix identifying one or more objects to which the filtering rule applies. The maximum length is 1,024 characters. Overlapping prefixes and suffixes are not supported. For more information, see Configuring Event Notifications (https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html) in the Amazon Simple Storage Service Developer Guide. Valid values are \\"prefix\\" or \\"suffix\\', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withValue':: d.fn(help='"The value that the filter searches for in object key names."', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#withFilterRules':: d.fn(help='"A list of containers for the key-value pair that defines the criteria for the filter rule."', args=[d.arg(name='filterRules', type=d.T.array)]),
              withFilterRules(filterRules): { filter+: { key+: { filterRules: if std.isArray(v=filterRules) then filterRules else [filterRules] } } },
              '#withFilterRulesMixin':: d.fn(help='"A list of containers for the key-value pair that defines the criteria for the filter rule."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='filterRules', type=d.T.array)]),
              withFilterRulesMixin(filterRules): { filter+: { key+: { filterRules+: if std.isArray(v=filterRules) then filterRules else [filterRules] } } },
            },
          },
          '#withEvents':: d.fn(help='"A collection of bucket events for which to send notifications \\n Events is a required field A full list of valid events can be found in the Amazon S3 Developer guide https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations"', args=[d.arg(name='events', type=d.T.array)]),
          withEvents(events): { events: if std.isArray(v=events) then events else [events] },
          '#withEventsMixin':: d.fn(help='"A collection of bucket events for which to send notifications \\n Events is a required field A full list of valid events can be found in the Amazon S3 Developer guide https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='events', type=d.T.array)]),
          withEventsMixin(events): { events+: if std.isArray(v=events) then events else [events] },
          '#withId':: d.fn(help="\"An optional unique identifier for configurations in a notification configuration. If you don't provide one, Amazon S3 will assign an ID.\"", args=[d.arg(name='id', type=d.T.string)]),
          withId(id): { id: id },
          '#withQueueArn':: d.fn(help='"The Amazon Resource Name (ARN) of the Amazon SQS queue to which Amazon S3 publishes a message when it detects events of the specified type. \\n QueueArn is a required field"', args=[d.arg(name='queueArn', type=d.T.string)]),
          withQueueArn(queueArn): { queueArn: queueArn },
        },
        '#topicConfigurations':: d.obj(help='"The topic to which notifications are sent and the events for which notifications are generated."'),
        topicConfigurations: {
          '#filter':: d.obj(help='"Specifies object key name filtering rules. For information about key name filtering, see Configuring Event Notifications (https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html) in the Amazon Simple Storage Service Developer Guide."'),
          filter: {
            '#key':: d.obj(help='"A container for object key name prefix and suffix filtering rules."'),
            key: {
              '#filterRules':: d.obj(help='"A list of containers for the key-value pair that defines the criteria for the filter rule."'),
              filterRules: {
                '#withName':: d.fn(help='"The object key name prefix or suffix identifying one or more objects to which the filtering rule applies. The maximum length is 1,024 characters. Overlapping prefixes and suffixes are not supported. For more information, see Configuring Event Notifications (https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html) in the Amazon Simple Storage Service Developer Guide. Valid values are \\"prefix\\" or \\"suffix\\', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withValue':: d.fn(help='"The value that the filter searches for in object key names."', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#withFilterRules':: d.fn(help='"A list of containers for the key-value pair that defines the criteria for the filter rule."', args=[d.arg(name='filterRules', type=d.T.array)]),
              withFilterRules(filterRules): { filter+: { key+: { filterRules: if std.isArray(v=filterRules) then filterRules else [filterRules] } } },
              '#withFilterRulesMixin':: d.fn(help='"A list of containers for the key-value pair that defines the criteria for the filter rule."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='filterRules', type=d.T.array)]),
              withFilterRulesMixin(filterRules): { filter+: { key+: { filterRules+: if std.isArray(v=filterRules) then filterRules else [filterRules] } } },
            },
          },
          '#topicRef':: d.obj(help='"TopicArnRef references an SNS Topic to retrieve its Arn"'),
          topicRef: {
            '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { topicRef+: { name: name } },
          },
          '#topicSelector':: d.obj(help='"TopicArnSelector selects a reference to an SNS Topic to retrieve its Arn"'),
          topicSelector: {
            '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
            withMatchControllerRef(matchControllerRef): { topicSelector+: { matchControllerRef: matchControllerRef } },
            '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabels(matchLabels): { topicSelector+: { matchLabels: matchLabels } },
            '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabelsMixin(matchLabels): { topicSelector+: { matchLabels+: matchLabels } },
          },
          '#withEvents':: d.fn(help='"The Amazon S3 bucket event about which to send notifications. For more information, see Supported Event Types (https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html) in the Amazon Simple Storage Service Developer Guide. \\n Events is a required field A full list of valid events can be found in the Amazon S3 Developer guide https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations"', args=[d.arg(name='events', type=d.T.array)]),
          withEvents(events): { events: if std.isArray(v=events) then events else [events] },
          '#withEventsMixin':: d.fn(help='"The Amazon S3 bucket event about which to send notifications. For more information, see Supported Event Types (https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html) in the Amazon Simple Storage Service Developer Guide. \\n Events is a required field A full list of valid events can be found in the Amazon S3 Developer guide https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='events', type=d.T.array)]),
          withEventsMixin(events): { events+: if std.isArray(v=events) then events else [events] },
          '#withId':: d.fn(help="\"An optional unique identifier for configurations in a notification configuration. If you don't provide one, Amazon S3 will assign an ID.\"", args=[d.arg(name='id', type=d.T.string)]),
          withId(id): { id: id },
          '#withTopicArn':: d.fn(help='"The Amazon Resource Name (ARN) of the Amazon SNS topic to which Amazon S3 publishes a message when it detects events of the specified type. At least one of topicArn, topicArnRef or topicSelector is required."', args=[d.arg(name='topicArn', type=d.T.string)]),
          withTopicArn(topicArn): { topicArn: topicArn },
        },
        '#withLambdaFunctionConfigurations':: d.fn(help='"Describes the AWS Lambda functions to invoke and the events for which to invoke them."', args=[d.arg(name='lambdaFunctionConfigurations', type=d.T.array)]),
        withLambdaFunctionConfigurations(lambdaFunctionConfigurations): { spec+: { forProvider+: { notificationConfiguration+: { lambdaFunctionConfigurations: if std.isArray(v=lambdaFunctionConfigurations) then lambdaFunctionConfigurations else [lambdaFunctionConfigurations] } } } },
        '#withLambdaFunctionConfigurationsMixin':: d.fn(help='"Describes the AWS Lambda functions to invoke and the events for which to invoke them."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='lambdaFunctionConfigurations', type=d.T.array)]),
        withLambdaFunctionConfigurationsMixin(lambdaFunctionConfigurations): { spec+: { forProvider+: { notificationConfiguration+: { lambdaFunctionConfigurations+: if std.isArray(v=lambdaFunctionConfigurations) then lambdaFunctionConfigurations else [lambdaFunctionConfigurations] } } } },
        '#withQueueConfigurations':: d.fn(help='"The Amazon Simple Queue Service queues to publish messages to and the events for which to publish messages."', args=[d.arg(name='queueConfigurations', type=d.T.array)]),
        withQueueConfigurations(queueConfigurations): { spec+: { forProvider+: { notificationConfiguration+: { queueConfigurations: if std.isArray(v=queueConfigurations) then queueConfigurations else [queueConfigurations] } } } },
        '#withQueueConfigurationsMixin':: d.fn(help='"The Amazon Simple Queue Service queues to publish messages to and the events for which to publish messages."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='queueConfigurations', type=d.T.array)]),
        withQueueConfigurationsMixin(queueConfigurations): { spec+: { forProvider+: { notificationConfiguration+: { queueConfigurations+: if std.isArray(v=queueConfigurations) then queueConfigurations else [queueConfigurations] } } } },
        '#withTopicConfigurations':: d.fn(help='"The topic to which notifications are sent and the events for which notifications are generated."', args=[d.arg(name='topicConfigurations', type=d.T.array)]),
        withTopicConfigurations(topicConfigurations): { spec+: { forProvider+: { notificationConfiguration+: { topicConfigurations: if std.isArray(v=topicConfigurations) then topicConfigurations else [topicConfigurations] } } } },
        '#withTopicConfigurationsMixin':: d.fn(help='"The topic to which notifications are sent and the events for which notifications are generated."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='topicConfigurations', type=d.T.array)]),
        withTopicConfigurationsMixin(topicConfigurations): { spec+: { forProvider+: { notificationConfiguration+: { topicConfigurations+: if std.isArray(v=topicConfigurations) then topicConfigurations else [topicConfigurations] } } } },
      },
      '#paymentConfiguration':: d.obj(help='"Specifies payer parameters for an Amazon S3 bucket. For more information, see Request Pays buckets (https://docs.aws.amazon.com/AmazonS3/latest/dev/RequesterPaysBuckets.html) in the Amazon Simple Storage Service Developer Guide."'),
      paymentConfiguration: {
        '#withPayer':: d.fn(help='"Payer is a required field, detailing who pays Valid values are \\"Requester\\" and \\"BucketOwner\\', args=[d.arg(name='payer', type=d.T.string)]),
        withPayer(payer): { spec+: { forProvider+: { paymentConfiguration+: { payer: payer } } } },
      },
      '#publicAccessBlockConfiguration':: d.obj(help='"PublicAccessBlockConfiguration that you want to apply to this Amazon S3 bucket."'),
      publicAccessBlockConfiguration: {
        '#withBlockPublicAcls':: d.fn(help="\"Specifies whether Amazon S3 should block public access control lists (ACLs) for this bucket and objects in this bucket. Setting this element to TRUE causes the following behavior: \\n    * PUT Bucket acl and PUT Object acl calls fail if the specified ACL is    public. \\n    * PUT Object calls fail if the request includes a public ACL. \\n    * PUT Bucket calls fail if the request includes a public ACL. \\n Enabling this setting doesn't affect existing policies or ACLs.\"", args=[d.arg(name='blockPublicAcls', type=d.T.boolean)]),
        withBlockPublicAcls(blockPublicAcls): { spec+: { forProvider+: { publicAccessBlockConfiguration+: { blockPublicAcls: blockPublicAcls } } } },
        '#withBlockPublicPolicy':: d.fn(help="\"Specifies whether Amazon S3 should block public bucket policies for this bucket. Setting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket policy allows public access. \\n Enabling this setting doesn't affect existing bucket policies.\"", args=[d.arg(name='blockPublicPolicy', type=d.T.boolean)]),
        withBlockPublicPolicy(blockPublicPolicy): { spec+: { forProvider+: { publicAccessBlockConfiguration+: { blockPublicPolicy: blockPublicPolicy } } } },
        '#withIgnorePublicAcls':: d.fn(help="\"Specifies whether Amazon S3 should ignore public ACLs for this bucket and objects in this bucket. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on this bucket and objects in this bucket. \\n Enabling this setting doesn't affect the persistence of any existing ACLs and doesn't prevent new public ACLs from being set.\"", args=[d.arg(name='ignorePublicAcls', type=d.T.boolean)]),
        withIgnorePublicAcls(ignorePublicAcls): { spec+: { forProvider+: { publicAccessBlockConfiguration+: { ignorePublicAcls: ignorePublicAcls } } } },
        '#withRestrictPublicBuckets':: d.fn(help="\"Specifies whether Amazon S3 should restrict public bucket policies for this bucket. Setting this element to TRUE restricts access to this bucket to only AWS services and authorized users within this account if the bucket has a public policy. \\n Enabling this setting doesn't affect previously stored bucket policies, except that public and cross-account access within any public bucket policy, including non-public delegation to specific accounts, is blocked.\"", args=[d.arg(name='restrictPublicBuckets', type=d.T.boolean)]),
        withRestrictPublicBuckets(restrictPublicBuckets): { spec+: { forProvider+: { publicAccessBlockConfiguration+: { restrictPublicBuckets: restrictPublicBuckets } } } },
      },
      '#replicationConfiguration':: d.obj(help='"Creates a replication configuration or replaces an existing one. For more information, see Replication (https://docs.aws.amazon.com/AmazonS3/latest/dev/replication.html) in the Amazon S3 Developer Guide."'),
      replicationConfiguration: {
        '#roleRef':: d.obj(help='"RoleRef references an IAMRole to retrieve its Name"'),
        roleRef: {
          '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { forProvider+: { replicationConfiguration+: { roleRef+: { name: name } } } } },
        },
        '#roleSelector':: d.obj(help='"RoleSelector selects a reference to an IAMRole to retrieve its Name"'),
        roleSelector: {
          '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
          withMatchControllerRef(matchControllerRef): { spec+: { forProvider+: { replicationConfiguration+: { roleSelector+: { matchControllerRef: matchControllerRef } } } } },
          '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { spec+: { forProvider+: { replicationConfiguration+: { roleSelector+: { matchLabels: matchLabels } } } } },
          '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { spec+: { forProvider+: { replicationConfiguration+: { roleSelector+: { matchLabels+: matchLabels } } } } },
        },
        '#rules':: d.obj(help='"A container for one or more replication rules. A replication configuration must have at least one rule and can contain a maximum of 1,000 rules. \\n Rules is a required field"'),
        rules: {
          '#deleteMarkerReplication':: d.obj(help="\"Specifies whether Amazon S3 replicates the delete markers. If you specify a Filter, you must specify this element. However, in the latest version of replication configuration (when Filter is specified), Amazon S3 doesn't replicate delete markers. Therefore, the DeleteMarkerReplication element can contain only \u003cStatus\u003eDisabled\u003c/Status\u003e. For an example configuration, see Basic Rule Configuration (https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-add-config.html#replication-config-min-rule-config). \\n If you don't specify the Filter element, Amazon S3 assumes that the replication configuration is the earlier version, V1. In the earlier version, Amazon S3 handled replication of delete markers differently. For more information, see Backward Compatibility (https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-add-config.html#replication-backward-compat-considerations).\""),
          deleteMarkerReplication: {
            '#withStatus':: d.fn(help="\"Indicates whether to replicate delete markers. In the current implementation, Amazon S3 doesn't replicate the delete markers. The status must be \\\"Disabled\\\".\"", args=[d.arg(name='status', type=d.T.string)]),
            withStatus(status): { deleteMarkerReplication+: { status: status } },
          },
          '#destination':: d.obj(help='"A container for information about the replication destination and its configurations including enabling the S3 Replication Time Control (S3 RTC). \\n Destination is a required field"'),
          destination: {
            '#accessControlTranslation':: d.obj(help='"Specify this only in a cross-account scenario (where source and destination bucket owners are not the same), and you want to change replica ownership to the AWS account that owns the destination bucket. If this is not specified in the replication configuration, the replicas are owned by same AWS account that owns the source object."'),
            accessControlTranslation: {
              '#withOwnerOverride':: d.fn(help='"Specifies the replica ownership. For default and valid values, see PUT bucket replication (https://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketPUTreplication.html) in the Amazon Simple Storage Service API Reference. Owner is a required field"', args=[d.arg(name='ownerOverride', type=d.T.string)]),
              withOwnerOverride(ownerOverride): { destination+: { accessControlTranslation+: { ownerOverride: ownerOverride } } },
            },
            '#bucketRef':: d.obj(help='"BucketRef references a Bucket to retrieve its Name"'),
            bucketRef: {
              '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { destination+: { bucketRef+: { name: name } } },
            },
            '#bucketSelector':: d.obj(help='"BucketSelector selects a reference to a Bucket to retrieve its Name"'),
            bucketSelector: {
              '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
              withMatchControllerRef(matchControllerRef): { destination+: { bucketSelector+: { matchControllerRef: matchControllerRef } } },
              '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { destination+: { bucketSelector+: { matchLabels: matchLabels } } },
              '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { destination+: { bucketSelector+: { matchLabels+: matchLabels } } },
            },
            '#encryptionConfiguration':: d.obj(help='"A container that provides information about encryption. If SourceSelectionCriteria is specified, you must specify this element."'),
            encryptionConfiguration: {
              '#withReplicaKmsKeyId':: d.fn(help='"Specifies the ID (Key ARN or Alias ARN) of the customer managed customer master key (CMK) stored in AWS Key Management Service (KMS) for the destination bucket. Amazon S3 uses this key to encrypt replica objects. Amazon S3 only supports symmetric customer managed CMKs. For more information, see Using Symmetric and Asymmetric Keys (https://docs.aws.amazon.com/kms/latest/developerguide/symmetric-asymmetric.html) in the AWS Key Management Service Developer Guide."', args=[d.arg(name='replicaKmsKeyId', type=d.T.string)]),
              withReplicaKmsKeyId(replicaKmsKeyId): { destination+: { encryptionConfiguration+: { replicaKmsKeyId: replicaKmsKeyId } } },
            },
            '#metrics':: d.obj(help='"A container specifying replication metrics-related settings enabling metrics and Amazon S3 events for S3 Replication Time Control (S3 RTC). Must be specified together with a ReplicationTime block."'),
            metrics: {
              '#eventThreshold':: d.obj(help='"A container specifying the time threshold for emitting the s3:Replication:OperationMissedThreshold event. EventThreshold is a required field"'),
              eventThreshold: {
                '#withMinutes':: d.fn(help='"Contains an integer specifying time in minutes. \\n Valid values: 15 minutes."', args=[d.arg(name='minutes', type=d.T.integer)]),
                withMinutes(minutes): { destination+: { metrics+: { eventThreshold+: { minutes: minutes } } } },
              },
            },
            '#replicationTime':: d.obj(help='"A container specifying S3 Replication Time Control (S3 RTC), including whether S3 RTC is enabled and the time when all objects and operations on objects must be replicated. Must be specified together with a Metrics block."'),
            replicationTime: {
              '#time':: d.obj(help='"A container specifying the time by which replication should be complete for all objects and operations on objects. Time is a required field"'),
              time: {
                '#withMinutes':: d.fn(help='"Contains an integer specifying time in minutes. \\n Valid values: 15 minutes."', args=[d.arg(name='minutes', type=d.T.integer)]),
                withMinutes(minutes): { destination+: { replicationTime+: { time+: { minutes: minutes } } } },
              },
            },
            '#withAccount':: d.fn(help='"Destination bucket owner account ID. In a cross-account scenario, if you direct Amazon S3 to change replica ownership to the AWS account that owns the destination bucket by specifying the AccessControlTranslation property, this is the account ID of the destination bucket owner. For more information, see Replication Additional Configuration: Changing the Replica Owner (https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-change-owner.html) in the Amazon Simple Storage Service Developer Guide."', args=[d.arg(name='account', type=d.T.string)]),
            withAccount(account): { destination+: { account: account } },
            '#withBucket':: d.fn(help='"The Amazon Resource Name (ARN) of the bucket where you want Amazon S3 to store the results. At least one of bucket, bucketRef or bucketSelector is required."', args=[d.arg(name='bucket', type=d.T.string)]),
            withBucket(bucket): { destination+: { bucket: bucket } },
            '#withStorageClass':: d.fn(help='"The storage class to use when replicating objects, such as S3 Standard or reduced redundancy. By default, Amazon S3 uses the storage class of the source object to create the object replica. For valid values, see the StorageClass element of the PUT Bucket replication (https://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketPUTreplication.html) action in the Amazon Simple Storage Service API Reference."', args=[d.arg(name='storageClass', type=d.T.string)]),
            withStorageClass(storageClass): { destination+: { storageClass: storageClass } },
          },
          '#existingObjectReplication':: d.obj(help='"Optional configuration to replicate existing source bucket objects. For more information, see Replicating Existing Objects (https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-what-is-isnot-replicated.html#existing-object-replication) in the Amazon S3 Developer Guide."'),
          existingObjectReplication: {},
          '#filter':: d.obj(help='"A filter that identifies the subset of objects to which the replication rule applies. A Filter must specify exactly one Prefix, Tag, or an And child element."'),
          filter: {
            '#and':: d.obj(help='"A container for specifying rule filters. The filters determine the subset of objects to which the rule applies. This element is required only if you specify more than one filter. For example: \\n    * If you specify both a Prefix and a Tag filter, wrap these filters in    an And tag. \\n    * If you specify a filter based on multiple tags, wrap the Tag elements    in an And tag."'),
            and: {
              '#tag':: d.obj(help='"An array of tags containing key and value pairs."'),
              tag: {
                '#withKey':: d.fn(help='"Name of the tag. Key is a required field"', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withValue':: d.fn(help='"Value of the tag. Value is a required field"', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#withPrefix':: d.fn(help='"An object key name prefix that identifies the subset of objects to which the rule applies."', args=[d.arg(name='prefix', type=d.T.string)]),
              withPrefix(prefix): { filter+: { and+: { prefix: prefix } } },
              '#withTag':: d.fn(help='"An array of tags containing key and value pairs."', args=[d.arg(name='tag', type=d.T.array)]),
              withTag(tag): { filter+: { and+: { tag: if std.isArray(v=tag) then tag else [tag] } } },
              '#withTagMixin':: d.fn(help='"An array of tags containing key and value pairs."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tag', type=d.T.array)]),
              withTagMixin(tag): { filter+: { and+: { tag+: if std.isArray(v=tag) then tag else [tag] } } },
            },
            '#tag':: d.obj(help='"A container for specifying a tag key and value. The rule applies only to objects that have the tag in their tag set."'),
            tag: {
              '#withKey':: d.fn(help='"Name of the tag. Key is a required field"', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { filter+: { tag+: { key: key } } },
              '#withValue':: d.fn(help='"Value of the tag. Value is a required field"', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { filter+: { tag+: { value: value } } },
            },
            '#withPrefix':: d.fn(help='"An object key name prefix that identifies the subset of objects to which the rule applies."', args=[d.arg(name='prefix', type=d.T.string)]),
            withPrefix(prefix): { filter+: { prefix: prefix } },
          },
          '#sourceSelectionCriteria':: d.obj(help='"A container that describes additional filters for identifying the source objects that you want to replicate. You can choose to enable or disable the replication of these objects. Currently, Amazon S3 supports only the filter that you can specify for objects created with server-side encryption using a customer master key (CMK) stored in AWS Key Management Service (SSE-KMS)."'),
          sourceSelectionCriteria: {
            '#sseKmsEncryptedObjects':: d.obj(help='"A container for filter information for the selection of Amazon S3 objects encrypted with AWS KMS. If you include SourceSelectionCriteria in the replication configuration, this element is required."'),
            sseKmsEncryptedObjects: {},
          },
          '#withId':: d.fn(help='"A unique identifier for the rule. The maximum value is 255 characters."', args=[d.arg(name='id', type=d.T.string)]),
          withId(id): { id: id },
          '#withPriority':: d.fn(help='"The priority associated with the rule. If you specify multiple rules in a replication configuration, Amazon S3 prioritizes the rules to prevent conflicts when filtering. If two or more rules identify the same object based on a specified filter, the rule with higher priority takes precedence. For example: \\n    * Same object quality prefix-based filter criteria if prefixes you specified    in multiple rules overlap \\n    * Same object qualify tag-based filter criteria specified in multiple    rules \\n For more information, see Replication (https://docs.aws.amazon.com/AmazonS3/latest/dev/replication.html) in the Amazon Simple Storage Service Developer Guide."', args=[d.arg(name='priority', type=d.T.integer)]),
          withPriority(priority): { priority: priority },
        },
        '#withRole':: d.fn(help='"The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that Amazon S3 assumes when replicating objects. For more information, see How to Set Up Replication (https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-how-setup.html) in the Amazon Simple Storage Service Developer Guide. \\n At least one of role, roleRef or roleSelector fields is required."', args=[d.arg(name='role', type=d.T.string)]),
        withRole(role): { spec+: { forProvider+: { replicationConfiguration+: { role: role } } } },
        '#withRules':: d.fn(help='"A container for one or more replication rules. A replication configuration must have at least one rule and can contain a maximum of 1,000 rules. \\n Rules is a required field"', args=[d.arg(name='rules', type=d.T.array)]),
        withRules(rules): { spec+: { forProvider+: { replicationConfiguration+: { rules: if std.isArray(v=rules) then rules else [rules] } } } },
        '#withRulesMixin':: d.fn(help='"A container for one or more replication rules. A replication configuration must have at least one rule and can contain a maximum of 1,000 rules. \\n Rules is a required field"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='rules', type=d.T.array)]),
        withRulesMixin(rules): { spec+: { forProvider+: { replicationConfiguration+: { rules+: if std.isArray(v=rules) then rules else [rules] } } } },
      },
      '#serverSideEncryptionConfiguration':: d.obj(help='"Specifies default encryption for a bucket using server-side encryption with Amazon S3-managed keys (SSE-S3) or customer master keys stored in AWS KMS (SSE-KMS). For information about the Amazon S3 default encryption feature, see Amazon S3 Default Bucket Encryption (https://docs.aws.amazon.com/AmazonS3/latest/dev/bucket-encryption.html) in the Amazon Simple Storage Service Developer Guide."'),
      serverSideEncryptionConfiguration: {
        '#rules':: d.obj(help='"Container for information about a particular server-side encryption configuration rule."'),
        rules: {
          '#applyServerSideEncryptionByDefault':: d.obj(help="\"Specifies the default server-side encryption to apply to new objects in the bucket. If a PUT Object request doesn't specify any server-side encryption, this default encryption will be applied.\""),
          applyServerSideEncryptionByDefault: {
            '#withKmsMasterKeyId':: d.fn(help='"AWS Key Management Service (KMS) customer master key ID to use for the default encryption. This parameter is allowed if and only if SSEAlgorithm is set to aws:kms. \\n You can specify the key ID or the Amazon Resource Name (ARN) of the CMK. However, if you are using encryption with cross-account operations, you must use a fully qualified CMK ARN. For more information, see Using encryption for cross-account operations (https://docs.aws.amazon.com/AmazonS3/latest/dev/bucket-encryption.html#bucket-encryption-update-bucket-policy). \\n For example: \\n    * Key ID: 1234abcd-12ab-34cd-56ef-1234567890ab \\n    * Key ARN: arn:aws:kms:us-east-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab \\n Amazon S3 only supports symmetric CMKs and not asymmetric CMKs. For more information, see Using Symmetric and Asymmetric Keys (https://docs.aws.amazon.com/kms/latest/developerguide/symmetric-asymmetric.html) in the AWS Key Management Service Developer Guide."', args=[d.arg(name='kmsMasterKeyId', type=d.T.string)]),
            withKmsMasterKeyId(kmsMasterKeyId): { applyServerSideEncryptionByDefault+: { kmsMasterKeyId: kmsMasterKeyId } },
            '#withSseAlgorithm':: d.fn(help='"Server-side encryption algorithm to use for the default encryption. Options are AES256 or aws:kms"', args=[d.arg(name='sseAlgorithm', type=d.T.string)]),
            withSseAlgorithm(sseAlgorithm): { applyServerSideEncryptionByDefault+: { sseAlgorithm: sseAlgorithm } },
          },
        },
        '#withRules':: d.fn(help='"Container for information about a particular server-side encryption configuration rule."', args=[d.arg(name='rules', type=d.T.array)]),
        withRules(rules): { spec+: { forProvider+: { serverSideEncryptionConfiguration+: { rules: if std.isArray(v=rules) then rules else [rules] } } } },
        '#withRulesMixin':: d.fn(help='"Container for information about a particular server-side encryption configuration rule."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='rules', type=d.T.array)]),
        withRulesMixin(rules): { spec+: { forProvider+: { serverSideEncryptionConfiguration+: { rules+: if std.isArray(v=rules) then rules else [rules] } } } },
      },
      '#tagging':: d.obj(help='"Sets the tags for a bucket. Use tags to organize your AWS bill to reflect your own cost structure. For more information, see Billing and usage reporting for S3 buckets. (https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketBilling.html) in the Amazon Simple Storage Service Developer Guide."'),
      tagging: {
        '#tagSet':: d.obj(help='"A collection for a set of tags TagSet is a required field"'),
        tagSet: {
          '#withKey':: d.fn(help='"Name of the tag. Key is a required field"', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { key: key },
          '#withValue':: d.fn(help='"Value of the tag. Value is a required field"', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#withTagSet':: d.fn(help='"A collection for a set of tags TagSet is a required field"', args=[d.arg(name='tagSet', type=d.T.array)]),
        withTagSet(tagSet): { spec+: { forProvider+: { tagging+: { tagSet: if std.isArray(v=tagSet) then tagSet else [tagSet] } } } },
        '#withTagSetMixin':: d.fn(help='"A collection for a set of tags TagSet is a required field"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tagSet', type=d.T.array)]),
        withTagSetMixin(tagSet): { spec+: { forProvider+: { tagging+: { tagSet+: if std.isArray(v=tagSet) then tagSet else [tagSet] } } } },
      },
      '#versioningConfiguration':: d.obj(help="\"VersioningConfiguration describes the versioning state of an Amazon S3 bucket. See the AWS API reference guide for Amazon Simple Storage Service's API operation PutBucketVersioning for usage and error information. See also, https://docs.aws.amazon.com/goto/WebAPI/s3-2006-03-01/PutBucketVersioning\""),
      versioningConfiguration: {
        '#withMfaDelete':: d.fn(help='"MFADelete specifies whether MFA delete is enabled in the bucket versioning configuration. This element is only returned if the bucket has been configured with MFA delete. If the bucket has never been so configured, this element is not returned."', args=[d.arg(name='mfaDelete', type=d.T.string)]),
        withMfaDelete(mfaDelete): { spec+: { forProvider+: { versioningConfiguration+: { mfaDelete: mfaDelete } } } },
      },
      '#websiteConfiguration':: d.obj(help="\"Specifies website configuration parameters for an Amazon S3 bucket. See the AWS API reference guide for Amazon Simple Storage Service's API operation PutBucketWebsite for usage and error information. See also, https://docs.aws.amazon.com/goto/WebAPI/s3-2006-03-01/PutBucketWebsite\""),
      websiteConfiguration: {
        '#errorDocument':: d.obj(help='"The name of the error document for the website."'),
        errorDocument: {
          '#withKey':: d.fn(help='"The object key name to use when a 4XX class error occurs."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { spec+: { forProvider+: { websiteConfiguration+: { errorDocument+: { key: key } } } } },
        },
        '#indexDocument':: d.obj(help='"The name of the index document for the website."'),
        indexDocument: {
          '#withSuffix':: d.fn(help='"A suffix that is appended to a request that is for a directory on the website endpoint (for example,if the suffix is index.html and you make a request to samplebucket/images/ the data that is returned will be for the object with the key name images/index.html) The suffix must not be empty and must not include a slash character."', args=[d.arg(name='suffix', type=d.T.string)]),
          withSuffix(suffix): { spec+: { forProvider+: { websiteConfiguration+: { indexDocument+: { suffix: suffix } } } } },
        },
        '#redirectAllRequestsTo':: d.obj(help="\"The redirect behavior for every request to this bucket's website endpoint. If you specify this property, you can't specify any other property.\""),
        redirectAllRequestsTo: {
          '#withHostName':: d.fn(help='"Name of the host where requests are redirected."', args=[d.arg(name='hostName', type=d.T.string)]),
          withHostName(hostName): { spec+: { forProvider+: { websiteConfiguration+: { redirectAllRequestsTo+: { hostName: hostName } } } } },
          '#withProtocol':: d.fn(help='"Protocol to use when redirecting requests. The default is the protocol that is used in the original request."', args=[d.arg(name='protocol', type=d.T.string)]),
          withProtocol(protocol): { spec+: { forProvider+: { websiteConfiguration+: { redirectAllRequestsTo+: { protocol: protocol } } } } },
        },
        '#routingRules':: d.obj(help='"Rules that define when a redirect is applied and the redirect behavior."'),
        routingRules: {
          '#condition':: d.obj(help='"A container for describing a condition that must be met for the specified redirect to apply. For example, 1. If request is for pages in the /docs folder, redirect to the /documents folder. 2. If request results in HTTP error 4xx, redirect request to another host where you might process the error."'),
          condition: {
            '#withHttpErrorCodeReturnedEquals':: d.fn(help='"The HTTP error code when the redirect is applied. In the event of an error, if the error code equals this value, then the specified redirect is applied. Required when parent element Condition is specified and sibling KeyPrefixEquals is not specified. If both are specified, then both must be true for the redirect to be applied."', args=[d.arg(name='httpErrorCodeReturnedEquals', type=d.T.string)]),
            withHttpErrorCodeReturnedEquals(httpErrorCodeReturnedEquals): { condition+: { httpErrorCodeReturnedEquals: httpErrorCodeReturnedEquals } },
            '#withKeyPrefixEquals':: d.fn(help='"The object key name prefix when the redirect is applied. For example, to redirect requests for ExamplePage.html, the key prefix will be ExamplePage.html. To redirect request for all pages with the prefix docs/, the key prefix will be /docs, which identifies all objects in the docs/ folder. Required when the parent element Condition is specified and sibling HttpErrorCodeReturnedEquals is not specified. If both conditions are specified, both must be true for the redirect to be applied."', args=[d.arg(name='keyPrefixEquals', type=d.T.string)]),
            withKeyPrefixEquals(keyPrefixEquals): { condition+: { keyPrefixEquals: keyPrefixEquals } },
          },
          '#redirect':: d.obj(help='"Container for redirect information. You can redirect requests to another host, to another page, or with another protocol. In the event of an error, you can specify a different error code to return."'),
          redirect: {
            '#withHttpRedirectCode':: d.fn(help='"The HTTP redirect code to use on the response. Not required if one of the siblings is present."', args=[d.arg(name='httpRedirectCode', type=d.T.string)]),
            withHttpRedirectCode(httpRedirectCode): { redirect+: { httpRedirectCode: httpRedirectCode } },
            '#withKeyPrefixEquals':: d.fn(help='"The host name to use in the redirect request."', args=[d.arg(name='keyPrefixEquals', type=d.T.string)]),
            withKeyPrefixEquals(keyPrefixEquals): { redirect+: { keyPrefixEquals: keyPrefixEquals } },
            '#withProtocol':: d.fn(help='"Protocol to use when redirecting requests. The default is the protocol that is used in the original request."', args=[d.arg(name='protocol', type=d.T.string)]),
            withProtocol(protocol): { redirect+: { protocol: protocol } },
            '#withReplaceKeyPrefixWith':: d.fn(help='"The object key prefix to use in the redirect request. For example, to redirect requests for all pages with prefix docs/ (objects in the docs/ folder) to documents/, you can set a condition block with KeyPrefixEquals set to docs/ and in the Redirect set ReplaceKeyPrefixWith to /documents. Not required if one of the siblings is present. Can be present only if ReplaceKeyWith is not provided."', args=[d.arg(name='replaceKeyPrefixWith', type=d.T.string)]),
            withReplaceKeyPrefixWith(replaceKeyPrefixWith): { redirect+: { replaceKeyPrefixWith: replaceKeyPrefixWith } },
            '#withReplaceKeyWith':: d.fn(help='"The specific object key to use in the redirect request. For example, redirect request to error.html. Not required if one of the siblings is present. Can be present only if ReplaceKeyPrefixWith is not provided."', args=[d.arg(name='replaceKeyWith', type=d.T.string)]),
            withReplaceKeyWith(replaceKeyWith): { redirect+: { replaceKeyWith: replaceKeyWith } },
          },
        },
        '#withRoutingRules':: d.fn(help='"Rules that define when a redirect is applied and the redirect behavior."', args=[d.arg(name='routingRules', type=d.T.array)]),
        withRoutingRules(routingRules): { spec+: { forProvider+: { websiteConfiguration+: { routingRules: if std.isArray(v=routingRules) then routingRules else [routingRules] } } } },
        '#withRoutingRulesMixin':: d.fn(help='"Rules that define when a redirect is applied and the redirect behavior."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='routingRules', type=d.T.array)]),
        withRoutingRulesMixin(routingRules): { spec+: { forProvider+: { websiteConfiguration+: { routingRules+: if std.isArray(v=routingRules) then routingRules else [routingRules] } } } },
      },
      '#withAcl':: d.fn(help='"The canned ACL to apply to the bucket. Note that either canned ACL or specific access permissions are required. If neither (or both) are provided, the creation of the bucket will fail."', args=[d.arg(name='acl', type=d.T.string)]),
      withAcl(acl): { spec+: { forProvider+: { acl: acl } } },
      '#withGrantFullControl':: d.fn(help='"Allows grantee the read, write, read ACP, and write ACP permissions on the bucket."', args=[d.arg(name='grantFullControl', type=d.T.string)]),
      withGrantFullControl(grantFullControl): { spec+: { forProvider+: { grantFullControl: grantFullControl } } },
      '#withGrantRead':: d.fn(help='"Allows grantee to list the objects in the bucket."', args=[d.arg(name='grantRead', type=d.T.string)]),
      withGrantRead(grantRead): { spec+: { forProvider+: { grantRead: grantRead } } },
      '#withGrantReadAcp':: d.fn(help='"Allows grantee to read the bucket ACL."', args=[d.arg(name='grantReadAcp', type=d.T.string)]),
      withGrantReadAcp(grantReadAcp): { spec+: { forProvider+: { grantReadAcp: grantReadAcp } } },
      '#withGrantWrite':: d.fn(help='"Allows grantee to create, overwrite, and delete any object in the bucket."', args=[d.arg(name='grantWrite', type=d.T.string)]),
      withGrantWrite(grantWrite): { spec+: { forProvider+: { grantWrite: grantWrite } } },
      '#withGrantWriteAcp':: d.fn(help='"Allows grantee to write the ACL for the applicable bucket."', args=[d.arg(name='grantWriteAcp', type=d.T.string)]),
      withGrantWriteAcp(grantWriteAcp): { spec+: { forProvider+: { grantWriteAcp: grantWriteAcp } } },
      '#withLocationConstraint':: d.fn(help='"LocationConstraint specifies the Region where the bucket will be created. It is a required field."', args=[d.arg(name='locationConstraint', type=d.T.string)]),
      withLocationConstraint(locationConstraint): { spec+: { forProvider+: { locationConstraint: locationConstraint } } },
      '#withObjectLockEnabledForBucket':: d.fn(help='"Specifies whether you want S3 Object Lock to be enabled for the new bucket."', args=[d.arg(name='objectLockEnabledForBucket', type=d.T.boolean)]),
      withObjectLockEnabledForBucket(objectLockEnabledForBucket): { spec+: { forProvider+: { objectLockEnabledForBucket: objectLockEnabledForBucket } } },
    },
    '#providerConfigRef':: d.obj(help='"ProviderConfigReference specifies how the provider that will be used to create, observe, update, and delete this managed resource should be configured."'),
    providerConfigRef: {
      '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { providerConfigRef+: { name: name } } },
    },
    '#providerRef':: d.obj(help='"ProviderReference specifies the provider that will be used to create, observe, update, and delete this managed resource. Deprecated: Please use ProviderConfigReference, i.e. `providerConfigRef`"'),
    providerRef: {
      '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { providerRef+: { name: name } } },
    },
    '#withDeletionPolicy':: d.fn(help='"DeletionPolicy specifies what will happen to the underlying external when this managed resource is deleted - either \\"Delete\\" or \\"Orphan\\" the external resource."', args=[d.arg(name='deletionPolicy', type=d.T.string)]),
    withDeletionPolicy(deletionPolicy): { spec+: { deletionPolicy: deletionPolicy } },
    '#writeConnectionSecretToRef':: d.obj(help='"WriteConnectionSecretToReference specifies the namespace and name of a Secret to which any connection details for this managed resource should be written. Connection details frequently include the endpoint, username, and password required to connect to the managed resource."'),
    writeConnectionSecretToRef: {
      '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { writeConnectionSecretToRef+: { name: name } } },
      '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { spec+: { writeConnectionSecretToRef+: { namespace: namespace } } },
    },
  },
  '#mixin': 'ignore',
  mixin: self,
}
