{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='taskDefinition', url='', help='"TaskDefinition is the Schema for the TaskDefinitions API"'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of TaskDefinition', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'ecs.aws.crossplane.io/v1alpha1',
    kind: 'TaskDefinition',
  } + self.metadata.withName(name=name) + self.metadata.withAnnotations(annotations={
    'tanka.dev/namespaced': 'false',
  }),
  '#spec':: d.obj(help='"TaskDefinitionSpec defines the desired state of TaskDefinition"'),
  spec: {
    '#forProvider':: d.obj(help='"TaskDefinitionParameters defines the desired state of TaskDefinition"'),
    forProvider: {
      '#containerDefinitions':: d.obj(help='"A list of container definitions in JSON format that describe the different containers that make up your task."'),
      containerDefinitions: {
        '#dependsOn':: d.obj(help=''),
        dependsOn: {
          '#withCondition':: d.fn(help='', args=[d.arg(name='condition', type=d.T.string)]),
          withCondition(condition): { condition: condition },
          '#withContainerName':: d.fn(help='', args=[d.arg(name='containerName', type=d.T.string)]),
          withContainerName(containerName): { containerName: containerName },
        },
        '#environment':: d.obj(help=''),
        environment: {
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withValue':: d.fn(help='', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#environmentFiles':: d.obj(help=''),
        environmentFiles: {
          '#withType_':: d.fn(help='', args=[d.arg(name='type_', type=d.T.string)]),
          withType_(type_): { type_: type_ },
          '#withValue':: d.fn(help='', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#extraHosts':: d.obj(help=''),
        extraHosts: {
          '#withHostname':: d.fn(help='', args=[d.arg(name='hostname', type=d.T.string)]),
          withHostname(hostname): { hostname: hostname },
          '#withIpAddress':: d.fn(help='', args=[d.arg(name='ipAddress', type=d.T.string)]),
          withIpAddress(ipAddress): { ipAddress: ipAddress },
        },
        '#firelensConfiguration':: d.obj(help='"The FireLens configuration for the container. This is used to specify and configure a log router for container logs. For more information, see Custom Log Routing (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_firelens.html) in the Amazon Elastic Container Service Developer Guide."'),
        firelensConfiguration: {
          '#withOptions':: d.fn(help='', args=[d.arg(name='options', type=d.T.object)]),
          withOptions(options): { firelensConfiguration+: { options: options } },
          '#withOptionsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='options', type=d.T.object)]),
          withOptionsMixin(options): { firelensConfiguration+: { options+: options } },
          '#withType_':: d.fn(help='', args=[d.arg(name='type_', type=d.T.string)]),
          withType_(type_): { firelensConfiguration+: { type_: type_ } },
        },
        '#healthCheck':: d.obj(help="\"An object representing a container health check. Health check parameters that are specified in a container definition override any Docker health checks that exist in the container image (such as those specified in a parent image or from the image's Dockerfile). \\n You can view the health status of both individual containers and a task with the DescribeTasks API operation or when viewing the task details in the console. \\n The following describes the possible healthStatus values for a container: \\n * HEALTHY-The container health check has passed successfully. \\n * UNHEALTHY-The container health check has failed. \\n * UNKNOWN-The container health check is being evaluated or there is no container health check defined. \\n The following describes the possible healthStatus values for a task. The container health check status of nonessential containers do not have an effect on the health status of a task. \\n * HEALTHY-All essential containers within the task have passed their health checks. \\n * UNHEALTHY-One or more essential containers have failed their health check. \\n * UNKNOWN-The essential containers within the task are still having their health checks evaluated or there are no container health checks defined. \\n If a task is run manually, and not as part of a service, the task will continue its lifecycle regardless of its health status. For tasks that are part of a service, if the task reports as unhealthy then the task will be stopped and the service scheduler will replace it. \\n The following are notes about container health check support: \\n * Container health checks require version 1.17.0 or greater of the Amazon ECS container agent. For more information, see Updating the Amazon ECS Container Agent (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html). \\n * Container health checks are supported for Fargate tasks if you are using platform version 1.1.0 or greater. For more information, see Fargate Platform Versions (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html). \\n * Container health checks are not supported for tasks that are part of a service that is configured to use a Classic Load Balancer.\""),
        healthCheck: {
          '#withCommand':: d.fn(help='', args=[d.arg(name='command', type=d.T.array)]),
          withCommand(command): { healthCheck+: { command: if std.isArray(v=command) then command else [command] } },
          '#withCommandMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='command', type=d.T.array)]),
          withCommandMixin(command): { healthCheck+: { command+: if std.isArray(v=command) then command else [command] } },
          '#withInterval':: d.fn(help='', args=[d.arg(name='interval', type=d.T.integer)]),
          withInterval(interval): { healthCheck+: { interval: interval } },
          '#withRetries':: d.fn(help='', args=[d.arg(name='retries', type=d.T.integer)]),
          withRetries(retries): { healthCheck+: { retries: retries } },
          '#withStartPeriod':: d.fn(help='', args=[d.arg(name='startPeriod', type=d.T.integer)]),
          withStartPeriod(startPeriod): { healthCheck+: { startPeriod: startPeriod } },
          '#withTimeout':: d.fn(help='', args=[d.arg(name='timeout', type=d.T.integer)]),
          withTimeout(timeout): { healthCheck+: { timeout: timeout } },
        },
        '#linuxParameters':: d.obj(help='"Linux-specific options that are applied to the container, such as Linux KernelCapabilities."'),
        linuxParameters: {
          '#capabilities':: d.obj(help='"The Linux capabilities for the container that are added to or dropped from the default configuration provided by Docker. For more information on the default capabilities and the non-default available capabilities, see Runtime privilege and Linux capabilities (https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities) in the Docker run reference. For more detailed information on these Linux capabilities, see the capabilities(7) (http://man7.org/linux/man-pages/man7/capabilities.7.html) Linux manual page."'),
          capabilities: {
            '#withAdd':: d.fn(help='', args=[d.arg(name='add', type=d.T.array)]),
            withAdd(add): { linuxParameters+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } },
            '#withAddMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
            withAddMixin(add): { linuxParameters+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } },
            '#withDrop':: d.fn(help='', args=[d.arg(name='drop', type=d.T.array)]),
            withDrop(drop): { linuxParameters+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } },
            '#withDropMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
            withDropMixin(drop): { linuxParameters+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } },
          },
          '#devices':: d.obj(help=''),
          devices: {
            '#withContainerPath':: d.fn(help='', args=[d.arg(name='containerPath', type=d.T.string)]),
            withContainerPath(containerPath): { containerPath: containerPath },
            '#withHostPath':: d.fn(help='', args=[d.arg(name='hostPath', type=d.T.string)]),
            withHostPath(hostPath): { hostPath: hostPath },
            '#withPermissions':: d.fn(help='', args=[d.arg(name='permissions', type=d.T.array)]),
            withPermissions(permissions): { permissions: if std.isArray(v=permissions) then permissions else [permissions] },
            '#withPermissionsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='permissions', type=d.T.array)]),
            withPermissionsMixin(permissions): { permissions+: if std.isArray(v=permissions) then permissions else [permissions] },
          },
          '#tmpfs':: d.obj(help=''),
          tmpfs: {
            '#withContainerPath':: d.fn(help='', args=[d.arg(name='containerPath', type=d.T.string)]),
            withContainerPath(containerPath): { containerPath: containerPath },
            '#withMountOptions':: d.fn(help='', args=[d.arg(name='mountOptions', type=d.T.array)]),
            withMountOptions(mountOptions): { mountOptions: if std.isArray(v=mountOptions) then mountOptions else [mountOptions] },
            '#withMountOptionsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='mountOptions', type=d.T.array)]),
            withMountOptionsMixin(mountOptions): { mountOptions+: if std.isArray(v=mountOptions) then mountOptions else [mountOptions] },
            '#withSize':: d.fn(help='', args=[d.arg(name='size', type=d.T.integer)]),
            withSize(size): { size: size },
          },
          '#withDevices':: d.fn(help='', args=[d.arg(name='devices', type=d.T.array)]),
          withDevices(devices): { linuxParameters+: { devices: if std.isArray(v=devices) then devices else [devices] } },
          '#withDevicesMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='devices', type=d.T.array)]),
          withDevicesMixin(devices): { linuxParameters+: { devices+: if std.isArray(v=devices) then devices else [devices] } },
          '#withInitProcessEnabled':: d.fn(help='', args=[d.arg(name='initProcessEnabled', type=d.T.boolean)]),
          withInitProcessEnabled(initProcessEnabled): { linuxParameters+: { initProcessEnabled: initProcessEnabled } },
          '#withMaxSwap':: d.fn(help='', args=[d.arg(name='maxSwap', type=d.T.integer)]),
          withMaxSwap(maxSwap): { linuxParameters+: { maxSwap: maxSwap } },
          '#withSharedMemorySize':: d.fn(help='', args=[d.arg(name='sharedMemorySize', type=d.T.integer)]),
          withSharedMemorySize(sharedMemorySize): { linuxParameters+: { sharedMemorySize: sharedMemorySize } },
          '#withSwappiness':: d.fn(help='', args=[d.arg(name='swappiness', type=d.T.integer)]),
          withSwappiness(swappiness): { linuxParameters+: { swappiness: swappiness } },
          '#withTmpfs':: d.fn(help='', args=[d.arg(name='tmpfs', type=d.T.array)]),
          withTmpfs(tmpfs): { linuxParameters+: { tmpfs: if std.isArray(v=tmpfs) then tmpfs else [tmpfs] } },
          '#withTmpfsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tmpfs', type=d.T.array)]),
          withTmpfsMixin(tmpfs): { linuxParameters+: { tmpfs+: if std.isArray(v=tmpfs) then tmpfs else [tmpfs] } },
        },
        '#logConfiguration':: d.obj(help='"The log configuration for the container. This parameter maps to LogConfig in the Create a container (https://docs.docker.com/engine/api/v1.35/#operation/ContainerCreate) section of the Docker Remote API (https://docs.docker.com/engine/api/v1.35/) and the --log-driver option to docker run (https://docs.docker.com/engine/reference/commandline/run/). \\n By default, containers use the same logging driver that the Docker daemon uses; however the container may use a different logging driver than the Docker daemon by specifying a log driver configuration in the container definition. For more information on the options for different supported log drivers, see Configure logging drivers (https://docs.docker.com/engine/admin/logging/overview/) in the Docker documentation. \\n The following should be noted when specifying a log configuration for your containers: \\n * Amazon ECS currently supports a subset of the logging drivers available to the Docker daemon (shown in the valid values below). Additional log drivers may be available in future releases of the Amazon ECS container agent. \\n * This parameter requires version 1.18 of the Docker Remote API or greater on your container instance. \\n * For tasks hosted on Amazon EC2 instances, the Amazon ECS container agent must register the available logging drivers with the ECS_AVAILABLE_LOGGING_DRIVERS environment variable before containers placed on that instance can use these log configuration options. For more information, see Amazon ECS container agent configuration (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the Amazon Elastic Container Service Developer Guide. \\n * For tasks on Fargate, because you do not have access to the underlying infrastructure your tasks are hosted on, any additional software needed will have to be installed outside of the task. For example, the Fluentd output aggregators or a remote host running Logstash to send Gelf logs to."'),
        logConfiguration: {
          '#secretOptions':: d.obj(help=''),
          secretOptions: {
            '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withValueFrom':: d.fn(help='', args=[d.arg(name='valueFrom', type=d.T.string)]),
            withValueFrom(valueFrom): { valueFrom: valueFrom },
          },
          '#withLogDriver':: d.fn(help='', args=[d.arg(name='logDriver', type=d.T.string)]),
          withLogDriver(logDriver): { logConfiguration+: { logDriver: logDriver } },
          '#withOptions':: d.fn(help='', args=[d.arg(name='options', type=d.T.object)]),
          withOptions(options): { logConfiguration+: { options: options } },
          '#withOptionsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='options', type=d.T.object)]),
          withOptionsMixin(options): { logConfiguration+: { options+: options } },
          '#withSecretOptions':: d.fn(help='', args=[d.arg(name='secretOptions', type=d.T.array)]),
          withSecretOptions(secretOptions): { logConfiguration+: { secretOptions: if std.isArray(v=secretOptions) then secretOptions else [secretOptions] } },
          '#withSecretOptionsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='secretOptions', type=d.T.array)]),
          withSecretOptionsMixin(secretOptions): { logConfiguration+: { secretOptions+: if std.isArray(v=secretOptions) then secretOptions else [secretOptions] } },
        },
        '#mountPoints':: d.obj(help=''),
        mountPoints: {
          '#withContainerPath':: d.fn(help='', args=[d.arg(name='containerPath', type=d.T.string)]),
          withContainerPath(containerPath): { containerPath: containerPath },
          '#withReadOnly':: d.fn(help='', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { readOnly: readOnly },
          '#withSourceVolume':: d.fn(help='', args=[d.arg(name='sourceVolume', type=d.T.string)]),
          withSourceVolume(sourceVolume): { sourceVolume: sourceVolume },
        },
        '#portMappings':: d.obj(help=''),
        portMappings: {
          '#withContainerPort':: d.fn(help='', args=[d.arg(name='containerPort', type=d.T.integer)]),
          withContainerPort(containerPort): { containerPort: containerPort },
          '#withHostPort':: d.fn(help='', args=[d.arg(name='hostPort', type=d.T.integer)]),
          withHostPort(hostPort): { hostPort: hostPort },
          '#withProtocol':: d.fn(help='', args=[d.arg(name='protocol', type=d.T.string)]),
          withProtocol(protocol): { protocol: protocol },
        },
        '#repositoryCredentials':: d.obj(help='"The repository credentials for private registry authentication."'),
        repositoryCredentials: {
          '#withCredentialsParameter':: d.fn(help='', args=[d.arg(name='credentialsParameter', type=d.T.string)]),
          withCredentialsParameter(credentialsParameter): { repositoryCredentials+: { credentialsParameter: credentialsParameter } },
        },
        '#resourceRequirements':: d.obj(help=''),
        resourceRequirements: {
          '#withType_':: d.fn(help='', args=[d.arg(name='type_', type=d.T.string)]),
          withType_(type_): { type_: type_ },
          '#withValue':: d.fn(help='', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#secrets':: d.obj(help=''),
        secrets: {
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withValueFrom':: d.fn(help='', args=[d.arg(name='valueFrom', type=d.T.string)]),
          withValueFrom(valueFrom): { valueFrom: valueFrom },
        },
        '#systemControls':: d.obj(help=''),
        systemControls: {
          '#withNamespace':: d.fn(help='', args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { namespace: namespace },
          '#withValue':: d.fn(help='', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#ulimits':: d.obj(help=''),
        ulimits: {
          '#withHardLimit':: d.fn(help='', args=[d.arg(name='hardLimit', type=d.T.integer)]),
          withHardLimit(hardLimit): { hardLimit: hardLimit },
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withSoftLimit':: d.fn(help='', args=[d.arg(name='softLimit', type=d.T.integer)]),
          withSoftLimit(softLimit): { softLimit: softLimit },
        },
        '#volumesFrom':: d.obj(help=''),
        volumesFrom: {
          '#withReadOnly':: d.fn(help='', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { readOnly: readOnly },
          '#withSourceContainer':: d.fn(help='', args=[d.arg(name='sourceContainer', type=d.T.string)]),
          withSourceContainer(sourceContainer): { sourceContainer: sourceContainer },
        },
        '#withCommand':: d.fn(help='', args=[d.arg(name='command', type=d.T.array)]),
        withCommand(command): { command: if std.isArray(v=command) then command else [command] },
        '#withCommandMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='command', type=d.T.array)]),
        withCommandMixin(command): { command+: if std.isArray(v=command) then command else [command] },
        '#withCpu':: d.fn(help='', args=[d.arg(name='cpu', type=d.T.integer)]),
        withCpu(cpu): { cpu: cpu },
        '#withDependsOn':: d.fn(help='', args=[d.arg(name='dependsOn', type=d.T.array)]),
        withDependsOn(dependsOn): { dependsOn: if std.isArray(v=dependsOn) then dependsOn else [dependsOn] },
        '#withDependsOnMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='dependsOn', type=d.T.array)]),
        withDependsOnMixin(dependsOn): { dependsOn+: if std.isArray(v=dependsOn) then dependsOn else [dependsOn] },
        '#withDisableNetworking':: d.fn(help='', args=[d.arg(name='disableNetworking', type=d.T.boolean)]),
        withDisableNetworking(disableNetworking): { disableNetworking: disableNetworking },
        '#withDnsSearchDomains':: d.fn(help='', args=[d.arg(name='dnsSearchDomains', type=d.T.array)]),
        withDnsSearchDomains(dnsSearchDomains): { dnsSearchDomains: if std.isArray(v=dnsSearchDomains) then dnsSearchDomains else [dnsSearchDomains] },
        '#withDnsSearchDomainsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='dnsSearchDomains', type=d.T.array)]),
        withDnsSearchDomainsMixin(dnsSearchDomains): { dnsSearchDomains+: if std.isArray(v=dnsSearchDomains) then dnsSearchDomains else [dnsSearchDomains] },
        '#withDnsServers':: d.fn(help='', args=[d.arg(name='dnsServers', type=d.T.array)]),
        withDnsServers(dnsServers): { dnsServers: if std.isArray(v=dnsServers) then dnsServers else [dnsServers] },
        '#withDnsServersMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='dnsServers', type=d.T.array)]),
        withDnsServersMixin(dnsServers): { dnsServers+: if std.isArray(v=dnsServers) then dnsServers else [dnsServers] },
        '#withDockerLabels':: d.fn(help='', args=[d.arg(name='dockerLabels', type=d.T.object)]),
        withDockerLabels(dockerLabels): { dockerLabels: dockerLabels },
        '#withDockerLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='dockerLabels', type=d.T.object)]),
        withDockerLabelsMixin(dockerLabels): { dockerLabels+: dockerLabels },
        '#withDockerSecurityOptions':: d.fn(help='', args=[d.arg(name='dockerSecurityOptions', type=d.T.array)]),
        withDockerSecurityOptions(dockerSecurityOptions): { dockerSecurityOptions: if std.isArray(v=dockerSecurityOptions) then dockerSecurityOptions else [dockerSecurityOptions] },
        '#withDockerSecurityOptionsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='dockerSecurityOptions', type=d.T.array)]),
        withDockerSecurityOptionsMixin(dockerSecurityOptions): { dockerSecurityOptions+: if std.isArray(v=dockerSecurityOptions) then dockerSecurityOptions else [dockerSecurityOptions] },
        '#withEntryPoint':: d.fn(help='', args=[d.arg(name='entryPoint', type=d.T.array)]),
        withEntryPoint(entryPoint): { entryPoint: if std.isArray(v=entryPoint) then entryPoint else [entryPoint] },
        '#withEntryPointMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='entryPoint', type=d.T.array)]),
        withEntryPointMixin(entryPoint): { entryPoint+: if std.isArray(v=entryPoint) then entryPoint else [entryPoint] },
        '#withEnvironment':: d.fn(help='', args=[d.arg(name='environment', type=d.T.array)]),
        withEnvironment(environment): { environment: if std.isArray(v=environment) then environment else [environment] },
        '#withEnvironmentFiles':: d.fn(help='', args=[d.arg(name='environmentFiles', type=d.T.array)]),
        withEnvironmentFiles(environmentFiles): { environmentFiles: if std.isArray(v=environmentFiles) then environmentFiles else [environmentFiles] },
        '#withEnvironmentFilesMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='environmentFiles', type=d.T.array)]),
        withEnvironmentFilesMixin(environmentFiles): { environmentFiles+: if std.isArray(v=environmentFiles) then environmentFiles else [environmentFiles] },
        '#withEnvironmentMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='environment', type=d.T.array)]),
        withEnvironmentMixin(environment): { environment+: if std.isArray(v=environment) then environment else [environment] },
        '#withEssential':: d.fn(help='', args=[d.arg(name='essential', type=d.T.boolean)]),
        withEssential(essential): { essential: essential },
        '#withExtraHosts':: d.fn(help='', args=[d.arg(name='extraHosts', type=d.T.array)]),
        withExtraHosts(extraHosts): { extraHosts: if std.isArray(v=extraHosts) then extraHosts else [extraHosts] },
        '#withExtraHostsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='extraHosts', type=d.T.array)]),
        withExtraHostsMixin(extraHosts): { extraHosts+: if std.isArray(v=extraHosts) then extraHosts else [extraHosts] },
        '#withHostname':: d.fn(help='', args=[d.arg(name='hostname', type=d.T.string)]),
        withHostname(hostname): { hostname: hostname },
        '#withImage':: d.fn(help='', args=[d.arg(name='image', type=d.T.string)]),
        withImage(image): { image: image },
        '#withInteractive':: d.fn(help='', args=[d.arg(name='interactive', type=d.T.boolean)]),
        withInteractive(interactive): { interactive: interactive },
        '#withLinks':: d.fn(help='', args=[d.arg(name='links', type=d.T.array)]),
        withLinks(links): { links: if std.isArray(v=links) then links else [links] },
        '#withLinksMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='links', type=d.T.array)]),
        withLinksMixin(links): { links+: if std.isArray(v=links) then links else [links] },
        '#withMemory':: d.fn(help='', args=[d.arg(name='memory', type=d.T.integer)]),
        withMemory(memory): { memory: memory },
        '#withMemoryReservation':: d.fn(help='', args=[d.arg(name='memoryReservation', type=d.T.integer)]),
        withMemoryReservation(memoryReservation): { memoryReservation: memoryReservation },
        '#withMountPoints':: d.fn(help='', args=[d.arg(name='mountPoints', type=d.T.array)]),
        withMountPoints(mountPoints): { mountPoints: if std.isArray(v=mountPoints) then mountPoints else [mountPoints] },
        '#withMountPointsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='mountPoints', type=d.T.array)]),
        withMountPointsMixin(mountPoints): { mountPoints+: if std.isArray(v=mountPoints) then mountPoints else [mountPoints] },
        '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withPortMappings':: d.fn(help='', args=[d.arg(name='portMappings', type=d.T.array)]),
        withPortMappings(portMappings): { portMappings: if std.isArray(v=portMappings) then portMappings else [portMappings] },
        '#withPortMappingsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='portMappings', type=d.T.array)]),
        withPortMappingsMixin(portMappings): { portMappings+: if std.isArray(v=portMappings) then portMappings else [portMappings] },
        '#withPrivileged':: d.fn(help='', args=[d.arg(name='privileged', type=d.T.boolean)]),
        withPrivileged(privileged): { privileged: privileged },
        '#withPseudoTerminal':: d.fn(help='', args=[d.arg(name='pseudoTerminal', type=d.T.boolean)]),
        withPseudoTerminal(pseudoTerminal): { pseudoTerminal: pseudoTerminal },
        '#withReadonlyRootFilesystem':: d.fn(help='', args=[d.arg(name='readonlyRootFilesystem', type=d.T.boolean)]),
        withReadonlyRootFilesystem(readonlyRootFilesystem): { readonlyRootFilesystem: readonlyRootFilesystem },
        '#withResourceRequirements':: d.fn(help='', args=[d.arg(name='resourceRequirements', type=d.T.array)]),
        withResourceRequirements(resourceRequirements): { resourceRequirements: if std.isArray(v=resourceRequirements) then resourceRequirements else [resourceRequirements] },
        '#withResourceRequirementsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='resourceRequirements', type=d.T.array)]),
        withResourceRequirementsMixin(resourceRequirements): { resourceRequirements+: if std.isArray(v=resourceRequirements) then resourceRequirements else [resourceRequirements] },
        '#withSecrets':: d.fn(help='', args=[d.arg(name='secrets', type=d.T.array)]),
        withSecrets(secrets): { secrets: if std.isArray(v=secrets) then secrets else [secrets] },
        '#withSecretsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='secrets', type=d.T.array)]),
        withSecretsMixin(secrets): { secrets+: if std.isArray(v=secrets) then secrets else [secrets] },
        '#withStartTimeout':: d.fn(help='', args=[d.arg(name='startTimeout', type=d.T.integer)]),
        withStartTimeout(startTimeout): { startTimeout: startTimeout },
        '#withStopTimeout':: d.fn(help='', args=[d.arg(name='stopTimeout', type=d.T.integer)]),
        withStopTimeout(stopTimeout): { stopTimeout: stopTimeout },
        '#withSystemControls':: d.fn(help='', args=[d.arg(name='systemControls', type=d.T.array)]),
        withSystemControls(systemControls): { systemControls: if std.isArray(v=systemControls) then systemControls else [systemControls] },
        '#withSystemControlsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='systemControls', type=d.T.array)]),
        withSystemControlsMixin(systemControls): { systemControls+: if std.isArray(v=systemControls) then systemControls else [systemControls] },
        '#withUlimits':: d.fn(help='', args=[d.arg(name='ulimits', type=d.T.array)]),
        withUlimits(ulimits): { ulimits: if std.isArray(v=ulimits) then ulimits else [ulimits] },
        '#withUlimitsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ulimits', type=d.T.array)]),
        withUlimitsMixin(ulimits): { ulimits+: if std.isArray(v=ulimits) then ulimits else [ulimits] },
        '#withUser':: d.fn(help='', args=[d.arg(name='user', type=d.T.string)]),
        withUser(user): { user: user },
        '#withVolumesFrom':: d.fn(help='', args=[d.arg(name='volumesFrom', type=d.T.array)]),
        withVolumesFrom(volumesFrom): { volumesFrom: if std.isArray(v=volumesFrom) then volumesFrom else [volumesFrom] },
        '#withVolumesFromMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumesFrom', type=d.T.array)]),
        withVolumesFromMixin(volumesFrom): { volumesFrom+: if std.isArray(v=volumesFrom) then volumesFrom else [volumesFrom] },
        '#withWorkingDirectory':: d.fn(help='', args=[d.arg(name='workingDirectory', type=d.T.string)]),
        withWorkingDirectory(workingDirectory): { workingDirectory: workingDirectory },
      },
      '#ephemeralStorage':: d.obj(help='"The amount of ephemeral storage to allocate for the task. This parameter is used to expand the total amount of ephemeral storage available, beyond the default amount, for tasks hosted on Fargate. For more information, see Fargate task storage (https://docs.aws.amazon.com/AmazonECS/latest/userguide/using_data_volumes.html) in the Amazon ECS User Guide for Fargate. \\n This parameter is only supported for tasks hosted on Fargate using the following platform versions: \\n * Linux platform version 1.4.0 or later. \\n * Windows platform version 1.0.0 or later."'),
      ephemeralStorage: {
        '#withSizeInGiB':: d.fn(help='', args=[d.arg(name='sizeInGiB', type=d.T.integer)]),
        withSizeInGiB(sizeInGiB): { spec+: { forProvider+: { ephemeralStorage+: { sizeInGiB: sizeInGiB } } } },
      },
      '#executionRoleARNRef':: d.obj(help='"A Reference to a named object."'),
      executionRoleARNRef: {
        '#policy':: d.obj(help='"Policies for referencing."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { forProvider+: { executionRoleARNRef+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { forProvider+: { executionRoleARNRef+: { policy+: { resolve: resolve } } } } },
        },
        '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { forProvider+: { executionRoleARNRef+: { name: name } } } },
      },
      '#executionRoleARNSelector':: d.obj(help='"A Selector selects an object."'),
      executionRoleARNSelector: {
        '#policy':: d.obj(help='"Policies for selection."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { forProvider+: { executionRoleARNSelector+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { forProvider+: { executionRoleARNSelector+: { policy+: { resolve: resolve } } } } },
        },
        '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
        withMatchControllerRef(matchControllerRef): { spec+: { forProvider+: { executionRoleARNSelector+: { matchControllerRef: matchControllerRef } } } },
        '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabels(matchLabels): { spec+: { forProvider+: { executionRoleARNSelector+: { matchLabels: matchLabels } } } },
        '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabelsMixin(matchLabels): { spec+: { forProvider+: { executionRoleARNSelector+: { matchLabels+: matchLabels } } } },
      },
      '#inferenceAccelerators':: d.obj(help='"The Elastic Inference accelerators to use for the containers in the task."'),
      inferenceAccelerators: {
        '#withDeviceName':: d.fn(help='', args=[d.arg(name='deviceName', type=d.T.string)]),
        withDeviceName(deviceName): { deviceName: deviceName },
        '#withDeviceType':: d.fn(help='', args=[d.arg(name='deviceType', type=d.T.string)]),
        withDeviceType(deviceType): { deviceType: deviceType },
      },
      '#placementConstraints':: d.obj(help='"An array of placement constraint objects to use for the task. You can specify a maximum of 10 constraints per task (this limit includes constraints in the task definition and those specified at runtime)."'),
      placementConstraints: {
        '#withExpression':: d.fn(help='', args=[d.arg(name='expression', type=d.T.string)]),
        withExpression(expression): { expression: expression },
        '#withType_':: d.fn(help='', args=[d.arg(name='type_', type=d.T.string)]),
        withType_(type_): { type_: type_ },
      },
      '#proxyConfiguration':: d.obj(help='"The configuration details for the App Mesh proxy. \\n For tasks hosted on Amazon EC2 instances, the container instances require at least version 1.26.0 of the container agent and at least version 1.26.0-1 of the ecs-init package to enable a proxy configuration. If your container instances are launched from the Amazon ECS-optimized AMI version 20190301 or later, then they contain the required versions of the container agent and ecs-init. For more information, see Amazon ECS-optimized AMI versions (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-ami-versions.html) in the Amazon Elastic Container Service Developer Guide."'),
      proxyConfiguration: {
        '#properties':: d.obj(help=''),
        properties: {
          '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withValue':: d.fn(help='', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#withContainerName':: d.fn(help='', args=[d.arg(name='containerName', type=d.T.string)]),
        withContainerName(containerName): { spec+: { forProvider+: { proxyConfiguration+: { containerName: containerName } } } },
        '#withProperties':: d.fn(help='', args=[d.arg(name='properties', type=d.T.array)]),
        withProperties(properties): { spec+: { forProvider+: { proxyConfiguration+: { properties: if std.isArray(v=properties) then properties else [properties] } } } },
        '#withPropertiesMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='properties', type=d.T.array)]),
        withPropertiesMixin(properties): { spec+: { forProvider+: { proxyConfiguration+: { properties+: if std.isArray(v=properties) then properties else [properties] } } } },
        '#withType_':: d.fn(help='', args=[d.arg(name='type_', type=d.T.string)]),
        withType_(type_): { spec+: { forProvider+: { proxyConfiguration+: { type_: type_ } } } },
      },
      '#runtimePlatform':: d.obj(help='"The operating system that your tasks definitions run on. A platform family is specified only for tasks using the Fargate launch type. \\n When you specify a task definition in a service, this value must match the runtimePlatform value of the service."'),
      runtimePlatform: {
        '#withCpuArchitecture':: d.fn(help='', args=[d.arg(name='cpuArchitecture', type=d.T.string)]),
        withCpuArchitecture(cpuArchitecture): { spec+: { forProvider+: { runtimePlatform+: { cpuArchitecture: cpuArchitecture } } } },
        '#withOperatingSystemFamily':: d.fn(help='', args=[d.arg(name='operatingSystemFamily', type=d.T.string)]),
        withOperatingSystemFamily(operatingSystemFamily): { spec+: { forProvider+: { runtimePlatform+: { operatingSystemFamily: operatingSystemFamily } } } },
      },
      '#tags':: d.obj(help='"The metadata that you apply to the task definition to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. \\n The following basic restrictions apply to tags: \\n * Maximum number of tags per resource - 50 \\n * For each resource, each tag key must be unique, and each tag key can have only one value. \\n * Maximum key length - 128 Unicode characters in UTF-8 \\n * Maximum value length - 256 Unicode characters in UTF-8 \\n * If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @. \\n * Tag keys and values are case-sensitive. \\n * Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit."'),
      tags: {
        '#withKey':: d.fn(help='', args=[d.arg(name='key', type=d.T.string)]),
        withKey(key): { key: key },
        '#withValue':: d.fn(help='', args=[d.arg(name='value', type=d.T.string)]),
        withValue(value): { value: value },
      },
      '#taskRoleARNRef':: d.obj(help='"A Reference to a named object."'),
      taskRoleARNRef: {
        '#policy':: d.obj(help='"Policies for referencing."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { forProvider+: { taskRoleARNRef+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { forProvider+: { taskRoleARNRef+: { policy+: { resolve: resolve } } } } },
        },
        '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { forProvider+: { taskRoleARNRef+: { name: name } } } },
      },
      '#taskRoleARNSelector':: d.obj(help='"A Selector selects an object."'),
      taskRoleARNSelector: {
        '#policy':: d.obj(help='"Policies for selection."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { forProvider+: { taskRoleARNSelector+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { forProvider+: { taskRoleARNSelector+: { policy+: { resolve: resolve } } } } },
        },
        '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
        withMatchControllerRef(matchControllerRef): { spec+: { forProvider+: { taskRoleARNSelector+: { matchControllerRef: matchControllerRef } } } },
        '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabels(matchLabels): { spec+: { forProvider+: { taskRoleARNSelector+: { matchLabels: matchLabels } } } },
        '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabelsMixin(matchLabels): { spec+: { forProvider+: { taskRoleARNSelector+: { matchLabels+: matchLabels } } } },
      },
      '#volumes':: d.obj(help=''),
      volumes: {
        '#dockerVolumeConfiguration':: d.obj(help='"This parameter is specified when you are using Docker volumes. Docker volumes are only supported when you are using the EC2 launch type. Windows containers only support the use of the local driver. To use bind mounts, specify a host instead."'),
        dockerVolumeConfiguration: {
          '#withAutoprovision':: d.fn(help='', args=[d.arg(name='autoprovision', type=d.T.boolean)]),
          withAutoprovision(autoprovision): { dockerVolumeConfiguration+: { autoprovision: autoprovision } },
          '#withDriver':: d.fn(help='', args=[d.arg(name='driver', type=d.T.string)]),
          withDriver(driver): { dockerVolumeConfiguration+: { driver: driver } },
          '#withDriverOpts':: d.fn(help='', args=[d.arg(name='driverOpts', type=d.T.object)]),
          withDriverOpts(driverOpts): { dockerVolumeConfiguration+: { driverOpts: driverOpts } },
          '#withDriverOptsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='driverOpts', type=d.T.object)]),
          withDriverOptsMixin(driverOpts): { dockerVolumeConfiguration+: { driverOpts+: driverOpts } },
          '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { dockerVolumeConfiguration+: { labels: labels } },
          '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { dockerVolumeConfiguration+: { labels+: labels } },
          '#withScope':: d.fn(help='', args=[d.arg(name='scope', type=d.T.string)]),
          withScope(scope): { dockerVolumeConfiguration+: { scope: scope } },
        },
        '#efsVolumeConfiguration':: d.obj(help='"This parameter is specified when you are using an Amazon Elastic File System file system for task storage. For more information, see Amazon EFS Volumes (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/efs-volumes.html) in the Amazon Elastic Container Service Developer Guide."'),
        efsVolumeConfiguration: {
          '#authorizationConfig':: d.obj(help='"The authorization configuration details for the Amazon EFS file system."'),
          authorizationConfig: {
            '#accessPointIDRef':: d.obj(help='"A Reference to a named object."'),
            accessPointIDRef: {
              '#policy':: d.obj(help='"Policies for referencing."'),
              policy: {
                '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
                withResolution(resolution): { efsVolumeConfiguration+: { authorizationConfig+: { accessPointIDRef+: { policy+: { resolution: resolution } } } } },
                '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
                withResolve(resolve): { efsVolumeConfiguration+: { authorizationConfig+: { accessPointIDRef+: { policy+: { resolve: resolve } } } } },
              },
              '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { efsVolumeConfiguration+: { authorizationConfig+: { accessPointIDRef+: { name: name } } } },
            },
            '#accessPointIDSelector':: d.obj(help='"A Selector selects an object."'),
            accessPointIDSelector: {
              '#policy':: d.obj(help='"Policies for selection."'),
              policy: {
                '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
                withResolution(resolution): { efsVolumeConfiguration+: { authorizationConfig+: { accessPointIDSelector+: { policy+: { resolution: resolution } } } } },
                '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
                withResolve(resolve): { efsVolumeConfiguration+: { authorizationConfig+: { accessPointIDSelector+: { policy+: { resolve: resolve } } } } },
              },
              '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
              withMatchControllerRef(matchControllerRef): { efsVolumeConfiguration+: { authorizationConfig+: { accessPointIDSelector+: { matchControllerRef: matchControllerRef } } } },
              '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { efsVolumeConfiguration+: { authorizationConfig+: { accessPointIDSelector+: { matchLabels: matchLabels } } } },
              '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { efsVolumeConfiguration+: { authorizationConfig+: { accessPointIDSelector+: { matchLabels+: matchLabels } } } },
            },
            '#withAccessPointID':: d.fn(help='"The Amazon EFS access point ID to use. If an access point is specified, the root directory value specified in the EFSVolumeConfiguration must either be omitted or set to / which will enforce the path set on the EFS access point. If an access point is used, transit encryption must be enabled in the EFSVolumeConfiguration. For more information, see Working with Amazon EFS Access Points (https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html) in the Amazon Elastic File System User Guide."', args=[d.arg(name='accessPointID', type=d.T.string)]),
            withAccessPointID(accessPointID): { efsVolumeConfiguration+: { authorizationConfig+: { accessPointID: accessPointID } } },
            '#withIam':: d.fn(help='"Determines whether to use the Amazon ECS task IAM role defined in a task definition when mounting the Amazon EFS file system. If enabled, transit encryption must be enabled in the EFSVolumeConfiguration. If this parameter is omitted, the default value of DISABLED is used. For more information, see Using Amazon EFS Access Points (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/efs-volumes.html#efs-volume-accesspoints) in the Amazon Elastic Container Service Developer Guide."', args=[d.arg(name='iam', type=d.T.string)]),
            withIam(iam): { efsVolumeConfiguration+: { authorizationConfig+: { iam: iam } } },
          },
          '#fileSystemIDRef':: d.obj(help='"A Reference to a named object."'),
          fileSystemIDRef: {
            '#policy':: d.obj(help='"Policies for referencing."'),
            policy: {
              '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
              withResolution(resolution): { efsVolumeConfiguration+: { fileSystemIDRef+: { policy+: { resolution: resolution } } } },
              '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
              withResolve(resolve): { efsVolumeConfiguration+: { fileSystemIDRef+: { policy+: { resolve: resolve } } } },
            },
            '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { efsVolumeConfiguration+: { fileSystemIDRef+: { name: name } } },
          },
          '#fileSystemIDSelector':: d.obj(help='"A Selector selects an object."'),
          fileSystemIDSelector: {
            '#policy':: d.obj(help='"Policies for selection."'),
            policy: {
              '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
              withResolution(resolution): { efsVolumeConfiguration+: { fileSystemIDSelector+: { policy+: { resolution: resolution } } } },
              '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
              withResolve(resolve): { efsVolumeConfiguration+: { fileSystemIDSelector+: { policy+: { resolve: resolve } } } },
            },
            '#withMatchControllerRef':: d.fn(help='"MatchControllerRef ensures an object with the same controller reference as the selecting object is selected."', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
            withMatchControllerRef(matchControllerRef): { efsVolumeConfiguration+: { fileSystemIDSelector+: { matchControllerRef: matchControllerRef } } },
            '#withMatchLabels':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabels(matchLabels): { efsVolumeConfiguration+: { fileSystemIDSelector+: { matchLabels: matchLabels } } },
            '#withMatchLabelsMixin':: d.fn(help='"MatchLabels ensures an object with matching labels is selected."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabelsMixin(matchLabels): { efsVolumeConfiguration+: { fileSystemIDSelector+: { matchLabels+: matchLabels } } },
          },
          '#withFileSystemID':: d.fn(help='', args=[d.arg(name='fileSystemID', type=d.T.string)]),
          withFileSystemID(fileSystemID): { efsVolumeConfiguration+: { fileSystemID: fileSystemID } },
          '#withRootDirectory':: d.fn(help='', args=[d.arg(name='rootDirectory', type=d.T.string)]),
          withRootDirectory(rootDirectory): { efsVolumeConfiguration+: { rootDirectory: rootDirectory } },
          '#withTransitEncryption':: d.fn(help='', args=[d.arg(name='transitEncryption', type=d.T.string)]),
          withTransitEncryption(transitEncryption): { efsVolumeConfiguration+: { transitEncryption: transitEncryption } },
          '#withTransitEncryptionPort':: d.fn(help='', args=[d.arg(name='transitEncryptionPort', type=d.T.integer)]),
          withTransitEncryptionPort(transitEncryptionPort): { efsVolumeConfiguration+: { transitEncryptionPort: transitEncryptionPort } },
        },
        '#fsxWindowsFileServerVolumeConfiguration':: d.obj(help='"This parameter is specified when you are using Amazon FSx for Windows File Server (https://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html) file system for task storage. \\n For more information and the input format, see Amazon FSx for Windows File Server Volumes (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/wfsx-volumes.html) in the Amazon Elastic Container Service Developer Guide."'),
        fsxWindowsFileServerVolumeConfiguration: {
          '#authorizationConfig':: d.obj(help='"The authorization configuration details for Amazon FSx for Windows File Server file system. See FSxWindowsFileServerVolumeConfiguration (https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_FSxWindowsFileServerVolumeConfiguration.html) in the Amazon Elastic Container Service API Reference. \\n For more information and the input format, see Amazon FSx for Windows File Server Volumes (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/wfsx-volumes.html) in the Amazon Elastic Container Service Developer Guide."'),
          authorizationConfig: {
            '#withCredentialsParameter':: d.fn(help='', args=[d.arg(name='credentialsParameter', type=d.T.string)]),
            withCredentialsParameter(credentialsParameter): { fsxWindowsFileServerVolumeConfiguration+: { authorizationConfig+: { credentialsParameter: credentialsParameter } } },
            '#withDomain':: d.fn(help='', args=[d.arg(name='domain', type=d.T.string)]),
            withDomain(domain): { fsxWindowsFileServerVolumeConfiguration+: { authorizationConfig+: { domain: domain } } },
          },
          '#withFileSystemID':: d.fn(help='', args=[d.arg(name='fileSystemID', type=d.T.string)]),
          withFileSystemID(fileSystemID): { fsxWindowsFileServerVolumeConfiguration+: { fileSystemID: fileSystemID } },
          '#withRootDirectory':: d.fn(help='', args=[d.arg(name='rootDirectory', type=d.T.string)]),
          withRootDirectory(rootDirectory): { fsxWindowsFileServerVolumeConfiguration+: { rootDirectory: rootDirectory } },
        },
        '#host':: d.obj(help='"Details on a container instance bind mount host volume."'),
        host: {
          '#withSourcePath':: d.fn(help='', args=[d.arg(name='sourcePath', type=d.T.string)]),
          withSourcePath(sourcePath): { host+: { sourcePath: sourcePath } },
        },
        '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
      },
      '#withContainerDefinitions':: d.fn(help='"A list of container definitions in JSON format that describe the different containers that make up your task."', args=[d.arg(name='containerDefinitions', type=d.T.array)]),
      withContainerDefinitions(containerDefinitions): { spec+: { forProvider+: { containerDefinitions: if std.isArray(v=containerDefinitions) then containerDefinitions else [containerDefinitions] } } },
      '#withContainerDefinitionsMixin':: d.fn(help='"A list of container definitions in JSON format that describe the different containers that make up your task."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='containerDefinitions', type=d.T.array)]),
      withContainerDefinitionsMixin(containerDefinitions): { spec+: { forProvider+: { containerDefinitions+: if std.isArray(v=containerDefinitions) then containerDefinitions else [containerDefinitions] } } },
      '#withCpu':: d.fn(help='"The number of CPU units used by the task. It can be expressed as an integer using CPU units, for example 1024, or as a string using vCPUs, for example 1 vCPU or 1 vcpu, in a task definition. String values are converted to an integer indicating the CPU units when the task definition is registered. \\n Task-level CPU and memory parameters are ignored for Windows containers. We recommend specifying container-level resources for Windows containers. \\n If you are using the EC2 launch type, this field is optional. Supported values are between 128 CPU units (0.125 vCPUs) and 10240 CPU units (10 vCPUs). \\n If you are using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of supported values for the memory parameter: \\n * 256 (.25 vCPU) - Available memory values: 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) \\n * 512 (.5 vCPU) - Available memory values: 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) \\n * 1024 (1 vCPU) - Available memory values: 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) \\n * 2048 (2 vCPU) - Available memory values: Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) \\n * 4096 (4 vCPU) - Available memory values: Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB)"', args=[d.arg(name='cpu', type=d.T.string)]),
      withCpu(cpu): { spec+: { forProvider+: { cpu: cpu } } },
      '#withExecutionRoleARN':: d.fn(help='"The Amazon Resource Name (ARN) of the task execution role that grants the Amazon ECS container agent permission to make Amazon Web Services API calls on your behalf. The task execution IAM role is required depending on the requirements of your task. For more information, see Amazon ECS task execution IAM role (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_execution_IAM_role.html) in the Amazon Elastic Container Service Developer Guide."', args=[d.arg(name='executionRoleARN', type=d.T.string)]),
      withExecutionRoleARN(executionRoleARN): { spec+: { forProvider+: { executionRoleARN: executionRoleARN } } },
      '#withFamily':: d.fn(help='"You must specify a family for a task definition, which allows you to track multiple versions of the same task definition. The family is used as a name for your task definition. Up to 255 letters (uppercase and lowercase), numbers, underscores, and hyphens are allowed."', args=[d.arg(name='family', type=d.T.string)]),
      withFamily(family): { spec+: { forProvider+: { family: family } } },
      '#withInferenceAccelerators':: d.fn(help='"The Elastic Inference accelerators to use for the containers in the task."', args=[d.arg(name='inferenceAccelerators', type=d.T.array)]),
      withInferenceAccelerators(inferenceAccelerators): { spec+: { forProvider+: { inferenceAccelerators: if std.isArray(v=inferenceAccelerators) then inferenceAccelerators else [inferenceAccelerators] } } },
      '#withInferenceAcceleratorsMixin':: d.fn(help='"The Elastic Inference accelerators to use for the containers in the task."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='inferenceAccelerators', type=d.T.array)]),
      withInferenceAcceleratorsMixin(inferenceAccelerators): { spec+: { forProvider+: { inferenceAccelerators+: if std.isArray(v=inferenceAccelerators) then inferenceAccelerators else [inferenceAccelerators] } } },
      '#withIpcMode':: d.fn(help='"The IPC resource namespace to use for the containers in the task. The valid values are host, task, or none. If host is specified, then all containers within the tasks that specified the host IPC mode on the same container instance share the same IPC resources with the host Amazon EC2 instance. If task is specified, all containers within the specified task share the same IPC resources. If none is specified, then IPC resources within the containers of a task are private and not shared with other containers in a task or on the container instance. If no value is specified, then the IPC resource namespace sharing depends on the Docker daemon setting on the container instance. For more information, see IPC settings (https://docs.docker.com/engine/reference/run/#ipc-settings---ipc) in the Docker run reference. \\n If the host IPC mode is used, be aware that there is a heightened risk of undesired IPC namespace expose. For more information, see Docker security (https://docs.docker.com/engine/security/security/). \\n If you are setting namespaced kernel parameters using systemControls for the containers in the task, the following will apply to your IPC resource namespace. For more information, see System Controls (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html) in the Amazon Elastic Container Service Developer Guide. \\n * For tasks that use the host IPC mode, IPC namespace related systemControls are not supported. \\n * For tasks that use the task IPC mode, IPC namespace related systemControls will apply to all containers within a task. \\n This parameter is not supported for Windows containers or tasks run on Fargate."', args=[d.arg(name='ipcMode', type=d.T.string)]),
      withIpcMode(ipcMode): { spec+: { forProvider+: { ipcMode: ipcMode } } },
      '#withMemory':: d.fn(help='"The amount of memory (in MiB) used by the task. It can be expressed as an integer using MiB, for example 1024, or as a string using GB, for example 1GB or 1 GB, in a task definition. String values are converted to an integer indicating the MiB when the task definition is registered. \\n Task-level CPU and memory parameters are ignored for Windows containers. We recommend specifying container-level resources for Windows containers. \\n If using the EC2 launch type, this field is optional. \\n If using the Fargate launch type, this field is required and you must use one of the following values, which determines your range of supported values for the cpu parameter: \\n * 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB) - Available cpu values: 256 (.25 vCPU) \\n * 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB) - Available cpu values: 512 (.5 vCPU) \\n * 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB) - Available cpu values: 1024 (1 vCPU) \\n * Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB) - Available cpu values: 2048 (2 vCPU) \\n * Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB) - Available cpu values: 4096 (4 vCPU)"', args=[d.arg(name='memory', type=d.T.string)]),
      withMemory(memory): { spec+: { forProvider+: { memory: memory } } },
      '#withNetworkMode':: d.fn(help='"The Docker networking mode to use for the containers in the task. The valid values are none, bridge, awsvpc, and host. If no network mode is specified, the default is bridge. \\n For Amazon ECS tasks on Fargate, the awsvpc network mode is required. For Amazon ECS tasks on Amazon EC2 Linux instances, any network mode can be used. For Amazon ECS tasks on Amazon EC2 Windows instances, <default> or awsvpc can be used. If the network mode is set to none, you cannot specify port mappings in your container definitions, and the tasks containers do not have external connectivity. The host and awsvpc network modes offer the highest networking performance for containers because they use the EC2 network stack instead of the virtualized network stack provided by the bridge mode. \\n With the host and awsvpc network modes, exposed container ports are mapped directly to the corresponding host port (for the host network mode) or the attached elastic network interface port (for the awsvpc network mode), so you cannot take advantage of dynamic host port mappings. \\n When using the host network mode, you should not run containers using the root user (UID 0). It is considered best practice to use a non-root user. \\n If the network mode is awsvpc, the task is allocated an elastic network interface, and you must specify a NetworkConfiguration value when you create a service or run a task with the task definition. For more information, see Task Networking (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-networking.html) in the Amazon Elastic Container Service Developer Guide. \\n If the network mode is host, you cannot run multiple instantiations of the same task on a single container instance when port mappings are used. \\n For more information, see Network settings (https://docs.docker.com/engine/reference/run/#network-settings) in the Docker run reference."', args=[d.arg(name='networkMode', type=d.T.string)]),
      withNetworkMode(networkMode): { spec+: { forProvider+: { networkMode: networkMode } } },
      '#withPidMode':: d.fn(help='"The process namespace to use for the containers in the task. The valid values are host or task. If host is specified, then all containers within the tasks that specified the host PID mode on the same container instance share the same process namespace with the host Amazon EC2 instance. If task is specified, all containers within the specified task share the same process namespace. If no value is specified, the default is a private namespace. For more information, see PID settings (https://docs.docker.com/engine/reference/run/#pid-settings---pid) in the Docker run reference. \\n If the host PID mode is used, be aware that there is a heightened risk of undesired process namespace expose. For more information, see Docker security (https://docs.docker.com/engine/security/security/). \\n This parameter is not supported for Windows containers or tasks run on Fargate."', args=[d.arg(name='pidMode', type=d.T.string)]),
      withPidMode(pidMode): { spec+: { forProvider+: { pidMode: pidMode } } },
      '#withPlacementConstraints':: d.fn(help='"An array of placement constraint objects to use for the task. You can specify a maximum of 10 constraints per task (this limit includes constraints in the task definition and those specified at runtime)."', args=[d.arg(name='placementConstraints', type=d.T.array)]),
      withPlacementConstraints(placementConstraints): { spec+: { forProvider+: { placementConstraints: if std.isArray(v=placementConstraints) then placementConstraints else [placementConstraints] } } },
      '#withPlacementConstraintsMixin':: d.fn(help='"An array of placement constraint objects to use for the task. You can specify a maximum of 10 constraints per task (this limit includes constraints in the task definition and those specified at runtime)."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='placementConstraints', type=d.T.array)]),
      withPlacementConstraintsMixin(placementConstraints): { spec+: { forProvider+: { placementConstraints+: if std.isArray(v=placementConstraints) then placementConstraints else [placementConstraints] } } },
      '#withRegion':: d.fn(help='"Region is which region the TaskDefinition will be created."', args=[d.arg(name='region', type=d.T.string)]),
      withRegion(region): { spec+: { forProvider+: { region: region } } },
      '#withRequiresCompatibilities':: d.fn(help="\"The task launch type that Amazon ECS should validate the task definition against. A client exception is returned if the task definition doesn't validate against the compatibilities specified. If no value is specified, the parameter is omitted from the response.\"", args=[d.arg(name='requiresCompatibilities', type=d.T.array)]),
      withRequiresCompatibilities(requiresCompatibilities): { spec+: { forProvider+: { requiresCompatibilities: if std.isArray(v=requiresCompatibilities) then requiresCompatibilities else [requiresCompatibilities] } } },
      '#withRequiresCompatibilitiesMixin':: d.fn(help="\"The task launch type that Amazon ECS should validate the task definition against. A client exception is returned if the task definition doesn't validate against the compatibilities specified. If no value is specified, the parameter is omitted from the response.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='requiresCompatibilities', type=d.T.array)]),
      withRequiresCompatibilitiesMixin(requiresCompatibilities): { spec+: { forProvider+: { requiresCompatibilities+: if std.isArray(v=requiresCompatibilities) then requiresCompatibilities else [requiresCompatibilities] } } },
      '#withTags':: d.fn(help='"The metadata that you apply to the task definition to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. \\n The following basic restrictions apply to tags: \\n * Maximum number of tags per resource - 50 \\n * For each resource, each tag key must be unique, and each tag key can have only one value. \\n * Maximum key length - 128 Unicode characters in UTF-8 \\n * Maximum value length - 256 Unicode characters in UTF-8 \\n * If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @. \\n * Tag keys and values are case-sensitive. \\n * Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit."', args=[d.arg(name='tags', type=d.T.array)]),
      withTags(tags): { spec+: { forProvider+: { tags: if std.isArray(v=tags) then tags else [tags] } } },
      '#withTagsMixin':: d.fn(help='"The metadata that you apply to the task definition to help you categorize and organize them. Each tag consists of a key and an optional value, both of which you define. \\n The following basic restrictions apply to tags: \\n * Maximum number of tags per resource - 50 \\n * For each resource, each tag key must be unique, and each tag key can have only one value. \\n * Maximum key length - 128 Unicode characters in UTF-8 \\n * Maximum value length - 256 Unicode characters in UTF-8 \\n * If your tagging schema is used across multiple services and resources, remember that other services may have restrictions on allowed characters. Generally allowed characters are: letters, numbers, and spaces representable in UTF-8, and the following characters: + - = . _ : / @. \\n * Tag keys and values are case-sensitive. \\n * Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for either keys or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or values with this prefix. Tags with this prefix do not count against your tags per resource limit."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.array)]),
      withTagsMixin(tags): { spec+: { forProvider+: { tags+: if std.isArray(v=tags) then tags else [tags] } } },
      '#withTaskRoleARN':: d.fn(help='"The short name or full Amazon Resource Name (ARN) of the IAM role that containers in this task can assume. All containers in this task are granted the permissions that are specified in this role. For more information, see IAM Roles for Tasks (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html) in the Amazon Elastic Container Service Developer Guide. A list of volume definitions in JSON format that containers in your task may use."', args=[d.arg(name='taskRoleARN', type=d.T.string)]),
      withTaskRoleARN(taskRoleARN): { spec+: { forProvider+: { taskRoleARN: taskRoleARN } } },
      '#withVolumes':: d.fn(help='', args=[d.arg(name='volumes', type=d.T.array)]),
      withVolumes(volumes): { spec+: { forProvider+: { volumes: if std.isArray(v=volumes) then volumes else [volumes] } } },
      '#withVolumesMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumes', type=d.T.array)]),
      withVolumesMixin(volumes): { spec+: { forProvider+: { volumes+: if std.isArray(v=volumes) then volumes else [volumes] } } },
    },
    '#providerConfigRef':: d.obj(help='"ProviderConfigReference specifies how the provider that will be used to create, observe, update, and delete this managed resource should be configured."'),
    providerConfigRef: {
      '#policy':: d.obj(help='"Policies for referencing."'),
      policy: {
        '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
        withResolution(resolution): { spec+: { providerConfigRef+: { policy+: { resolution: resolution } } } },
        '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
        withResolve(resolve): { spec+: { providerConfigRef+: { policy+: { resolve: resolve } } } },
      },
      '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { providerConfigRef+: { name: name } } },
    },
    '#providerRef':: d.obj(help='"ProviderReference specifies the provider that will be used to create, observe, update, and delete this managed resource. Deprecated: Please use ProviderConfigReference, i.e. `providerConfigRef`"'),
    providerRef: {
      '#policy':: d.obj(help='"Policies for referencing."'),
      policy: {
        '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
        withResolution(resolution): { spec+: { providerRef+: { policy+: { resolution: resolution } } } },
        '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
        withResolve(resolve): { spec+: { providerRef+: { policy+: { resolve: resolve } } } },
      },
      '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { providerRef+: { name: name } } },
    },
    '#publishConnectionDetailsTo':: d.obj(help='"PublishConnectionDetailsTo specifies the connection secret config which contains a name, metadata and a reference to secret store config to which any connection details for this managed resource should be written. Connection details frequently include the endpoint, username, and password required to connect to the managed resource."'),
    publishConnectionDetailsTo: {
      '#configRef':: d.obj(help='"SecretStoreConfigRef specifies which secret store config should be used for this ConnectionSecret."'),
      configRef: {
        '#policy':: d.obj(help='"Policies for referencing."'),
        policy: {
          '#withResolution':: d.fn(help="\"Resolution specifies whether resolution of this reference is required. The default is 'Required', which means the reconcile will fail if the reference cannot be resolved. 'Optional' means this reference will be a no-op if it cannot be resolved.\"", args=[d.arg(name='resolution', type=d.T.string)]),
          withResolution(resolution): { spec+: { publishConnectionDetailsTo+: { configRef+: { policy+: { resolution: resolution } } } } },
          '#withResolve':: d.fn(help="\"Resolve specifies when this reference should be resolved. The default is 'IfNotPresent', which will attempt to resolve the reference only when the corresponding field is not present. Use 'Always' to resolve the reference on every reconcile.\"", args=[d.arg(name='resolve', type=d.T.string)]),
          withResolve(resolve): { spec+: { publishConnectionDetailsTo+: { configRef+: { policy+: { resolve: resolve } } } } },
        },
        '#withName':: d.fn(help='"Name of the referenced object."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { publishConnectionDetailsTo+: { configRef+: { name: name } } } },
      },
      '#metadata':: d.obj(help='"Metadata is the metadata for connection secret."'),
      metadata: {
        '#withAnnotations':: d.fn(help='"Annotations are the annotations to be added to connection secret. - For Kubernetes secrets, this will be used as \\"metadata.annotations\\". - It is up to Secret Store implementation for others store types."', args=[d.arg(name='annotations', type=d.T.object)]),
        withAnnotations(annotations): { spec+: { publishConnectionDetailsTo+: { metadata+: { annotations: annotations } } } },
        '#withAnnotationsMixin':: d.fn(help='"Annotations are the annotations to be added to connection secret. - For Kubernetes secrets, this will be used as \\"metadata.annotations\\". - It is up to Secret Store implementation for others store types."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
        withAnnotationsMixin(annotations): { spec+: { publishConnectionDetailsTo+: { metadata+: { annotations+: annotations } } } },
        '#withLabels':: d.fn(help='"Labels are the labels/tags to be added to connection secret. - For Kubernetes secrets, this will be used as \\"metadata.labels\\". - It is up to Secret Store implementation for others store types."', args=[d.arg(name='labels', type=d.T.object)]),
        withLabels(labels): { spec+: { publishConnectionDetailsTo+: { metadata+: { labels: labels } } } },
        '#withLabelsMixin':: d.fn(help='"Labels are the labels/tags to be added to connection secret. - For Kubernetes secrets, this will be used as \\"metadata.labels\\". - It is up to Secret Store implementation for others store types."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
        withLabelsMixin(labels): { spec+: { publishConnectionDetailsTo+: { metadata+: { labels+: labels } } } },
        '#withType':: d.fn(help='"Type is the SecretType for the connection secret. - Only valid for Kubernetes Secret Stores."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { spec+: { publishConnectionDetailsTo+: { metadata+: { type: type } } } },
      },
      '#withName':: d.fn(help='"Name is the name of the connection secret."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { publishConnectionDetailsTo+: { name: name } } },
    },
    '#withDeletionPolicy':: d.fn(help='"DeletionPolicy specifies what will happen to the underlying external when this managed resource is deleted - either \\"Delete\\" or \\"Orphan\\" the external resource."', args=[d.arg(name='deletionPolicy', type=d.T.string)]),
    withDeletionPolicy(deletionPolicy): { spec+: { deletionPolicy: deletionPolicy } },
    '#writeConnectionSecretToRef':: d.obj(help='"WriteConnectionSecretToReference specifies the namespace and name of a Secret to which any connection details for this managed resource should be written. Connection details frequently include the endpoint, username, and password required to connect to the managed resource. This field is planned to be replaced in a future release in favor of PublishConnectionDetailsTo. Currently, both could be set independently and connection details would be published to both without affecting each other."'),
    writeConnectionSecretToRef: {
      '#withName':: d.fn(help='"Name of the secret."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { writeConnectionSecretToRef+: { name: name } } },
      '#withNamespace':: d.fn(help='"Namespace of the secret."', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { spec+: { writeConnectionSecretToRef+: { namespace: namespace } } },
    },
  },
  '#mixin': 'ignore',
  mixin: self,
}
