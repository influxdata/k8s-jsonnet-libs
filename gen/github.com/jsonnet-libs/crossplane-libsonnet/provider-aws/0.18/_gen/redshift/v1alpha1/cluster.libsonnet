{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='cluster', url='', help='A Cluster is a managed resource that represents an AWS Redshift cluster.'),
  '#metadata':: d.obj(help='ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create.'),
  metadata: {
    '#withAnnotations':: d.fn(help='Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request.', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers.', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only.', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers.', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list.', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list.\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\n\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\n\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='A sequence number representing a specific generation of the desired state. Populated by the system. Read-only.', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withManagedFields':: d.fn(help="ManagedFields maps workflow-id and version to the set of fields that are managed by that workflow. This is mostly for internal housekeeping, and users typically shouldn't need to set or understand this field. A workflow can be the user's name, a controller's name, or the name of a specific apply path like 'ci-cd'. The set of fields is always in the version that the workflow used when modifying the object.", args=[d.arg(name='managedFields', type=d.T.array)]),
    withManagedFields(managedFields): { metadata+: { managedFields: if std.isArray(v=managedFields) then managedFields else [managedFields] } },
    '#withManagedFieldsMixin':: d.fn(help="ManagedFields maps workflow-id and version to the set of fields that are managed by that workflow. This is mostly for internal housekeeping, and users typically shouldn't need to set or understand this field. A workflow can be the user's name, a controller's name, or the name of a specific apply path like 'ci-cd'. The set of fields is always in the version that the workflow used when modifying the object.\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='managedFields', type=d.T.array)]),
    withManagedFieldsMixin(managedFields): { metadata+: { managedFields+: if std.isArray(v=managedFields) then managedFields else [managedFields] } },
    '#withName':: d.fn(help='Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the "default" namespace, but "default" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\n\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller.', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller.\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\n\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='SelfLink is a URL representing this object. Populated by the system. Read-only.\n\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release.', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\n\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of Cluster', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'redshift.aws.crossplane.io/v1alpha1',
    kind: 'Cluster',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help='ClusterSpec defines the desired state of an AWS Redshift Cluster.'),
  spec: {
    '#forProvider':: d.obj(help='ClusterParameters define the parameters available for an AWS Redshift cluster'),
    forProvider: {
      '#clusterSecurityGroupSelector':: d.obj(help='ClusterSecurityGroupSelector selects references to ClusterSecurityGroups used to set the ClusterSecurityGroups.'),
      clusterSecurityGroupSelector: {
        '#withMatchControllerRef':: d.fn(help='MatchControllerRef ensures an object with the same controller reference as the selecting object is selected.', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
        withMatchControllerRef(matchControllerRef): { spec+: { forProvider+: { clusterSecurityGroupSelector+: { matchControllerRef: matchControllerRef } } } },
        '#withMatchLabels':: d.fn(help='MatchLabels ensures an object with matching labels is selected.', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabels(matchLabels): { spec+: { forProvider+: { clusterSecurityGroupSelector+: { matchLabels: matchLabels } } } },
        '#withMatchLabelsMixin':: d.fn(help='MatchLabels ensures an object with matching labels is selected.\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabelsMixin(matchLabels): { spec+: { forProvider+: { clusterSecurityGroupSelector+: { matchLabels+: matchLabels } } } },
      },
      '#iamRoleSelector':: d.obj(help='IAMRoleSelector selects references to IAMRoles used to set the IAMRoles.'),
      iamRoleSelector: {
        '#withMatchControllerRef':: d.fn(help='MatchControllerRef ensures an object with the same controller reference as the selecting object is selected.', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
        withMatchControllerRef(matchControllerRef): { spec+: { forProvider+: { iamRoleSelector+: { matchControllerRef: matchControllerRef } } } },
        '#withMatchLabels':: d.fn(help='MatchLabels ensures an object with matching labels is selected.', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabels(matchLabels): { spec+: { forProvider+: { iamRoleSelector+: { matchLabels: matchLabels } } } },
        '#withMatchLabelsMixin':: d.fn(help='MatchLabels ensures an object with matching labels is selected.\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabelsMixin(matchLabels): { spec+: { forProvider+: { iamRoleSelector+: { matchLabels+: matchLabels } } } },
      },
      '#vpcSecurityGroupIDSelector':: d.obj(help='VPCSecurityGroupIDSelector selects references to VPCSecurityGroups used to set the VPCSecurityGroupIDs.'),
      vpcSecurityGroupIDSelector: {
        '#withMatchControllerRef':: d.fn(help='MatchControllerRef ensures an object with the same controller reference as the selecting object is selected.', args=[d.arg(name='matchControllerRef', type=d.T.boolean)]),
        withMatchControllerRef(matchControllerRef): { spec+: { forProvider+: { vpcSecurityGroupIDSelector+: { matchControllerRef: matchControllerRef } } } },
        '#withMatchLabels':: d.fn(help='MatchLabels ensures an object with matching labels is selected.', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabels(matchLabels): { spec+: { forProvider+: { vpcSecurityGroupIDSelector+: { matchLabels: matchLabels } } } },
        '#withMatchLabelsMixin':: d.fn(help='MatchLabels ensures an object with matching labels is selected.\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabelsMixin(matchLabels): { spec+: { forProvider+: { vpcSecurityGroupIDSelector+: { matchLabels+: matchLabels } } } },
      },
      '#withAllowVersionUpgrade':: d.fn(help='AllowVersionUpgrade indicates that major engine upgrades are applied automatically to the cluster during the maintenance window. default=true', args=[d.arg(name='allowVersionUpgrade', type=d.T.boolean)]),
      withAllowVersionUpgrade(allowVersionUpgrade): { spec+: { forProvider+: { allowVersionUpgrade: allowVersionUpgrade } } },
      '#withAutomatedSnapshotRetentionPeriod':: d.fn(help='AutomatedSnapshotRetentionPeriod is the number of days for which automated backups are retained. Setting this parameter to a positive number enables backups. Setting this parameter to  0 disables automated backups. default=1', args=[d.arg(name='automatedSnapshotRetentionPeriod', type=d.T.integer)]),
      withAutomatedSnapshotRetentionPeriod(automatedSnapshotRetentionPeriod): { spec+: { forProvider+: { automatedSnapshotRetentionPeriod: automatedSnapshotRetentionPeriod } } },
      '#withAvailabilityZone':: d.fn(help="AvailabilityZone is the EC2 Availability Zone in which you want Amazon Redshift to provision the cluster. Default: A random, system-chosen Availability Zone in the region that is specified by the endpoint. Example: us-east-2d Constraint: The specified Availability Zone must be in the same region as the current endpoint. The Availability Zone parameter can't be specified if the MultiAZ parameter is set to true. The specified Availability Zone must be in the same AWS Region as the current endpoint.", args=[d.arg(name='availabilityZone', type=d.T.string)]),
      withAvailabilityZone(availabilityZone): { spec+: { forProvider+: { availabilityZone: availabilityZone } } },
      '#withClusterParameterGroupName':: d.fn(help='ClusterParameterGroupName is the name of the cluster parameter group to use for the cluster. Default: The default Amazon Redshift cluster parameter group. For information about the default parameter group, go to Working with Amazon Redshift Parameter Groups (https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-parameter-groups.html)', args=[d.arg(name='clusterParameterGroupName', type=d.T.string)]),
      withClusterParameterGroupName(clusterParameterGroupName): { spec+: { forProvider+: { clusterParameterGroupName: clusterParameterGroupName } } },
      '#withClusterSecurityGroupRefs':: d.fn(help='ClusterSecurityGroupRefs are references to ClusterSecurityGroups used to set the ClusterSecurityGroups.', args=[d.arg(name='clusterSecurityGroupRefs', type=d.T.array)]),
      withClusterSecurityGroupRefs(clusterSecurityGroupRefs): { spec+: { forProvider+: { clusterSecurityGroupRefs: if std.isArray(v=clusterSecurityGroupRefs) then clusterSecurityGroupRefs else [clusterSecurityGroupRefs] } } },
      '#withClusterSecurityGroupRefsMixin':: d.fn(help='ClusterSecurityGroupRefs are references to ClusterSecurityGroups used to set the ClusterSecurityGroups.\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='clusterSecurityGroupRefs', type=d.T.array)]),
      withClusterSecurityGroupRefsMixin(clusterSecurityGroupRefs): { spec+: { forProvider+: { clusterSecurityGroupRefs+: if std.isArray(v=clusterSecurityGroupRefs) then clusterSecurityGroupRefs else [clusterSecurityGroupRefs] } } },
      '#withClusterSecurityGroups':: d.fn(help='SecurityGroups is a list of security groups to associate with this cluster. Default: The default cluster security group for Amazon Redshift.', args=[d.arg(name='clusterSecurityGroups', type=d.T.array)]),
      withClusterSecurityGroups(clusterSecurityGroups): { spec+: { forProvider+: { clusterSecurityGroups: if std.isArray(v=clusterSecurityGroups) then clusterSecurityGroups else [clusterSecurityGroups] } } },
      '#withClusterSecurityGroupsMixin':: d.fn(help='SecurityGroups is a list of security groups to associate with this cluster. Default: The default cluster security group for Amazon Redshift.\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='clusterSecurityGroups', type=d.T.array)]),
      withClusterSecurityGroupsMixin(clusterSecurityGroups): { spec+: { forProvider+: { clusterSecurityGroups+: if std.isArray(v=clusterSecurityGroups) then clusterSecurityGroups else [clusterSecurityGroups] } } },
      '#withClusterSubnetGroupName':: d.fn(help='ClusterSubnetGroupName is the name of a cluster subnet group to be associated with this cluster. If this parameter is not provided the resulting cluster will be deployed outside virtual private cloud (VPC).', args=[d.arg(name='clusterSubnetGroupName', type=d.T.string)]),
      withClusterSubnetGroupName(clusterSubnetGroupName): { spec+: { forProvider+: { clusterSubnetGroupName: clusterSubnetGroupName } } },
      '#withClusterType':: d.fn(help='ClusterType is the type of the cluster you want. When cluster type is specified as    * single-node, the NumberOfNodes parameter is not required.    * multi-node, the NumberOfNodes parameter is required. default=multi-node', args=[d.arg(name='clusterType', type=d.T.string)]),
      withClusterType(clusterType): { spec+: { forProvider+: { clusterType: clusterType } } },
      '#withClusterVersion':: d.fn(help='ClusterVersion is the version of the Amazon Redshift engine software that you want to deploy on the cluster. The version selected runs on all the nodes in the cluster. Constraints: Only version 1.0 is currently available.', args=[d.arg(name='clusterVersion', type=d.T.string)]),
      withClusterVersion(clusterVersion): { spec+: { forProvider+: { clusterVersion: clusterVersion } } },
      '#withDbName':: d.fn(help='DBName is the name of the first database to be created when the cluster is created. To create additional databases after the cluster is created, connect to the cluster with a SQL client and use SQL commands to create a database. For more information, go to Create a Database (https://docs.aws.amazon.com/redshift/latest/dg/t_creating_database.html) in the Amazon Redshift Database Developer Guide. Constraints:    * Must contain 1 to 64 alphanumeric characters.    * Must contain only lowercase letters.    * Cannot be a word that is reserved by the service. A list of reserved    words can be found in Reserved Words (https://docs.aws.amazon.com/redshift/latest/dg/r_pg_keywords.html)    in the Amazon Redshift Database Developer Guide. default=dev', args=[d.arg(name='dbName', type=d.T.string)]),
      withDbName(dbName): { spec+: { forProvider+: { dbName: dbName } } },
      '#withElasticIP':: d.fn(help='The Elastic IP (EIP) address for the cluster. Constraints: The cluster must be provisioned in EC2-VPC and publicly-accessible through an Internet gateway. For more information about provisioning clusters in EC2-VPC, go to Supported Platforms to Launch Your Cluster (https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-clusters.html#cluster-platforms) in the Amazon Redshift Cluster Management Guide.', args=[d.arg(name='elasticIP', type=d.T.string)]),
      withElasticIP(elasticIP): { spec+: { forProvider+: { elasticIP: elasticIP } } },
      '#withEncrypted':: d.fn(help='Encrypted defines whether your data in the cluster will be encrypted at rest or not. default=false', args=[d.arg(name='encrypted', type=d.T.boolean)]),
      withEncrypted(encrypted): { spec+: { forProvider+: { encrypted: encrypted } } },
      '#withEnhancedVPCRouting':: d.fn(help='EnhancedVPCRouting specifies whether to create the cluster with enhanced VPC routing enabled. To create a cluster that uses enhanced VPC routing, the cluster must be in a VPC. For more information, see Enhanced VPC Routing (https://docs.aws.amazon.com/redshift/latest/mgmt/enhanced-vpc-routing.html) in the Amazon Redshift Cluster Management Guide. If this option is true, enhanced VPC routing is enabled. default=false', args=[d.arg(name='enhancedVPCRouting', type=d.T.boolean)]),
      withEnhancedVPCRouting(enhancedVPCRouting): { spec+: { forProvider+: { enhancedVPCRouting: enhancedVPCRouting } } },
      '#withFinalClusterSnapshotIdentifier':: d.fn(help='FinalClusterSnapshotIdentifier is the identifier of the final snapshot that is to be created immediately before deleting the cluster. If this parameter is provided, SkipFinalClusterSnapshot must be false. Constraints:    * Must be 1 to 255 alphanumeric characters.    * First character must be a letter.    * Cannot end with a hyphen or contain two consecutive hyphens.', args=[d.arg(name='finalClusterSnapshotIdentifier', type=d.T.string)]),
      withFinalClusterSnapshotIdentifier(finalClusterSnapshotIdentifier): { spec+: { forProvider+: { finalClusterSnapshotIdentifier: finalClusterSnapshotIdentifier } } },
      '#withFinalClusterSnapshotRetentionPeriod':: d.fn(help='FinalClusterSnapshotRetentionPeriod is the number of days that a manual snapshot is retained. If the value is -1, the manual snapshot is retained indefinitely. The value must be either -1 or an integer between 1 and 3,653. default -1', args=[d.arg(name='finalClusterSnapshotRetentionPeriod', type=d.T.integer)]),
      withFinalClusterSnapshotRetentionPeriod(finalClusterSnapshotRetentionPeriod): { spec+: { forProvider+: { finalClusterSnapshotRetentionPeriod: finalClusterSnapshotRetentionPeriod } } },
      '#withHsmClientCertificateIdentifier':: d.fn(help='HSMClientCertificateIdentifier specifies the name of the HSM client certificate the Amazon Redshift cluster uses to retrieve the data encryption keys stored in an HSM.', args=[d.arg(name='hsmClientCertificateIdentifier', type=d.T.string)]),
      withHsmClientCertificateIdentifier(hsmClientCertificateIdentifier): { spec+: { forProvider+: { hsmClientCertificateIdentifier: hsmClientCertificateIdentifier } } },
      '#withHsmConfigurationIdentifier':: d.fn(help='HSMConfigurationIdentifier specifies the name of the HSM configuration that contains the information the Amazon Redshift cluster can use to retrieve and store keys in an HSM.', args=[d.arg(name='hsmConfigurationIdentifier', type=d.T.string)]),
      withHsmConfigurationIdentifier(hsmConfigurationIdentifier): { spec+: { forProvider+: { hsmConfigurationIdentifier: hsmConfigurationIdentifier } } },
      '#withIamRoleRefs':: d.fn(help='IAMRoleRefs are references to IAMRoles used to set the IAMRoles.', args=[d.arg(name='iamRoleRefs', type=d.T.array)]),
      withIamRoleRefs(iamRoleRefs): { spec+: { forProvider+: { iamRoleRefs: if std.isArray(v=iamRoleRefs) then iamRoleRefs else [iamRoleRefs] } } },
      '#withIamRoleRefsMixin':: d.fn(help='IAMRoleRefs are references to IAMRoles used to set the IAMRoles.\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='iamRoleRefs', type=d.T.array)]),
      withIamRoleRefsMixin(iamRoleRefs): { spec+: { forProvider+: { iamRoleRefs+: if std.isArray(v=iamRoleRefs) then iamRoleRefs else [iamRoleRefs] } } },
      '#withIamRoles':: d.fn(help='IAMRoles is a list of AWS Identity and Access Management (IAM) roles that can be used by the cluster to access other AWS services. You must supply the IAM roles in their Amazon Resource Name (ARN) format. You can supply up to 10 IAM roles in a single request. A cluster can have up to 10 IAM roles associated with it at any time. kubebuilder:validation:MaxItems=10', args=[d.arg(name='iamRoles', type=d.T.array)]),
      withIamRoles(iamRoles): { spec+: { forProvider+: { iamRoles: if std.isArray(v=iamRoles) then iamRoles else [iamRoles] } } },
      '#withIamRolesMixin':: d.fn(help='IAMRoles is a list of AWS Identity and Access Management (IAM) roles that can be used by the cluster to access other AWS services. You must supply the IAM roles in their Amazon Resource Name (ARN) format. You can supply up to 10 IAM roles in a single request. A cluster can have up to 10 IAM roles associated with it at any time. kubebuilder:validation:MaxItems=10\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='iamRoles', type=d.T.array)]),
      withIamRolesMixin(iamRoles): { spec+: { forProvider+: { iamRoles+: if std.isArray(v=iamRoles) then iamRoles else [iamRoles] } } },
      '#withKmsKeyID':: d.fn(help='KMSKeyID is the Amazon Resource Name (ARN) for the KMS encryption key. If you are creating a cluster with the same AWS account that owns the KMS encryption key used to encrypt the new cluster, then you can use the KMS key alias instead of the ARN for the KM encryption key.', args=[d.arg(name='kmsKeyID', type=d.T.string)]),
      withKmsKeyID(kmsKeyID): { spec+: { forProvider+: { kmsKeyID: kmsKeyID } } },
      '#withMaintenanceTrackName':: d.fn(help='MaintenanceTrackName an optional parameter for the name of the maintenance track for the cluster.', args=[d.arg(name='maintenanceTrackName', type=d.T.string)]),
      withMaintenanceTrackName(maintenanceTrackName): { spec+: { forProvider+: { maintenanceTrackName: maintenanceTrackName } } },
      '#withManualSnapshotRetentionPeriod':: d.fn(help="ManualSnapshotRetentionPeriod is the default number of days to retain a manual snapshot. If the value is -1, the snapshot is retained indefinitely. This setting doesn't change the retention period of existing snapshots. default=1", args=[d.arg(name='manualSnapshotRetentionPeriod', type=d.T.integer)]),
      withManualSnapshotRetentionPeriod(manualSnapshotRetentionPeriod): { spec+: { forProvider+: { manualSnapshotRetentionPeriod: manualSnapshotRetentionPeriod } } },
      '#withMasterUsername':: d.fn(help="MasterUsername is the user name associated with the master user account for the cluster that is being created. Constraints:    * Must be 1 - 128 alphanumeric characters. The user name can't be PUBLIC.    * First character must be a letter.    * Cannot be a reserved word. A list of reserved words can be found in    Reserved Words (https://docs.aws.amazon.com/redshift/latest/dg/r_pg_keywords.html)    in the Amazon Redshift Database Developer Guide.", args=[d.arg(name='masterUsername', type=d.T.string)]),
      withMasterUsername(masterUsername): { spec+: { forProvider+: { masterUsername: masterUsername } } },
      '#withNewClusterIdentifier':: d.fn(help='NewClusterIdentifier is the new identifier you want to use for the cluster.', args=[d.arg(name='newClusterIdentifier', type=d.T.string)]),
      withNewClusterIdentifier(newClusterIdentifier): { spec+: { forProvider+: { newClusterIdentifier: newClusterIdentifier } } },
      '#withNewMasterUserPassword':: d.fn(help="NewMasterUserPassword is the new password to be associated with the master user account for the cluster that has being created. Set this value if you want to change the existing password of the cluster. Constraints:    * Must be between 8 and 64 characters in length.    * Must contain at least one uppercase letter.    * Must contain at least one lowercase letter.    * Must contain one number.    * Can be any printable ASCII character (ASCII code 33 to 126) except '    (single quote), ' (double quote), \\, /, @, or space.", args=[d.arg(name='newMasterUserPassword', type=d.T.string)]),
      withNewMasterUserPassword(newMasterUserPassword): { spec+: { forProvider+: { newMasterUserPassword: newMasterUserPassword } } },
      '#withNodeType':: d.fn(help='NodeType is the node type defining its size and compute capacity to be provisioned for the cluster. For information about node types, go to Working with Clusters (https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-clusters.html#how-many-nodes) in the Amazon Redshift Cluster Management Guide.', args=[d.arg(name='nodeType', type=d.T.string)]),
      withNodeType(nodeType): { spec+: { forProvider+: { nodeType: nodeType } } },
      '#withNumberOfNodes':: d.fn(help="NumberOfNodes defines the number of compute nodes in the cluster. This parameter is required when the ClusterType parameter is specified as multi-node. For information about determining how many nodes you need, go to Working with Clusters (https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-clusters.html#how-many-nodes) in the Amazon Redshift Cluster Management Guide. If you don't specify this parameter, you get a single-node cluster. When requesting a multi-node cluster, you must specify the number of nodes that you want in the cluster. default=1", args=[d.arg(name='numberOfNodes', type=d.T.integer)]),
      withNumberOfNodes(numberOfNodes): { spec+: { forProvider+: { numberOfNodes: numberOfNodes } } },
      '#withPort':: d.fn(help='Port specifies the port number on which the cluster accepts incoming connections. The cluster is accessible only via the JDBC and ODBC connection strings. Part of the connection string requires the port on which the cluster will listen for incoming connections. default=5439', args=[d.arg(name='port', type=d.T.integer)]),
      withPort(port): { spec+: { forProvider+: { port: port } } },
      '#withPreferredMaintenanceWindow':: d.fn(help='PreferredMaintenanceWindow is the weekly time range (in UTC) during which automated cluster maintenance can occur. Default: A 30-minute window selected at random from an 8-hour block of time per region, occurring on a random day of the week. For more information about the time blocks for each region, see Maintenance Windows (https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-clusters.html#rs-maintenance-windows) in Amazon Redshift Cluster Management Guide. Constraints: Minimum 30-minute window.', args=[d.arg(name='preferredMaintenanceWindow', type=d.T.string)]),
      withPreferredMaintenanceWindow(preferredMaintenanceWindow): { spec+: { forProvider+: { preferredMaintenanceWindow: preferredMaintenanceWindow } } },
      '#withPubliclyAccessible':: d.fn(help='PubliclyAccessible is to specify if the cluster can be accessed from a public network.', args=[d.arg(name='publiclyAccessible', type=d.T.boolean)]),
      withPubliclyAccessible(publiclyAccessible): { spec+: { forProvider+: { publiclyAccessible: publiclyAccessible } } },
      '#withRegion':: d.fn(help="Region is the region you'd like the Cluster to be created in.", args=[d.arg(name='region', type=d.T.string)]),
      withRegion(region): { spec+: { forProvider+: { region: region } } },
      '#withSkipFinalClusterSnapshot':: d.fn(help='SkipFinalClusterSnapshot determines whether a final snapshot of the cluster is created before Amazon Redshift deletes the cluster. If true, a final cluster snapshot is not created. If false, a final cluster snapshot is created before the cluster is deleted. The FinalClusterSnapshotIdentifier parameter must be specified if SkipFinalClusterSnapshot is false. Default: false', args=[d.arg(name='skipFinalClusterSnapshot', type=d.T.boolean)]),
      withSkipFinalClusterSnapshot(skipFinalClusterSnapshot): { spec+: { forProvider+: { skipFinalClusterSnapshot: skipFinalClusterSnapshot } } },
      '#withSnapshotScheduleIdentifier':: d.fn(help='SnapshotScheduleIdentifier is a unique identifier for the snapshot schedule.', args=[d.arg(name='snapshotScheduleIdentifier', type=d.T.string)]),
      withSnapshotScheduleIdentifier(snapshotScheduleIdentifier): { spec+: { forProvider+: { snapshotScheduleIdentifier: snapshotScheduleIdentifier } } },
      '#withTags':: d.fn(help='Tags indicates a list of tags for the clusters.', args=[d.arg(name='tags', type=d.T.array)]),
      withTags(tags): { spec+: { forProvider+: { tags: if std.isArray(v=tags) then tags else [tags] } } },
      '#withTagsMixin':: d.fn(help='Tags indicates a list of tags for the clusters.\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tags', type=d.T.array)]),
      withTagsMixin(tags): { spec+: { forProvider+: { tags+: if std.isArray(v=tags) then tags else [tags] } } },
      '#withVpcSecurityGroupIDRefs':: d.fn(help='VPCSecurityGroupIDRefs are references to VPCSecurityGroups used to set the VPCSecurityGroupIDs.', args=[d.arg(name='vpcSecurityGroupIDRefs', type=d.T.array)]),
      withVpcSecurityGroupIDRefs(vpcSecurityGroupIDRefs): { spec+: { forProvider+: { vpcSecurityGroupIDRefs: if std.isArray(v=vpcSecurityGroupIDRefs) then vpcSecurityGroupIDRefs else [vpcSecurityGroupIDRefs] } } },
      '#withVpcSecurityGroupIDRefsMixin':: d.fn(help='VPCSecurityGroupIDRefs are references to VPCSecurityGroups used to set the VPCSecurityGroupIDs.\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='vpcSecurityGroupIDRefs', type=d.T.array)]),
      withVpcSecurityGroupIDRefsMixin(vpcSecurityGroupIDRefs): { spec+: { forProvider+: { vpcSecurityGroupIDRefs+: if std.isArray(v=vpcSecurityGroupIDRefs) then vpcSecurityGroupIDRefs else [vpcSecurityGroupIDRefs] } } },
      '#withVpcSecurityGroupIds':: d.fn(help='VPCSecurityGroupIDs a list of Virtual Private Cloud (VPC) security groups to be associated with the cluster.', args=[d.arg(name='vpcSecurityGroupIds', type=d.T.array)]),
      withVpcSecurityGroupIds(vpcSecurityGroupIds): { spec+: { forProvider+: { vpcSecurityGroupIds: if std.isArray(v=vpcSecurityGroupIds) then vpcSecurityGroupIds else [vpcSecurityGroupIds] } } },
      '#withVpcSecurityGroupIdsMixin':: d.fn(help='VPCSecurityGroupIDs a list of Virtual Private Cloud (VPC) security groups to be associated with the cluster.\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='vpcSecurityGroupIds', type=d.T.array)]),
      withVpcSecurityGroupIdsMixin(vpcSecurityGroupIds): { spec+: { forProvider+: { vpcSecurityGroupIds+: if std.isArray(v=vpcSecurityGroupIds) then vpcSecurityGroupIds else [vpcSecurityGroupIds] } } },
    },
    '#providerConfigRef':: d.obj(help='ProviderConfigReference specifies how the provider that will be used to create, observe, update, and delete this managed resource should be configured.'),
    providerConfigRef: {
      '#withName':: d.fn(help='Name of the referenced object.', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { providerConfigRef+: { name: name } } },
    },
    '#providerRef':: d.obj(help='ProviderReference specifies the provider that will be used to create, observe, update, and delete this managed resource. Deprecated: Please use ProviderConfigReference, i.e. `providerConfigRef`'),
    providerRef: {
      '#withName':: d.fn(help='Name of the referenced object.', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { providerRef+: { name: name } } },
    },
    '#withDeletionPolicy':: d.fn(help='DeletionPolicy specifies what will happen to the underlying external when this managed resource is deleted - either "Delete" or "Orphan" the external resource. The "Delete" policy is the default when no policy is specified.', args=[d.arg(name='deletionPolicy', type=d.T.string)]),
    withDeletionPolicy(deletionPolicy): { spec+: { deletionPolicy: deletionPolicy } },
    '#writeConnectionSecretToRef':: d.obj(help='WriteConnectionSecretToReference specifies the namespace and name of a Secret to which any connection details for this managed resource should be written. Connection details frequently include the endpoint, username, and password required to connect to the managed resource.'),
    writeConnectionSecretToRef: {
      '#withName':: d.fn(help='Name of the secret.', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { writeConnectionSecretToRef+: { name: name } } },
      '#withNamespace':: d.fn(help='Namespace of the secret.', args=[d.arg(name='namespace', type=d.T.string)]),
      withNamespace(namespace): { spec+: { writeConnectionSecretToRef+: { namespace: namespace } } },
    },
  },
  '#mixin': 'ignore',
  mixin: self,
}
